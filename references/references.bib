@Article{Shi2024,
  author    = {Shi, Yuchen and Jiang, Guochao and Qiu, Tian and Yang, Deqing},
  title     = {AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction},
  year      = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2409.01854},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Josifoski2021,
  author        = {Josifoski, Martin and De Cao, Nicola and Peyrard, Maxime and Petroni, Fabio and West, Robert},
  title         = {GenIE: Generative Information Extraction},
  year          = {2021},
  month         = dec,
  abstract      = {Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce GenIE (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. GenIE naturally exploits the language knowledge from the pre-trained transformer by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that GenIE is state-of-the-art on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction. Code, data and models available at https://github.com/epfl-dlab/GenIE.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2112.08340},
  eprint        = {2112.08340},
  file          = {:Josifoski2021 - GenIE_ Generative Information Extraction.pdf:PDF:http\://arxiv.org/pdf/2112.08340v3},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Article{Zhao2024,
  author    = {Zhao, Xiaoyan and Deng, Yang and Yang, Min and Wang, Lingzhi and Zhang, Rui and Cheng, Hong and Lam, Wai and Shen, Ying and Xu, Ruifeng},
  journal   = {ACM Computing Surveys},
  title     = {A Comprehensive Survey on Relation Extraction: Recent Advances and New Frontiers},
  year      = {2024},
  issn      = {1557-7341},
  month     = jul,
  number    = {11},
  pages     = {1--39},
  volume    = {56},
  doi       = {10.1145/3674501},
  publisher = {Association for Computing Machinery (ACM)},
}

@Article{Brown2020,
  author        = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  title         = {Language Models are Few-Shot Learners},
  year          = {2020},
  month         = may,
  abstract      = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2005.14165},
  eprint        = {2005.14165},
  file          = {:Brown2020 - Language Models Are Few Shot Learners.pdf:PDF:http\://arxiv.org/pdf/2005.14165v4},
  keywords      = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Article{Wadhwa2023,
  author        = {Somin Wadhwa and Silvio Amir and Byron C. Wallace},
  journal       = {CoRR},
  title         = {Revisiting Relation Extraction in the era of Large Language Models},
  year          = {2023},
  volume        = {abs/2305.05003},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2305-05003.bib},
  doi           = {10.48550/ARXIV.2305.05003},
  eprint        = {2305.05003},
}

@Article{Xia2024,
  author        = {Yuchen Xia and Jiho Kim and Yuhan Chen and Haojie Ye and Souvik Kundu and Cong Hao and Nishil Talati},
  journal       = {CoRR},
  title         = {Understanding the Performance and Estimating the Cost of {LLM} Fine-Tuning},
  year          = {2024},
  volume        = {abs/2408.04693},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2408-04693.bib},
  doi           = {10.48550/ARXIV.2408.04693},
  eprint        = {2408.04693},
}

@Article{Chen2024,
  author    = {Chen, Zhenbin and Li, Zhixin and Zeng, Yufei and Zhang, Canlong and Ma, Huifang},
  journal   = {Expert Systems with Applications},
  title     = {GAP: A novel Generative context-Aware Prompt-tuning method for relation extraction},
  year      = {2024},
  issn      = {0957-4174},
  month     = aug,
  pages     = {123478},
  volume    = {248},
  doi       = {10.1016/j.eswa.2024.123478},
  publisher = {Elsevier BV},
}

@Article{Xue2024,
  author        = {Lilong Xue and Dan Zhang and Yuxiao Dong and Jie Tang},
  journal       = {CoRR},
  title         = {AutoRE: Document-Level Relation Extraction with Large Language Models},
  year          = {2024},
  volume        = {abs/2403.14888},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2403-14888.bib},
  doi           = {10.48550/ARXIV.2403.14888},
  eprint        = {2403.14888},
}

@Article{Levi2024,
  author        = {Elad Levi and Eli Brosh and Matan Friedmann},
  journal       = {CoRR},
  title         = {Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases},
  year          = {2024},
  volume        = {abs/2402.03099},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2402-03099.bib},
  doi           = {10.48550/ARXIV.2402.03099},
  eprint        = {2402.03099},
}

@Misc{LangChain,
  author    = {{LangChain Inc.}},
  title     = {Multi-agent Systems},
  timestamp = {2025-02-10},
  url       = {https://langchain-ai.github.io/langgraph/concepts/multi_agent/},
}

@InBook{Moeller2024,
  author    = {Möller, Cedric and Usbeck, Ricardo},
  pages     = {23-40},
  publisher = {Springer Nature Switzerland},
  title     = {DISCIE–Discriminative Closed Information Extraction},
  year      = {2024},
  month     = {11},
  booktitle = {Lecture Notes in Computer Science},
  date      = {2024-11-27},
  day       = {27},
  doi       = {10.1007/978-3-031-77850-6_2},
}

@Misc{Josifoski2023,
  author        = {Martin Josifoski and Marija Sakota and Maxime Peyrard and Robert West},
  title         = {Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.04132},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.04132},
}

@InProceedings{HuguetCabot2021,
  author    = {Huguet Cabot, Pere-Llu{\'i}s and Navigli, Roberto},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
  title     = {{REBEL}: Relation Extraction By End-to-end Language generation},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  month     = nov,
  pages     = {2370--2381},
  publisher = {Association for Computational Linguistics},
  abstract  = {Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model{'}s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.},
  doi       = {10.18653/v1/2021.findings-emnlp.204},
  url       = {https://aclanthology.org/2021.findings-emnlp.204/},
}

@Misc{Anthropic2024,
  author = {Anthropic},
  month  = {December},
  note   = {Accessed: 2025-06-03},
  title  = {Building Effective Agents},
  year   = {2024},
  url    = {https://www.anthropic.com/engineering/building-effective-agents},
}

@Misc{Schulhoff2025,
  author        = {Sander Schulhoff and Michael Ilie and Nishant Balepur and Konstantine Kahadze and Amanda Liu and Chenglei Si and Yinheng Li and Aayush Gupta and HyoJung Han and Sevien Schulhoff and Pranav Sandeep Dulepet and Saurav Vidyadhara and Dayeon Ki and Sweta Agrawal and Chau Pham and Gerson Kroiz and Feileen Li and Hudson Tao and Ashay Srivastava and Hevander Da Costa and Saloni Gupta and Megan L. Rogers and Inna Goncearenco and Giuseppe Sarli and Igor Galynker and Denis Peskoff and Marine Carpuat and Jules White and Shyamal Anadkat and Alexander Hoyle and Philip Resnik},
  title         = {The Prompt Report: A Systematic Survey of Prompt Engineering Techniques},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2406.06608},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.06608},
}

@Comment{jabref-meta: databaseType:bibtex;}
