@article{Shi2024,
  author    = {Shi, Yuchen and Jiang, Guochao and Qiu, Tian and Yang, Deqing},
  title     = {AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction},
  year      = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2409.01854},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv}
}

@article{Josifoski2021,
  author        = {Josifoski, Martin and De Cao, Nicola and Peyrard, Maxime and Petroni, Fabio and West, Robert},
  title         = {GenIE: Generative Information Extraction},
  year          = {2021},
  month         = dec,
  abstract      = {Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce GenIE (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. GenIE naturally exploits the language knowledge from the pre-trained transformer by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that GenIE is state-of-the-art on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction. Code, data and models available at https://github.com/epfl-dlab/GenIE.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2112.08340},
  eprint        = {2112.08340},
  file          = {:Josifoski2021 - GenIE_ Generative Information Extraction.pdf:PDF:http\://arxiv.org/pdf/2112.08340v3},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@article{Wadhwa2023,
  author        = {Somin Wadhwa and Silvio Amir and Byron C. Wallace},
  journal       = {CoRR},
  title         = {Revisiting Relation Extraction in the era of Large Language Models},
  year          = {2023},
  volume        = {abs/2305.05003},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2305-05003.bib},
  doi           = {10.48550/ARXIV.2305.05003},
  eprint        = {2305.05003}
}

@article{Xia2024,
  author        = {Yuchen Xia and Jiho Kim and Yuhan Chen and Haojie Ye and Souvik Kundu and Cong Hao and Nishil Talati},
  journal       = {CoRR},
  title         = {Understanding the Performance and Estimating the Cost of {LLM} Fine-Tuning},
  year          = {2024},
  volume        = {abs/2408.04693},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2408-04693.bib},
  doi           = {10.48550/ARXIV.2408.04693},
  eprint        = {2408.04693}
}

@article{Chen2024,
  author    = {Chen, Zhenbin and Li, Zhixin and Zeng, Yufei and Zhang, Canlong and Ma, Huifang},
  journal   = {Expert Systems with Applications},
  title     = {GAP: A novel Generative context-Aware Prompt-tuning method for relation extraction},
  year      = {2024},
  issn      = {0957-4174},
  month     = aug,
  pages     = {123478},
  volume    = {248},
  doi       = {10.1016/j.eswa.2024.123478},
  publisher = {Elsevier BV}
}

@article{Xue2024,
  author        = {Lilong Xue and Dan Zhang and Yuxiao Dong and Jie Tang},
  journal       = {CoRR},
  title         = {AutoRE: Document-Level Relation Extraction with Large Language Models},
  year          = {2024},
  volume        = {abs/2403.14888},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2403-14888.bib},
  doi           = {10.48550/ARXIV.2403.14888},
  eprint        = {2403.14888}
}

@article{Levi2024,
  author        = {Elad Levi and Eli Brosh and Matan Friedmann},
  journal       = {CoRR},
  title         = {Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases},
  year          = {2024},
  volume        = {abs/2402.03099},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2402-03099.bib},
  doi           = {10.48550/ARXIV.2402.03099},
  eprint        = {2402.03099}
}

@misc{LangChain,
  author    = {{LangChain Inc.}},
  title     = {Multi-agent Systems},
  timestamp = {2025-02-10},
  url       = {https://langchain-ai.github.io/langgraph/concepts/multi_agent/}
}

@inbook{Moeller2024,
  author    = {Möller, Cedric and Usbeck, Ricardo},
  pages     = {23-40},
  publisher = {Springer Nature Switzerland},
  title     = {DISCIE–Discriminative Closed Information Extraction},
  year      = {2024},
  month     = {11},
  booktitle = {Lecture Notes in Computer Science},
  date      = {2024-11-27},
  day       = {27},
  doi       = {10.1007/978-3-031-77850-6_2}
}

@misc{Josifoski2023,
  author        = {Martin Josifoski and Marija Sakota and Maxime Peyrard and Robert West},
  title         = {Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.04132},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.04132}
}

@inproceedings{HuguetCabot2021,
  author    = {Huguet Cabot, Pere-Llu{\'i}s and Navigli, Roberto},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
  title     = {{REBEL}: Relation Extraction By End-to-end Language generation},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  month     = nov,
  pages     = {2370--2381},
  publisher = {Association for Computational Linguistics},
  abstract  = {Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model{'}s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.},
  doi       = {10.18653/v1/2021.findings-emnlp.204},
  url       = {https://aclanthology.org/2021.findings-emnlp.204/}
}

@misc{Anthropic2024,
  author = {Anthropic},
  month  = {December},
  note   = {Accessed: 2025-06-03},
  title  = {Building Effective Agents},
  year   = {2024},
  url    = {https://www.anthropic.com/engineering/building-effective-agents}
}

@article{Vrandecic2014,
  author    = {Vrande{\v{c}}i{\'c}, Denny and Kr{\"o}tzsch, Markus},
  journal   = {Communications of the ACM},
  title     = {Wikidata: a free collaborative knowledgebase},
  year      = {2014},
  number    = {10},
  pages     = {78--85},
  volume    = {57},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{Auer2007,
  author    = {Auer, S{\"o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
  booktitle = {The Semantic Web},
  title     = {DBpedia: A Nucleus for a Web of Open Data},
  year      = {2007},
  address   = {Berlin, Heidelberg},
  editor    = {Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudr{\'e}-Mauroux, Philippe},
  pages     = {722--735},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
  isbn      = {978-3-540-76298-0}
}

@misc{Peng2023,
  author        = {Ciyuan Peng and Feng Xia and Mehdi Naseriparsa and Francesco Osborne},
  title         = {Knowledge Graphs: Opportunities and Challenges},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.13948},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2303.13948}
}

@article{Ji2022,
  author    = {Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  title     = {A Survey on Knowledge Graphs: Representation, Acquisition, and Applications},
  year      = {2022},
  issn      = {2162-2388},
  month     = feb,
  number    = {2},
  pages     = {494–514},
  volume    = {33},
  doi       = {10.1109/tnnls.2021.3070843},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  url       = {http://dx.doi.org/10.1109/TNNLS.2021.3070843}
}

@article{Paulheim2016,
  author   = {Heiko Paulheim},
  journal  = {Semantic Web},
  title    = {Knowledge graph refinement: A survey of approaches and evaluation methods},
  year     = {2016},
  number   = {3},
  pages    = {489-508},
  volume   = {8},
  abstract = {In the recent years, different Web knowledge graphs, both free and commercial, have been created. While Google coined the term â€œKnowledge Graphâ€ in 2012, there are also a few openly available knowledge graphs, with DBpedia, YAGO, and Freebase being among the most prominent ones. Those graphs are often constructed from semi-structured knowledge, such as Wikipedia, or harvested from the web with a combination of statistical and linguistic methods. The result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness. In order to further increase the utility of such knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information. In this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used.},
  doi      = {10.3233/SW-160218},
  eprint   = {https://journals.sagepub.com/doi/pdf/10.3233/SW-160218},
  url      = {https://journals.sagepub.com/doi/abs/10.3233/SW-160218}
}

@inbook{GomezPerez2017,
  author    = {Gomez-Perez, Jose and Pan, Jeff and Vetere, Guido and Wu, Honghan},
  pages     = {1-14},
  publisher = {Springer International Publishing},
  title     = {Enterprise Knowledge Graph: An Introduction},
  year      = {2017},
  booktitle = {Exploiting Linked Data and Knowledge Graphs in Large Organisations},
  date      = {2017},
  doi       = {10.1007/978-3-319-45654-6_1}
}

@article{Tomaszuk2020,
  author    = {Tomaszuk, Dominik and Hyland-Wood, David},
  journal   = {Symmetry},
  title     = {RDF 1.1: Knowledge Representation and Data Integration Language for the Web},
  year      = {2020},
  issn      = {2073-8994},
  month     = jan,
  number    = {1},
  pages     = {84},
  volume    = {12},
  doi       = {10.3390/sym12010084},
  publisher = {MDPI AG},
  url       = {http://dx.doi.org/10.3390/sym12010084}
}

@inproceedings{Stefani2018,
  author    = {Eleni Stefani and Klesti Hoxha},
  booktitle = {Proceedings of the 3rd International Conference on Recent Trends and Applications in Computer Science and Information Technology (RTA‑CSIT 2018)},
  title     = {Implementing Triple‑Stores using NoSQL Databases},
  year      = {2018},
  address   = {Tirana, Albania},
  editor    = {Endrit Xhina and Klesti Hoxha},
  month     = nov,
  publisher = {CEUR‑WS.org},
  series    = {CEUR Workshop Proceedings},
  volume    = {2280},
  day       = {23--24},
  url       = {https://ceur-ws.org/Vol-2280/paper-13.pdf}
}

@misc{ASF2025,
  author       = {{Apache Software Foundation}},
  howpublished = {\url{https://jena.apache.org/}},
  note         = {Zugriff im Juni 2025; empfohlen wird, Versionsnummer und Zugriffsdatum bei Reproduzierbarkeit hinzuzufügen},
  title        = {Apache Jena},
  year         = {2025}
}

@article{Chokshi2022,
  author  = {Chokshi, HJ and Panchal, R},
  journal = {International Journal of Innovative Research in Computer Science \& Technology},
  title   = {Using apache Jena Fuseki server for execution of SPARQL queries in job search ontology using semantic technology},
  year    = {2022},
  number  = {2},
  pages   = {497--504},
  volume  = {10}
}

@inproceedings{Erxleben2014,
  author    = {Erxleben, Fredo and G{\"u}nther, Michael and Kr{\"o}tzsch, Markus and Mendez, Julian and Vrande{\v{c}}i{\'{c}}, Denny},
  booktitle = {The Semantic Web -- ISWC 2014},
  title     = {Introducing Wikidata to the Linked Data Web},
  year      = {2014},
  address   = {Cham},
  editor    = {Mika, Peter and Tudorache, Tania and Bernstein, Abraham and Welty, Chris and Knoblock, Craig and Vrande{\v{c}}i{\'{c}}, Denny and Groth, Paul and Noy, Natasha and Janowicz, Krzysztof and Goble, Carole},
  pages     = {50--65},
  publisher = {Springer International Publishing},
  abstract  = {Wikidata is the central data management platform of Wikipedia. By the efforts of thousands of volunteers, the project has produced a large, open knowledge base with many interesting applications. The data is highly interlinked and connected to many other datasets, but it is also very rich, complex, and not available in RDF. To address this issue, we introduce new RDF exports that connect Wikidata to the Linked Data Web. We explain the data model of Wikidata and discuss its encoding in RDF. Moreover, we introduce several partial exports that provide more selective or simplified views on the data. This includes a class hierarchy and several other types of ontological axioms that we extract from the site. All datasets we discuss here are freely available online and updated regularly.},
  isbn      = {978-3-319-11964-9}
}

@misc{Wikidata2025,
  author       = {{Wikidata}},
  howpublished = {\url{https://www.wikidata.org/wiki/Help:Qualifiers}},
  note         = {Zugegriffen: 10. Juni 2025},
  title        = {{Help:Qualifiers}},
  year         = {2025}
}

@Misc{Meta2024,
  author       = {{Meta}},
  howpublished = {\url{https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md}},
  note         = {Zugegriffen: 10. Juni 2025},
  title        = {{Llama 3.3 Model Card}},
  year         = {2024},
}

@misc{Radford2018,
  author       = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  howpublished = {\url{https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf}},
  note         = {OpenAI Technical Report},
  title        = {Improving Language Understanding by Generative Pre-Training},
  year         = {2018},
  publisher    = {OpenAI}
}

@misc{Sennrich2016,
  author        = {Rico Sennrich and Barry Haddow and Alexandra Birch},
  title         = {Neural Machine Translation of Rare Words with Subword Units},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1508.07909},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1508.07909}
}

@misc{OpenAI2023,
  author       = {{OpenAI}},
  howpublished = {\url{https://openai.com/index/chatgpt/}},
  note         = {Einführende Webseite},
  title        = {Introducing {ChatGPT}},
  year         = {2023}
}

@misc{Peeperkorn2024,
  author        = {Max Peeperkorn and Tom Kouwenhoven and Dan Brown and Anna Jordanous},
  title         = {Is Temperature the Creativity Parameter of Large Language Models?},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2405.00492},
  file          = {:Peeperkorn2024 - Is Temperature the Creativity Parameter of Large Language Models_.ris:ris},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2405.00492}
}

@misc{Kapoor2024,
  author        = {Sayash Kapoor and Benedikt Stroebl and Zachary S. Siegel and Nitya Nadgir and Arvind Narayanan},
  title         = {AI Agents That Matter},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2407.01502},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.01502}
}

@inproceedings{Chen2024a,
  author    = {Chen, Jianlyu and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
  title     = {{M}3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation},
  year      = {2024},
  address   = {Bangkok, Thailand},
  editor    = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  month     = aug,
  pages     = {2318--2335},
  publisher = {Association for Computational Linguistics},
  abstract  = {In this paper, we introduce a new embedding model called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It provides a uniform support for the semantic retrieval of more than 100 working languages. It can simultaneously accomplish the three common retrieval functionalities: dense retrieval, multi-vector retrieval, and sparse retrieval. Besides, it is also capable of processing inputs of different granularities, spanning from short sentences to long documents of up to 8,192 tokens. The effective training of M3-Embedding presents a series of technical contributions. Notably, we propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strategy, which enables a large batch size and high training throughput to improve the discriminativeness of embeddings. M3-Embedding exhibits a superior performance in our experiment, leading to new state-of-the-art results on multilingual, cross-lingual, and long-document retrieval benchmarks.},
  doi       = {10.18653/v1/2024.findings-acl.137},
  url       = {https://aclanthology.org/2024.findings-acl.137/}
}

@misc{Park2023,
  author        = {Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
  title         = {Generative Agents: Interactive Simulacra of Human Behavior},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.03442},
  file          = {:Park2023 - Generative Agents_ Interactive Simulacra of Human Behavior.ris:ris},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2304.03442}
}

@article{Dorri2018,
  author   = {Dorri, Ali and Kanhere, Salil S. and Jurdak, Raja},
  journal  = {IEEE Access},
  title    = {Multi-Agent Systems: A Survey},
  year     = {2018},
  pages    = {28573-28593},
  volume   = {6},
  doi      = {10.1109/ACCESS.2018.2831228},
  keywords = {Task analysis;Multi-agent systems;Computer science;Security;Australia;Computational modeling;Decision making;Multi-agent systems;survey;MAS applications;challenges}
}

@misc{Sapkota2025,
  author        = {Ranjan Sapkota and Konstantinos I. Roumeliotis and Manoj Karkee},
  title         = {AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2505.10468},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2505.10468}
}

@misc{Yao2023,
  author        = {Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
  title         = {ReAct: Synergizing Reasoning and Acting in Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2210.03629},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.03629}
}

@misc{LangChain2025,
  author       = {{LangChain Inc.}},
  howpublished = {\url{https://langchain-ai.github.io/langgraph/concepts/why-langgraph/}},
  month        = {June},
  note         = {Accessed: 2025-06-16},
  title        = {Why LangGraph?},
  year         = {2025}
}

@misc{LangChain2025a,
  author       = {{LangChain Inc.}},
  howpublished = {\url{https://langchain-ai.github.io/langgraph/agents/overview/}},
  month        = {June},
  note         = {Online-Dokumentation; abgerufen am 16. Juni 2025},
  title        = {Agent development with {LangGraph}},
  year         = {2025}
}

@misc{LangChain2025b,
  author       = {{LangChain Inc.}},
  howpublished = {\url{https://langchain-ai.github.io/langgraph/concepts/multi_agent/}},
  month        = {June},
  note         = {Online-Dokumentation; abgerufen am 16. Juni 2025},
  title        = {Multi-agent systems},
  year         = {2025}
}

@misc{LangChain2025c,
  author       = {{LangChain Inc.}},
  howpublished = {\url{https://langchain-ai.github.io/langgraph/how-tos/multi_agent/#build-a-multi-agent-system}},
  month        = {June},
  note         = {Online-Dokumentation; abgerufen am 16. Juni 2025},
  title        = {Build multi-agent systems},
  year         = {2025}
}

@misc{Hadfield2025,
  author       = {Jeremy Hadfield and Barry Zhang and Kenneth Lien and Florian Scholz and Jeremy Fox and Daniel Ford},
  howpublished = {\url{https://www.anthropic.com/engineering/built-multi-agent-research-system}},
  month        = {June},
  note         = {Anthropic Engineering Blog; abgerufen am 17. Juni 2025},
  title        = {How we built our multi-agent research system},
  year         = {2025},
  day          = {13}
}

@misc{Reimers2019,
  author        = {Nils Reimers and Iryna Gurevych},
  title         = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.10084},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1908.10084}
}

@article{Singhal2001,
  author  = {Singhal, Amit and others},
  journal = {IEEE Data Eng. Bull.},
  title   = {Modern information retrieval: A brief overview},
  year    = {2001},
  number  = {4},
  pages   = {35--43},
  volume  = {24}
}

@inproceedings{Rusher2003,
  author    = {Jack Rusher},
  booktitle = {Position Paper, SWAD‑Europe Workshop on Semantic Web Storage and Retrieval},
  title     = {Triple Store},
  year      = {2003},
  address   = {Vrije Universiteit, Amsterdam, Netherlands},
  month     = nov,
  note      = {Position Paper from Radar Networks},
  publisher = {W3C},
  eventdate = {2003-11-13/2003-11-14},
  url       = {https://www.w3.org/2001/sw/Europe/events/20031113-storage/positions/rusher.html}
}

@article{Carroll2004,
  author  = {Carroll, Jeremy and Reynolds, Dave and Dickinson, Ian and Seaborne, Andy and Dollin, Chris and Wilkinson, Kevin},
  journal = {WWW Alt. '04: Proceedings of the 13th international World Wide Web conference on Alternate track papers \& posters},
  title   = {Jena: Implementing the Semantic Web Recommendations},
  year    = {2004},
  month   = {05},
  doi     = {10.1145/1013367.1013381}
}

@misc{OpenAI2025,
  author       = {{OpenAI}},
  howpublished = {\url{https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf}},
  month        = apr,
  note         = {Whitepaper, OpenAI},
  title        = {A Practical Guide to Building Agents},
  year         = {2025}
}

@article{Pan2024,
  author   = {Pan, James Jie and Wang, Jianguo and Li, Guoliang},
  journal  = {The VLDB Journal},
  title    = {Survey of vector database management systems},
  year     = {2024},
  issn     = {0949-877X},
  number   = {5},
  pages    = {1591--1615},
  volume   = {33},
  abstract = {There are now over 20 commercial vector database management systems (VDBMSs), all produced within the past five years. But embedding-based retrieval has been studied for over ten years, and similarity search a staggering half century and more. Driving this shift from algorithms to systems are new data intensive applications, notably large language models, that demand vast stores of unstructured data coupled with reliable, secure, fast, and scalable query processing capability. A variety of new data management techniques now exist for addressing these needs, however there is no comprehensive survey to thoroughly review these techniques and systems. We start by identifying five main obstacles to vector data management, namely the ambiguity of semantic similarity, large size of vectors, high cost of similarity comparison, lack of structural properties that can be used for indexing, and difficulty of efficiently answering "hybrid" queries that jointly search both attributes and vectors. Overcoming these obstacles has led to new approaches to query processing, storage and indexing, and query optimization and execution. For query processing, a variety of similarity scores and query types are now well understood; for storage and indexing, techniques include vector compression, namely quantization, and partitioning techniques based on randomization, learned partitioning, and "navigable" partitioning; for query optimization and execution, we describe new operators for hybrid queries, as well as techniques for plan enumeration, plan selection, distributed query processing, data manipulation queries, and hardware accelerated query execution. These techniques lead to a variety of VDBMSs across a spectrum of design and runtime characteristics, including "native" systems that are specialized for vectors and "extended" systems that incorporate vector capabilities into existing systems. We then discuss benchmarks, and finally outline research challenges and point the direction for future work.},
  doi      = {10.1007/s00778-024-00864-x},
  refid    = {Pan2024},
  url      = {https://doi.org/10.1007/s00778-024-00864-x}
}

@article{Etzioni2008,
  author    = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S},
  journal   = {Communications of the ACM},
  title     = {Open information extraction from the web},
  year      = {2008},
  number    = {12},
  pages     = {68--74},
  volume    = {51},
  publisher = {ACM New York, NY, USA}
}

@misc{Kamp2023,
  author        = {Serafina Kamp and Morteza Fayazi and Zineb Benameur-El and Shuyan Yu and Ronald Dreslinski},
  title         = {Open Information Extraction: A Review of Baseline Techniques, Approaches, and Applications},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2310.11644},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2310.11644}
}

@article{Radford2019,
  author  = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal = {OpenAI blog},
  title   = {Language models are unsupervised multitask learners},
  year    = {2019},
  number  = {8},
  pages   = {9},
  volume  = {1}
}

@misc{Sanderson2024,
  author       = {Grant Sanderson},
  howpublished = {3Blue1Brown website},
  month        = apr # {~7},
  note         = {Text adaptation by Justin Sun},
  title        = {Visualizing Attention, a Transformer's Heart},
  year         = {2024},
  lastchecked  = {2025-06-24},
  url          = {https://www.3blue1brown.com/lessons/attention}
}

@Misc{MetaAI2025,
  author       = {{Meta AI}},
  howpublished = {\url{https://ai.meta.com/blog/llama-4-multimodal-intelligence/}},
  note         = {Accessed: 2025-06-25},
  title        = {The Llama 4 herd: The beginning of a new era of natively multimodal intelligence},
  year         = {2025},
}

@misc{CCF2025,
  author       = {{Common Crawl Foundation}},
  howpublished = {\url{https://commoncrawl.org/faq}},
  note         = {Accessed: 2025-06-25},
  title        = {Frequently Asked Questions --- Common Crawl},
  year         = {2025}
}

@misc{LangChain2025d,
  author       = {{LangChain}},
  howpublished = {\url{https://python.langchain.com/docs/introduction/}},
  note         = {Accessed on 25 June 2025},
  title        = {Introduction},
  year         = {2025}
}

@misc{Qdrant2025,
  author       = {{Qdrant Inc.}},
  howpublished = {\url{https://qdrant.tech/documentation/overview/}},
  month        = {June},
  note         = {Online-Dokumentation; abgerufen am 17. Juni 2025},
  title        = {What is Qdrant?},
  year         = {2025}
}

@techreport{Wiesinger2025,
  author = {Julia Wiesinger and Patrick Marlow and Vladimir Vuskovic},
  title  = {Agents},
  year   = {2025},
  month  = {April},
  note   = {Whitepaper; veröffentlicht auf Kaggle},
  school = {Kaggle},
  url    = {https://www.kaggle.com/whitepaper-agents}
}

@Misc{Han2025,
  author        = {Shanshan Han and Qifan Zhang and Yuhang Yao and Weizhao Jin and Zhaozhuo Xu},
  title         = {LLM Multi-Agent Systems: Challenges and Open Problems},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2402.03578},
  file          = {:Han2025 - LLM Multi Agent Systems_ Challenges and Open Problems.ris:ris},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2402.03578},
}

@Misc{LGFT2025,
  author       = {{{Langfuse GmbH / Finto Technologies Inc.}}},
  howpublished = {\url{https://langfuse.com/docs}},
  note         = {Last viewed June 27, 2025; published approximately June 13, 2025},
  title        = {Langfuse Documentation},
  year         = {2025},
  organization = {Langfuse GmbH / Finto Technologies Inc.},
  url          = {https://langfuse.com/docs},
}

@Online{Leys2022,
  author       = {Mathias Leys},
  day          = {20},
  month        = jun,
  organization = {ML6team},
  title        = {The Art of Pooling Embeddings},
  url          = {https://blog.ml6.eu/the-art-of-pooling-embeddings-c56575114cf8},
  urldate      = {2025-06-30},
  year         = {2022},
}

@InProceedings{Trisedya2019,
  author    = {Trisedya, Bayu Distiawan and Weikum, Gerhard and Qi, Jianzhong and Zhang, Rui},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  title     = {Neural Relation Extraction for Knowledge Base Enrichment},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/p19-1023},
  url       = {http://dx.doi.org/10.18653/v1/P19-1023},
}

@InProceedings{Angeli2015,
  author    = {Angeli, Gabor and Johnson Premkumar, Melvin Jose and Manning, Christopher D.},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  title     = {Leveraging Linguistic Structure For Open Domain Information Extraction},
  year      = {2015},
  publisher = {Association for Computational Linguistics},
  doi       = {10.3115/v1/p15-1034},
  url       = {http://dx.doi.org/10.3115/v1/P15-1034},
}

@Article{Zhang2022,
  author   = {Zhang, Zhu and Zhan, Shu and Zhang, Haiyan and Li, Xinke},
  journal  = {Journal of Ambient Intelligence and Humanized Computing},
  title    = {Joint model of entity recognition and relation extraction based on artificial neural network},
  year     = {2022},
  issn     = {1868-5145},
  number   = {7},
  pages    = {3503--3511},
  volume   = {13},
  abstract = {Entity and relationship extraction is an important step in building a knowledge base, which is the basis for many artificial intelligence products to be used in life, such as Amazon Echo and Intelligent Search. We propose a new artificial neural network model to identify entities and their relationships without any handcrafted features. The neural network model mainly includes the CNN module for extracting text features and relationship classifications, and a bidirectional LSTM module for obtaining context information of the entity. The context information and entity tags between the entities obtained in the entity identification process are further passed to the CNN module of the relationship classification to improve the effectiveness of the relationship classification and achieve the purpose of joint processing. We conducted experiments on the public datasets CoNLL04 (Conference on Computational Natural Language Learning), ACE04 and ACE05 (Automatic Content Extraction program) to verify the effectiveness of our approach. The method we proposed achieves the state-of-the-art results on entity and relation extraction task.},
  doi      = {10.1007/s12652-020-01949-5},
  refid    = {Zhang2022},
  url      = {https://doi.org/10.1007/s12652-020-01949-5},
}

@Misc{OpenAI2025a,
  author       = {{OpenAI}},
  howpublished = {\url{https://platform.openai.com/docs/deprecations}},
  note         = {Accessed July 1, 2025},
  title        = {Deprecations},
  year         = {2025},
}

@InProceedings{Luan2018,
  author    = {Luan, Yi and He, Luheng and Ostendorf, Mari and Hajishirzi, Hannaneh},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  title     = {Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction},
  year      = {2018},
  address   = {Brussels, Belgium},
  editor    = {Riloff, Ellen and Chiang, David and Hockenmaier, Julia and Tsujii, Jun{'}ichi},
  month     = oct # {-} # nov,
  pages     = {3219--3232},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.},
  doi       = {10.18653/v1/D18-1360},
  url       = {https://aclanthology.org/D18-1360/},
}

@Misc{LangChain2025e,
  author       = {{LangChain Inc.}},
  howpublished = {\url{https://python.langchain.com/docs/concepts/structured_outputs/}},
  note         = {Accessed: 2025-07-02},
  title        = {{Structured Outputs – LangChain Documentation}},
  year         = {2025},
}

@Misc{Frantar2023,
  author        = {Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  title         = {GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2210.17323},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2210.17323},
}

@Misc{ASF2010,
  author       = {{Apache Software Foundation}},
  howpublished = {\url{https://xmlbeans.apache.org/docs/2.4.0/reference/org/apache/xmlbeans/XmlQName.html}},
  note         = {Accessed: 2025-07-10},
  title        = {XmlQName (XMLBeans 2.4.0 Documentation)},
  year         = {2010},
}

@Misc{Xu2025,
  author        = {Ziwei Xu and Sanjay Jain and Mohan Kankanhalli},
  title         = {Hallucination is Inevitable: An Innate Limitation of Large Language Models},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2401.11817},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2401.11817},
}

@Article{Korolov2025,
  author  = {Korolov, Maria},
  journal = {CIO},
  title   = {Knowledge graphs: the missing link in enterprise AI},
  year    = {2025},
  month   = {jan},
  note    = {Contributing writer},
  day     = {29},
  url     = {https://www.cio.com/article/3808569/knowledge-graphs-the-missing-link-in-enterprise-ai.html},
}

@Misc{Chandrasekaran2025,
  author       = {Chandrasekaran, Arun},
  howpublished = {Gartner article},
  month        = {jul},
  note         = {Distinguished VP Analyst at Gartner},
  title        = {The 2025 Hype Cycle for Generative AI Highlights Critical Innovations},
  year         = {2025},
  day          = {29},
  url          = {https://www.gartner.com/en/articles/hype-cycle-for-genai},
}

@Misc{Cabot2023,
  author        = {Pere-Lluís Huguet Cabot and Simone Tedeschi and Axel-Cyrille Ngonga Ngomo and Roberto Navigli},
  title         = {REDFM: a Filtered and Multilingual Relation Extraction Dataset},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2306.09802},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.09802},
}

@Misc{Muennighoff2023,
  author        = {Niklas Muennighoff and Nouamane Tazi and Loïc Magne and Nils Reimers},
  title         = {MTEB: Massive Text Embedding Benchmark},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2210.07316},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.07316},
}

@article{Zhao2024,
  author    = {Zhao, Xiaoyan and Deng, Yang and Yang, Min and Wang, Lingzhi and Zhang, Rui and Cheng, Hong and others},
  journal   = {ACM Computing Surveys},
  title     = {A Comprehensive Survey on Relation Extraction: Recent Advances and New Frontiers},
  year      = {2024},
  issn      = {1557-7341},
  month     = jul,
  number    = {11},
  pages     = {1--39},
  volume    = {56},
  doi       = {10.1145/3674501},
  publisher = {Association for Computing Machinery (ACM)}
}

@misc{Schulhoff2025,
  author        = {Sander Schulhoff and Michael Ilie and Nishant Balepur and Konstantine Kahadze and Amanda Liu and Chenglei Si and others},
  title         = {The Prompt Report: A Systematic Survey of Prompt Engineering Techniques},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2406.06608},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.06608}
}

@inbook{Monti2017,
  author    = {Monti, Marco and Perego, Fernanda and Zhao, Yuting and Vetere, Guido and Gomez-Perez, Jose Manuel and Alexopoulos, Panos and others},
  editor    = {Pan, Jeff Z. and Vetere, Guido and Gomez-Perez, Jose Manuel and Wu, Honghan},
  pages     = {215--236},
  publisher = {Springer International Publishing},
  title     = {Success Stories},
  year      = {2017},
  address   = {Cham},
  isbn      = {978-3-319-45654-6},
  abstract  = {So far, we have introduced different approaches to construct, explore, and exploit knowledge graphs in large organizations.},
  booktitle = {Exploiting Linked Data and Knowledge Graphs in Large Organisations},
  doi       = {10.1007/978-3-319-45654-6_8},
  url       = {https://doi.org/10.1007/978-3-319-45654-6_8}
}

@misc{Vaswani2023,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and others},
  title         = {Attention Is All You Need},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762}
}

@misc{Brown2020,
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and others},
  title         = {Language Models are Few-Shot Learners},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2005.14165},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.14165}
}

@misc{Grattafiori2024,
  author        = {Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and others},
  title         = {The Llama 3 Herd of Models},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2407.21783},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2407.21783}
}

@misc{Chiang2024,
  author        = {Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and others},
  title         = {Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2403.04132},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2403.04132}
}

@misc{Ouyang2022,
  author        = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and others},
  title         = {Training language models to follow instructions with human feedback},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2203.02155},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.02155}
}

@misc{Wang2024,
  author        = {Yubo Wang and Xueguang Ma and Ge Zhang and Yuansheng Ni and Abhranil Chandra and Shiguang Guo and others},
  title         = {MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2406.01574},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.01574}
}

@misc{Gao2024,
  author        = {Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and others},
  title         = {Retrieval-Augmented Generation for Large Language Models: A Survey},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2312.10997},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2312.10997}
}

@misc{Kwon2023,
  author        = {Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and others},
  title         = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2309.06180},
  file          = {:Kwon2023 - Efficient Memory Management for Large Language Model Serving with PagedAttention.ris:ris},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2309.06180}
}

@misc{Lin2024,
  author        = {Ji Lin and Jiaming Tang and Haotian Tang and Shang Yang and Wei-Ming Chen and Wei-Chen Wang and others},
  title         = {AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2306.00978},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.00978}
}

@misc{DeepSeekAI2025,
  author        = {DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and others},
  title         = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2501.12948},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2501.12948}
}

@misc{Agrawal2025,
  author        = {Lakshya A Agrawal and Shangyin Tan and Dilara Soylu and Noah Ziems and Rishi Khare and Krista Opsahl-Ong and others},
  title         = {GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2507.19457},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2507.19457}
}

@misc{Edge2025,
  author        = {Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and others},
  title         = {From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2404.16130},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.16130}
}

@Misc{Barnett2024,
  author        = {Scott Barnett and Stefanus Kurniawan and Srikanth Thudumu and Zach Brannelly and Mohamed Abdelrazek},
  title         = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2401.05856},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2401.05856},
}

@Misc{KimiTeam2025,
  author        = {{Kimi Team} and Yifan Bai and Yiping Bao and Guanduo Chen and Jiahao Chen and Ningxin Chen and others},
  title         = {Kimi K2: Open Agentic Intelligence},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2507.20534},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2507.20534},
}

@misc{Team2025,
  author        = {{Gemma Team} and Aishwarya Kamath and Johan Ferret and Shreya Pathak and Nino Vieillard and Ramona Merhej and others},
  title         = {Gemma 3 Technical Report},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2503.19786},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2503.19786}
}

@TechReport{Prudhommeaux2008,
  author = {Prud'hommeaux, Eric and Seaborne, Andy},
  title  = {{SPARQL} Query Language for {RDF}},
  year   = {2008},
  month  = {January},
  note   = {W3C Recommendation, 15 January 2008},
  type   = {W3C Recommendation},
  school = {World Wide Web Consortium},
  url    = {https://www.w3.org/TR/rdf-sparql-query/},
}

@inbook{VillazonTerrazas2017,
  author    = {Villazon-Terrazas, Boris and Garcia-Santa, Nuria and Ren, Yuan and others},
  editor    = {Pan, Jeff Z. and Vetere, Guido and Gomez-Perez, Jose Manuel and Wu, Honghan},
  pages     = {17--55},
  publisher = {Springer International Publishing},
  title     = {Knowledge Graph Foundations},
  year      = {2017},
  address   = {Cham},
  isbn      = {978-3-319-45654-6},
  abstract  = {This chapter presents a high-level overview of the foundations of Knowledge Graphs.},
  booktitle = {Exploiting Linked Data and Knowledge Graphs in Large Organisations},
  doi       = {10.1007/978-3-319-45654-6_2},
  url       = {https://doi.org/10.1007/978-3-319-45654-6_2},
  note      = {Chapter 2 — with coauthors: Alessandro Faraotti, Honghan Wu, Yuting Zhao}
}

@inbook{VillazonTerrazas2017a,
  author    = {Villazon-Terrazas, Boris and Garcia-Santa, Nuria and Ren, Yuan and others},
  editor    = {Pan, Jeff Z. and Vetere, Guido and Gomez-Perez, Jose Manuel and Wu, Honghan},
  pages     = {87--116},
  publisher = {Springer International Publishing},
  title     = {Construction of Enterprise Knowledge Graphs (I)},
  year      = {2017},
  address   = {Cham},
  isbn      = {978-3-319-45654-6},
  abstract  = {In the previous chapters, we have shown the three-layer architecture of Knowledge Graph for Organizations. The very first question we are facing is how to build the Knowledge Graphs. From now on, we will use two chapters to introduce the technologies for the Acquisition and Integration Layer.},
  booktitle = {Exploiting Linked Data and Knowledge Graphs in Large Organisations},
  doi       = {10.1007/978-3-319-45654-6_4},
  url       = {https://doi.org/10.1007/978-3-319-45654-6_4},
  note      = {Chapter 4 — with coauthors: Kavitha Srinivas, Mariano Rodriguez-Muro, Panos Alexopoulos, Jeff Z. Pan}
}

@Misc{Hsieh2024,
  author        = {Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Yang Zhang and Boris Ginsburg},
  title         = {RULER: What's the Real Context Size of Your Long-Context Language Models?},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2404.06654},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.06654},
}

@InBook{Gayo2018,
  author    = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
  pages     = {9--26},
  publisher = {Springer International Publishing},
  title     = {The RDF Ecosystem},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-031-79478-0},
  abstract  = {This chapter includes a short overview of the RDF data model and the Turtle notation, as well as some technologies like SPARQL, RDF Schema, and OWL that form part of the RDF ecosystem.},
  booktitle = {Validating RDF Data},
  doi       = {10.1007/978-3-031-79478-0_2},
  url       = {https://doi.org/10.1007/978-3-031-79478-0_2},
}

@Misc{Abrahamsson2017,
  author        = {Pekka Abrahamsson and Outi Salo and Jussi Ronkainen and Juhani Warsta},
  title         = {Agile Software Development Methods: Review and Analysis},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1709.08439},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/1709.08439},
}

@Comment{jabref-meta: databaseType:bibtex;}
