% Do not change document class, margins, fonts, etc.
\documentclass[a4paper,oneside,bibliography=totoc]{scrbook}

% some useful packages (add more as needed)
\usepackage{scrhack}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{csquotes}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{algorithm}
\counterwithin{algorithm}{chapter}
\usepackage{algorithmic}
\usepackage{csquotes}
\renewcommand{\algorithmiccomment}[1]{\hfill\textit{// #1}}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks,citecolor=Green]{hyperref}
\usepackage{lipsum}
\usepackage[printonlyused]{acronym}

% chicago citation style
\usepackage{natbib}
\bibliographystyle{chicagoa}
\setcitestyle{authoryear,round,semicolon,aysep={},yysep={,}} \let\cite\citep

% example enviroments (add more as needed)
\newtheorem{definition}{Definition} \newtheorem{proposition}{Proposition}

% Definition einer Turtle-Sprache
\lstdefinelanguage{Turtle}{
  morekeywords={@prefix,@base,a},
  morekeywords=[2]{ex,exp,rdfs},
  morestring=[b]",
  morestring=[b]',
  sensitive=true,
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue},
  keywordstyle=[2]\color{magenta},
  commentstyle=\color{gray}\itshape,
  stringstyle=\color{OliveGreen},
  columns=fullflexible,
  breaklines=true,
  breakatwhitespace=false,
  literate={:}{{{\color{orange}:}}}1,
}

% Definition einer SPARQL-Sprache
\lstdefinelanguage{SPARQL}{
  morekeywords={@prefix,@base,a,SELECT,WHERE},
  morekeywords=[2]{ex,exp,rdfs},
  morestring=[b]",
  morestring=[b]',
  sensitive=true,
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue},
  keywordstyle=[2]\color{magenta},
  commentstyle=\color{gray}\itshape,
  stringstyle=\color{OliveGreen},
  columns=fullflexible,
  breaklines=true,
  breakatwhitespace=false,
  literate={:}{{{\color{orange}:}}}1,
}

% Globales Styling für alle Listings
\lstset{
  language=Turtle,
  frame=single,
  numbers=left,
  numberstyle=\tiny\color{gray},
  numbersep=5pt,
  tabsize=2,
  captionpos=b,
  basicstyle=\small\ttfamily,
}

\begin{document}

\frontmatter
\subject{Master Thesis}
\title{CIExMAS: Closed Information Extraction using a Multi-Agent-System}
\author{Max Lautenbach\\
  (matriculation number 1980683)}
\date{18.08.2025}
\publishers{{\small Submitted to}\\
  Data and Web Science Group\\
  Dr.\ Sven Hertling\\
  University of Mannheim\\}
\maketitle

\chapter{Abstract}

Closed information extraction has so far relied mainly on fine-tuned transformer models that require large training datasets. However, advances in large language models and agent-based artificial intelligence have not yet been explored in this context. In this work, we introduce CIExMAS, a collection of modular architectures based on multi-agent systems for closed information extraction without the need for fine-tuning. The best architecture comprises specialized agents for triple extraction, uniform resource identifier mapping, and validation, supported by tools for integration with knowledge graphs. CIExMAS is designed as an exploratory framework that tests a broad range of architectural setups to evaluate the general feasibility of multi-agent systems in this domain. In our evaluation, CIExMAS achieved up to 80\% of the performance of current state-of-the-art models—despite requiring no supervised training. This result highlights the effectiveness of agent-based approaches in closed information extraction and points to their potential as flexible, scalable, and lightweight alternatives. As an initial study in this direction, CIExMAS lays the foundation for further research at the intersection of agent-based artificial intelligence and closed information extraction.

\begingroup%
\hypersetup{hidelinks}%
\tableofcontents%
\endgroup

\begingroup%
\hypersetup{hidelinks}%
\listoffigures%
\addcontentsline{toc}{chapter}{List of Figures}
\endgroup

\begingroup%
\hypersetup{hidelinks}%
\listoftables%
\addcontentsline{toc}{chapter}{List of Tables}
\endgroup

\chapter{List of Abbreviations}
\begin{acronym}
  \acro{AI}{Artificial Intelligence}
  \acro{CoT}{Chain of Thought}
  \acro{CRM}{Customer Relationship Management}
  \acro{DBMS}{Database Management System}
  \acro{GPT}{Generative Pre-trained Transformer}
  \acro{ICL}{In-Context Learning}
  \acro{IE}{Information Extraction}
  \acro{KG}{Knowledge Graph}
  \acro{LLM}{Large Language Model}
  \acro{LLaMA}{Large Language Model Meta AI}
  \acro{LM}{Language Model}
  \acro{MAS}{Multi-Agent System}
  \acro{ML}{Machine Learning}
  \acro{NLP}{Natural Language Processing}
  \acro{OWL}{Web Ontology Language}
  \acro{RAG}{Retrieval Augmented Generation}
  \acro{RDF}{Resource Description Framework}
  \acro{RDFS}{Resource Description Framework Schema}
  \acro{SPARQL}{SPARQL Protocol and RDF Query Language}
  \acro{SSA}{Splitted Supervisor Architecture}
  \acro{SSSA}{Simplified Splitted Supervisor Architecture}
  \acro{URI}{Uniform Resource Identifier}
  \acro{VDBMS}{Vector Database Management System}
  \acro{cIE}{Closed Information Extraction}

\end{acronym}

\mainmatter

\chapter{Introduction}
\label{ch:introduction}

\acp{LM}, and especially modern \acp{LLM}, have significantly improved the ability of machines to understand and generate human language. These models have enabled progress in various downstream tasks ranging from question answering to summarization and reasoning \cite{Brown2020}. However, their static training data limits their ability to incorporate new or domain-specific knowledge — a limitation known as the knowledge cutoff problem. Most \acp{LLM} are trained once on large corpora and as a result, they have no built-in access to information that emerged after the end of their training period and cannot retrieve up-to-date or external knowledge out of the box \cite{Brown2020,Grattafiori2024}.

As a result, there is a growing interest in structured external knowledge sources, especially \acp{KG}, to provide reliable and semantically rich context for generative models \cite{Korolov2025}. \acp{KG} allow information to be represented in a formal, machine-interpretable way, which makes them highly suitable for integration into retrieval-augmented generation systems, question answering pipelines, and reasoning engines \cite{Korolov2025,Paulheim2016}. The increasing use of \ac{LLM}-based applications has therefore renewed attention on \acp{KG} as critical infrastructure for trustworthy and explainable \ac{AI} \cite{Korolov2025}.

At the same time, this demand creates a practical challenge: many enterprise or domain-specific knowledge graphs do not yet exist in structured form. Most relevant knowledge is still locked in unstructured text documents, reports, or communication logs \cite{Korolov2025}. To make this information accessible to downstream applications, it must be transformed into structured representations — ideally in a way that aligns with a predefined ontology or knowledge schema.

This transformation process leads directly to the research field of \ac{cIE}. As a specialized task within the broader area of \ac{IE}, \ac{cIE} focuses on extracting subject–predicate–object triples from text such that all components can be linked to valid entries in a target knowledge graph \cite{Josifoski2021}. This makes \ac{cIE} a crucial enabling technology for automated knowledge graph construction and maintenance.

\section{Motivation and Problem Statement}
\label{sec:motivation}

The automatic extraction of structured information from text is a long-standing goal in natural language processing. This task, generally referred to as \ac{IE}, includes subtasks such as named entity recognition, entity linking, and relation extraction. These components aim to identify real-world entities in text, assign them canonical identifiers, and detect semantic relationships between them \cite{Zhao2024}.

\ac{cIE} is a constrained subtask of \ac{IE}, where the goal is to extract subject–predicate–object triples that exactly match the identifiers and relations of a predefined \ac{KG}. In contrast to open \ac{IE} approaches, where relations may be freely expressed in natural language, \ac{cIE} requires strict alignment with the vocabulary and structure of a target ontology. This constraint makes \ac{cIE} especially relevant for applications that involve structured knowledge integration or automated \ac{KG} construction \cite{Josifoski2021}.

State-of-the-art models such as GenIE and synthIE have shown that \ac{cIE} can be performed with very high accuracy, particularly when the models are fine-tuned on a specific dataset. However, \cite{Josifoski2021,Josifoski2023} demonstrate a crucial limitation: models trained on one dataset (e.g., GenIE) do not generalize well to others (e.g., synthIE), even when the task and \ac{KG} structure remain similar. This lack of generalization highlights a key drawback of current \ac{IE} systems, which often rely on supervised fine-tuning and are closely coupled to a specific domain or knowledge graph.

This tight coupling reduces reusability and makes it difficult to adapt systems to new domains or ontologies without significant retraining. Consequently, researchers are exploring more modular alternatives that promise better generalisation without the need for task-specific fine-tuning \cite{Shi2024}.

\acp{LLM} have demonstrated strong \ac{ICL} capabilities. Rather than encoding knowledge directly into model weights, \acp{LLM} can be guided to perform tasks dynamically using prompts, examples, and external tools \cite{Brown2020}. This opens up the possibility of solving \ac{cIE} through prompting alone, without any task-specific fine-tuning.

At the same time, recent work in agentic AI explores how \acp{LLM} can be organized into multi-agent systems that interact via tool use, planning, and role-based coordination~\cite{OpenAI2025,Anthropic2024,Wiesinger2025}. These systems have shown promise for complex reasoning tasks and dynamic workflows. \citet{Shi2024} further demonstrate that even single-agent architectures can achieve state-of-the-art performance on \ac{IE} tasks.

These developments motivate the hypothesis that multi-agent systems may offer an effective and generalizable approach to \ac{cIE}. Unlike monolithic pipelines or fine-tuned models, multi-agent architectures can decompose the task into modular roles such as entity extraction, URI disambiguation, and triple validation, and combine the flexibility of prompting with external tool access. This is especially relevant when generating \ac{KG}-ready triples, as these often require lookups or validation against the underlying graph structure. Such tool use is increasingly common in modern agentic frameworks \citet{OpenAI2025} and forms the foundation of the CIExMAS architecture proposed in this thesis.

\section{Research Objectives and Questions}
\label{sec:research_questions}

This thesis investigates whether \ac{cIE} can be solved effectively by \ac{LLM}-based multi-agent systems — without relying on model fine-tuning. The central idea is to replace the monolithic, task-specific IE pipelines with distributed, role-based agents that coordinate through a shared plan or workflow. These agents can perform tasks such as entity and relation extraction, URI matching, or validation, using prompting and tool use.

The following research questions guide this investigation:

\begin{itemize}
  \item[\textbf{RQ1}] To what extent can \ac{LLM}-based \acp{MAS} perform closed information extraction on unstructured text?
  \item[\textbf{RQ2}] Which agentic architectures (e.g., single-agent, supervisor-agent, or agent networks) perform best for this task in terms of accuracy and robustness?
\end{itemize}

\section{Methodological Approach}
\label{sec:methodology}

To address these questions, this thesis presents CIExMAS, a Closed Information Extraction Multi-Agent System. CIExMAS was developed through an iterative process that emphasised modularity and extensibility, but followed no rigid pipeline. Rather, agents and prompts were initially tested on a small sample set and improved step by step, using qualitative trace inspection and targeted adjustments. This empirical, trial-and-error driven strategy was followed by evaluation on a larger benchmark subset.

The system was implemented using the LangGraph framework, which provides abstractions for \ac{LLM}-based agent flows and tool orchestration. Multiple configurations were developed and tested, including a single-agent baseline, supervisor-worker hierarchies, and decentralized agent networks. Each setup was designed to extract valid triples from unstructured documents, relying solely on prompt engineering and tool usage—without any model fine-tuning.

To evaluate this agentic approach, pre-trained snapshots of existing comparison models (GenIE and synthIE) were used. Both were run on the same subset of the \textit{synthIE-text} dataset as CIExMAS configurations, enabling a fair comparison. Performance was measured using macro-F1 and entity-level precision, recall, and coverage.

The overall goal was not only to assess absolute performance, but also to evaluate how well such systems generalise and adapt across tasks without retraining. By relying on prompt-guided reasoning and external tools, this approach explores a more flexible paradigm for solving \ac{cIE} with \acp{LLM}.

\section{Contribution of this Thesis}
\label{sec:contribution}

This thesis introduces a novel approach to closed information extraction by proposing a network-based multi-agent system that leverages large language models in combination with external tools. The proposed system incorporates agents specialized in URI retrieval, semantic validation, and transformation of triples from Turtle notation to human-readable labels. It systematically evaluates the performance of multiple architectural patterns, including single-agent baselines, supervisor-worker models, customized pipelines, and decentralized networks.

Furthermore, the work empirically demonstrates the effectiveness of knowledge graph incorporation and tool-supported URI matching for improving extraction quality. It also shows that recent open-source large language models are capable of solving the task of closed information extraction without the need for model fine-tuning. The resulting framework is designed to be both extensible and generalizable, thus laying the groundwork for future research in agentic systems for knowledge-based reasoning and extraction.

\section{Limitations}
\label{sec:limitations}

Despite its promising results, this thesis has several limitations. The evaluation is restricted to a single synthetic benchmark dataset and does not include multilingual scenarios or real-world enterprise data. The primary focus is on validating the functionality and coordination of the multi-agent system; as a result, deeper semantic modeling, ontology alignment, or integration into production-level knowledge graph infrastructure remains outside the scope of this work.

In addition, this work does not explicitly address ethical risks such as knowledge bias or error propagation through incorrectly generated triples. The use of pre-trained \acp{LLM} may introduce unintended biases, and the extraction process lacks mechanisms for ensuring fairness or factual correctness in sensitive domains. These aspects should be carefully considered in downstream applications.

\section{Structure of the Thesis}
\label{sec:structure}

The thesis unfolds over six chapters and one appendix, each building on the previous to guide the reader from basic concepts to empirical evidence and, finally, to broader implications.

Chapter~\ref{ch:background} lays the conceptual groundwork. After introducing essential terminology and formalisms of knowledge graphs (Section~\ref{sec:knowledge_graphs}), it narrows the focus to closed information extraction (Section~\ref{sec:closed_information_extraction}) and the capabilities of modern language models (Section~\ref{sec:language_models}). Subsequent sections explore sentence-level representations for semantic similarity (Section~\ref{sec:sentence_embeddings}), the paradigm of retrieval-augmented generation (Section~\ref{sec:retrieval_augmented_generation}), and the principles of AI agents and multi-agent systems (Sections~\ref{sec:ai_agents}–\ref{sec:multi_agent_systems}). The chapter closes by discussing agent design patterns (Section~\ref{sec:agent_design}) that later inform the CIExMAS architecture.

Building on this foundation, Chapter~\ref{ch:related_work_chapter} surveys prior research. Section~\ref{sec:related_datasets} catalogues publicly available datasets that target entity and relation extraction, while Section~\ref{sec:related_approaches} analyses state-of-the-art approaches—ranging from end-to-end transformer models to pipeline-based systems. Particular attention is paid to generative AI methods and their reported generalisation gaps, an observation that motivates the agentic direction taken in this thesis.

Chapter~\ref{ch:approach} details the proposed solution. Section~\ref{sec:agent_architectures} compares five agent-architecture patterns, including a baseline, several supervisor variants, a ReAct implementation, and a decentralised network. Section~\ref{sec:agent_tools} lists the bespoke tools (URI retrieval, network traversal, semantic validation, and others) required by the agents, whereas Section~\ref{sec:iterative_prompt_engineering} explains the iterative prompt-engineering strategy adopted. Error-handling routines are summarised in Section~\ref{sec:error_incorportion}.

The empirical setup appears in Chapter~\ref{ch:evaluation}. Section~\ref{sec:evaluation_setup} describes the dataset split, competing models and knowledge-graph access rules. Evaluation metrics are justified in Section~\ref{sec:evaluation_metrics}, followed by an overview of experiment groups in Section~\ref{sec:evaluation_overview} and a fine-grained description of nine configuration stages in Section~\ref{sec:evaluation_configurations}. Section~\ref{sec:discussion} discusses the quantitative results, highlighting the influence of architectural choices, tool ablations and language-model variation.

Chapter~\ref{ch:conclusion_outlook} closes the thesis by summarising contributions, acknowledging limitations and sketching three avenues for future research: multilingual extension, domain adaptation and ontology-driven refinement.

Finally, Appendix~A houses supplementary material, including prompt templates, extended result tables and a detailed category-wise performance analysis that supports the claims made in the main text.

\chapter{Background}
\label{ch:background}

This chapter provides the theoretical foundations necessary to understand the core concepts addressed in this work. It begins with an introduction to knowledge graphs (Section~\ref{sec:knowledge_graphs}), which serve as the foundational data structure for this approach. Building on this foundation, Section~\ref{sec:closed_information_extraction} introduces the concept of closed information extraction, which constitutes the central problem addressed in this thesis.

Subsequently, the chapter outlines the theoretical background related to the multi-agent system approach. It first presents the relevant core technologies, including language models, sentence embeddings, and retrieval-augmented generation (Sections~\ref{sec:language_models},~\ref{sec:sentence_embeddings}, and~\ref{sec:retrieval_augmented_generation}). Based on these, the concepts of \ac{AI} agents and multi-agent systems are introduced (Sections~\ref{sec:ai_agents} and~\ref{sec:multi_agent_systems}). The chapter concludes with a discussion of best practices in agent design (Section~\ref{sec:agent_design}).


\section{Knowledge Graphs}
\label{sec:knowledge_graphs}

Knowledge graphs are a concept used to store knowledge in a form that allows machines to retrieve and interpret semantic relationships \cite{GomezPerez2017}. To achieve this, knowledge graphs are modeled as directed graphs, where nodes represent real-world entities and edges define the relationships between these entities \cite{Paulheim2016}. Ontologies specify the types of entities and relationships, and additionally provide logical constraints that govern how instances can be interpreted within a domain \cite{GomezPerez2017,Paulheim2016}. Based on these definitions, the knowledge graph ecosystem can be divided into three fundamental building blocks: knowledge graph construction, storage, and consumption \cite{GomezPerez2017}.

The construction of knowledge graphs involves specification, modeling, and data lifting. In the specification phase, the requirements of the knowledge graph are defined, followed by the creation of an ontology. Subsequently, the data sources that will provide the content of the knowledge graph must be processed \cite{VillazonTerrazas2017a}.

Knowledge graphs are typically represented using \ac{RDF}, the standard model for data interchange in the context of knowledge graphs \cite{VillazonTerrazas2017}. Therefore, it is necessary to transform the original data sources into the \ac{RDF} format \cite{VillazonTerrazas2017a}. RDF is composed of triples, where each triple describes a relationship and consists of three parts: a start node, an edge, and a target node. All components of a triple must be either a resource identifier, a blank node, or a literal. In the context of this work, the resource identifiers used are \acp{URI}, such as \textit{\url{http://example.org/entity/Angela_Merkel}}. Consequently, the term \ac{URI} will be used consistently throughout this work, unless referring explicitly to blank nodes or literals. Blank nodes are used when a resource cannot be explicitly specified. This applies in cases where the triple describes concepts such as \textit{someone} or \textit{something}. Literals represent simple values such as integers or strings \cite{VillazonTerrazas2017}.

Each triple can also be interpreted as a simple English sentence consisting of a subject (start node), predicate (edge), and object (target node). There are standard rules regarding the format of each triple component. Subjects can be either a \ac{URI} or a blank node. Predicates (hereinafter referred to as properties) must be \acp{URI}. Objects may be a \ac{URI}, a blank node, or a literal. RDF, like other semantic web technologies, supports multiple syntactical representations of triples. One widely used format is Turtle \cite{VillazonTerrazas2017}.

Turtle syntax consists of triple statements separated by spaces, tabs, or other whitespace. Each statement ends with a period. \acp{URI} are enclosed in angle brackets, blank nodes are represented with an underscore followed by a colon and an arbitrary name, and literals are enclosed in quotation marks. The Turtle parser may infer the data type, or it can be explicitly specified by the user. The following example illustrates how four RDF triples can be represented using Turtle \cite{Tomaszuk2020}:

\begin{lstlisting}[language=Turtle, caption=Example of a Knowledge Graph in Turtle Format, label=lst:turtle_example, escapechar=@]
@\textcolor{gray}{\# Angela Merkel is member of the CDU.}@
<http://example.org/entity/Angela_Merkel> <http://example.org/property/member_of> <http://example.org/entity/CDU>.

@\textcolor{gray}{\# Angela Merkel is written "Angela Merkel".}@
<http://example.org/entity/Angela_Merkel> <http://www.w3.org/2000/01/rdf-schema#label> "Angela Merkel".

@\textcolor{gray}{\# Angela Merkel is greeted by someone.}@
<http://example.org/entity/Angela_Merkel> <http://example.org/property/greeted_by> _:b1.

@\textcolor{gray}{\# This someone works for Friedrich Merz.}@
_:b1 <http://example.org/property/works_for> <http://example.org/entity/Friedrich_Merz>.
\end{lstlisting}

To simplify Turtle statements, prefixes can be defined. Prefixes correspond to a namespace, which is a common path in a \ac{URI} under which related resources are grouped. A prefix is defined using the \texttt{@prefix} keyword, followed by a name and the corresponding namespace. Using prefixes, the previous example can be rewritten more compactly \cite{Tomaszuk2020}:

\begin{lstlisting}[language=Turtle, caption=Example of a Knowledge Graph in Turtle Format with Prefixes, label=lst:turtle_example]
@prefix ex: <http://example.org/entity/>
@prefix exp: <http://example.org/property/>
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>

ex:Angela_Merkel exp:member_of ex:CDU.
ex:Angela_Merkel rdfs:label "Angela Merkel".
ex:Angela_Merkel exp:greeted_by _:b1.
_:b1 exp:works_for ex:Friedrich_Merz.
\end{lstlisting}

Beyond describing entities and their relationships, Turtle is also used for defining ontologies. Ontologies can be modeled using the \ac{RDFS} or the \ac{OWL}, where OWL extends the expressiveness of RDFS. \ac{RDFS} provides a standardized way to define classes and properties within a knowledge graph. It also allows the specification of semantic constraints, such as class restrictions. One commonly used constraint mechanism is the specification of domains and ranges for properties. Domains and ranges restrict the type of the subject and object, respectively. For example, if the property \texttt{exp:member\_of} is defined with the domain \texttt{ex:human} and the range \texttt{ex:organisation}, then every subject of a triple using this property must be of type \texttt{ex:human}, and every object must be of type \texttt{ex:organisation}. Since \ac{RDFS} has limited expressiveness, \ac{OWL} was developed to allow for additional constructs such as symmetric properties. For instance, defining \texttt{exp:married\_to} as symmetric implies that if A is married to B, then B is also married to A. \ac{OWL} supports a wide variety of constraints and enables the definition of complex rules for both classes and properties \cite{VillazonTerrazas2017}.

Following the construction phase, the next component is knowledge graph storage. This task is handled by so-called triple stores, which are systems designed to persist and retrieve RDF triples. Triple stores serve as the central component that links data construction with data consumption, and they must comply with the \ac{RDF} specification \cite{Rusher2003}. One widely used implementation of a triple store is Apache Jena. Jena provides a comprehensive software stack for storing and querying RDF data. It offers direct API and I/O access in Java and supports all relevant standards, including \ac{RDFS} and \ac{OWL} \cite{Carroll2004}. To enable access via \ac{SPARQL}, the de facto standard query language for RDF data, Apache Jena includes the Fuseki module, which functions as a \ac{SPARQL} endpoint \cite{Chokshi2022}.

\ac{SPARQL} provides a standardized language for both querying and modifying data within an RDF knowledge graph. Its syntax closely resembles Turtle, which facilitates its adoption in RDF-based systems. Among the most commonly used query forms are \texttt{SELECT}, \texttt{ASK}, and \texttt{INSERT}. While \texttt{SELECT} queries are used to retrieve specific data from the graph, \texttt{ASK} queries return a boolean value that indicates whether a given pattern exists. In contrast, \texttt{INSERT} queries are used to add new data into the graph \cite{VillazonTerrazas2017}.

A typical \ac{SPARQL} query begins with the query type, followed by the \texttt{WHERE} clause that specifies the graph pattern to be matched. In \texttt{SELECT} queries, variables are identified by a leading question mark (e.g., \texttt{?organisation}). Similar to Turtle, SPARQL supports the use of prefixes to simplify long \acp{URI}. In addition, queries can include filtering conditions and modifiers such as \texttt{LIMIT} or \texttt{OFFSET} to constrain or paginate the results \cite{VillazonTerrazas2017}. The following example illustrates a query that retrieves all organisations Angela Merkel is a member of:

\pagebreak

\begin{lstlisting}[language=SPARQL, caption=Example of a SPARQL Query, label=lst:turtle_example]
  @prefix ex: <http://example.org/entity/>
  @prefix exp: <http://example.org/property/>
  
  SELECT ?organisation WHERE {
    ex:Angela_Merkel exp:member_of ?organisation
  }
\end{lstlisting}

With the core components of knowledge graphs defined, one practical use case can help illustrate their capabilities and associated challenges. The project HAVAS 18 aimed to monitor start-up activity, tech trends, and tech talent using knowledge graphs. It relied on existing relationships between such entities in social networks to reveal hidden connections and gain deeper insights into the evolution of start-ups and technologies. Since social networks already provide structured relational data, they serve as a valuable data source for such graphs \cite{Monti2017}. However, \citet{Monti2017} also emphasize key challenges such as entity resolution, disambiguation, and processing of unstructured data. These challenges are also central to the present work.

In addition to specific applications, broader initiatives such as Wikidata and DBpedia aim to represent Wikipedia as a knowledge graph. Wikidata was created to serve as a structured, multilingual knowledge base for factual content in Wikipedia. It eliminates redundancy and enables machine-readability of facts. As a community-driven project, it allows users to edit and maintain its content, and it now serves as the central factual backbone of Wikipedia \cite{Vrandecic2014}. In contrast, DBpedia focuses on extracting structured data from Wikipedia using syntactic patterns in MediaWiki. The extracted data is then transformed into \ac{RDF}, making it usable in semantic web applications \cite{Auer2007}.

In conclusion, knowledge graphs provide semantically rich data by combining graph structures with standardized frameworks and languages. Publicly available and large in scale, they offer significant potential for use in a wide range of domains. Nevertheless, practical implementations often face key challenges such as processing unstructured data and resolving ambiguous entities.


\section{Closed Information Extraction}
\label{sec:closed_information_extraction}

Closed information extraction refers to the task of extracting triples from unstructured text, where each component of the triple must correspond to elements within a predefined knowledge graph \cite{Josifoski2021}. This means that the extracted entities and properties must be mappable to existing entries in the knowledge graph, even if their surface forms do not exactly match. In contrast, open information extraction generates free-form triples directly from text, without requiring alignment to a specific schema or vocabulary \cite{Etzioni2008}.

A related concept within the broader field of information extraction is relation extraction, which focuses on identifying relationships between entities and often includes the detection of the entities themselves \cite{Zhao2024}. Relation extraction differs from open relation extraction in that it relies on a predefined set of relation types and structures \cite{Kamp2023}. All of these tasks are subfields of information extraction, which broadly refers to the process of extracting entities and their relations from natural language text \cite{Etzioni2008}.

Given the similarities between relation extraction and closed information extraction, many of the associated challenges and solution strategies overlap. A primary challenge is the identification and extraction of entities from text. In the context of closed information extraction, this step is closely tied to entity linking, as entities must be disambiguated and mapped to corresponding entries in the knowledge graph. This disambiguation is necessary because multiple entities may share identical surface forms. Once entities are identified and resolved, the next step is to detect relationships between them and classify these relations according to a predefined ontology. In a closed setting, these extracted relations must then be mapped precisely onto the structure of the knowledge graph \cite{Josifoski2021,Zhao2024}.

To illustrate this, consider the sentence \textit{"Angela Merkel is the chancellor of Germany."} A possible closed information extraction result, using Wikidata as the target knowledge graph, could be the triple \texttt{wd:Q567\ P39\ wd:Q14211}, where \texttt{wd:Q567} represents Angela Merkel, \texttt{P39} denotes the property \textit{position held}, and \texttt{wd:Q14211} corresponds to the entity \textit{Chancellor of Germany}.

To address these tasks, two principal approaches are commonly used: pipeline-based methods and joint models. Pipeline approaches decompose the task into sequential stages, such as entity recognition, disambiguation, relation detection, and triple generation. In some implementations, individual stages may be further subdivided or combined depending on the system design. In contrast, joint models aim to perform all subtasks simultaneously, often using shared representations. This can help reduce error propagation across pipeline stages by optimizing for the overall goal of producing accurate and coherent triples \cite{Zhao2024,Josifoski2021}.

While the foundational goals of information extraction remain consistent across its subfields, \citet{Josifoski2021} emphasize that techniques developed for open information extraction are generally not applicable to closed settings. The reason lies in the stricter requirements of closed information extraction, which is constrained by the structure and vocabulary of an existing knowledge base. Consequently, the output must be structured in a way that aligns precisely with predefined entities and properties \cite{Josifoski2021}.

Given these constraints, the performance of closed information extraction systems is typically assessed using standard evaluation metrics such as precision, recall, and F1-score \cite{Josifoski2021,Josifoski2023}. These metrics capture how accurately and completely a system can extract triples that are both correct and mappable to the knowledge graph. A detailed discussion of these metrics is provided in Section~\ref{sec:evaluation_metrics}.

In summary, closed information extraction represents a highly constrained subclass of information extraction. In addition to the standard challenges of entity recognition, disambiguation, and relation extraction, it introduces the additional requirement of aligning outputs with a knowledge graph. Each step in the process presents opportunities for error, which is why pipeline approaches often emphasize robustness at each stage. Joint approaches, in contrast, seek to optimize the process holistically in order to improve overall accuracy.

\section{Language Models}
\label{sec:language_models}
A \ac{LM} is a \ac{ML} model, that at its core is able to predict the probabilities of how a text is going to be completed based on the previous text\cite{Radford2019}. Since the original publication by \citet{Vaswani2023} most present \acp{LM} are build out of two components, the tokenizer and the transformel model. The tokenizer transforms parts of a text into a integers. Therefore, the integers are like a index in a vocabulary mapping a character sequence to an integer \cite{Sennrich2016}. In present models like the GPT-models the existing tokenizer is a byte-pair encoding \cite{Radford2019}. This byte-pair encoding works by intialising a vocabulary using single characters. Afterwards frequent character sequences will be merged iteratively, create new tokens. This will be done until a defined maximum number of tokens in the vocabulary is reached \cite{Sennrich2016}. With that explained, a \ac{LM} can be mathematically formulated as a conditional probability $P$ of the token $t_i$ under the condition of all previous tokens:
\begin{equation}
  P(t_i|t_1,...,t_{i-1}).
\end{equation}

The core part of a \ac{LM} is the transformer. Transformers itself are \ac{ML} models that concept of Multi-Head-Attention Layers and Feed-Fordward Layers. Attention is a concept to encode previously tokens ($t_1,...,t_{i-1}$) and their relation to the current token $t_i$ into the encoded representation of the current token. The implementation of this concepts requires an learned embedidng of all tokens and three learnable weight matrices. An embedding is in this case a trained mathematical representation of a token. The weight matrices split up in one weight matrix $W^Q$ for the current token and two weight matrices $W^K, W^V$ for the previous tokens \cite{Vaswani2023}. The idea behind this concept is, that those weight matrices are able to detect relations like adjectives and therefore influence the encoding of a token \cite{Sanderson2024}. For instance, when the text \enquote{... the former german chancelor Angela Merkel ...} is processed by the attention layer, the attention mechanism could encode \enquote{former german} into the token of \enquote{chancelor}. It has to be mentioned, that this is an example and the exact behavior of the attention layer could differ \cite{Sanderson2024}.

Following this idea, \citet{Vaswani2023} proposed the concept of multi-head attention to learn multiple weight matrices and run the matrix multiplication done by the attention mechanism multiple times in parallel. Afterwards the result of all attention heads are concatenated and projected using the Softmax function \cite{Vaswani2023}. Therefore, multi-head attention could also be able to identify various kinds of relationships inside a sentence \cite{Sanderson2024}. In addition to multi-head attention, a position encoding is inserted into the embeddings of the tokens \cite{Vaswani2023}. In addition, each output of the attention respective the feed forward layer gets added to the initial input to this layer and afterwards get normalized. The Transformer is completed by a linear layer mapping the vector representation back on the vocabulary and a softmax layer to get a probability distribution across the vocabulary \cite{Vaswani2023}. Figure \ref{fig:transformer} shows the overall composition of transformers with the encoder component on the left and the decoder component on the right. As following explanations focusses on the already explained components the masked-multi-head-attention and encoder-decoder split will not be covered.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/Transformer.png}
  \caption[Architecture of a Transformer model]{Architecture of a Transformer model. \cite{Vaswani2023}}
  \label{fig:transformer}
\end{figure}

As already stated, a softmax function is used to get a probability distribution across all possible output tokens. Normally the sampling process of the next token is used to be a random process, where each tokens has the assigned weight from the softmax function. In order to increase or decrease randomness, a temperature parameter $T$ is introduced in the softmax function \cite{Peeperkorn2024}. For each output $z_i$ on token $t_i$ for a sequence with length $n$ the softmax function $softmax(\mathbf{z})_i$ with the temperature $T$ will be calculated as \cite{Peeperkorn2024}:

\begin{equation}
  softmax(\mathbf{z})_i = \frac{exp(\frac{z_i}{T})}{\sum^n_j exp(\frac{z_j}{T})}~~~where~\mathbf{z} \in \mathbb{R}^n.
\end{equation}

Increasing the temperature $T>1$ would lower high probabilities and increase low probabilities and therefore make the output more novel in theory. A temperatur $T<1$ would amplify high probabilities and make the text generation more predictable. Using a temperature $T=0$ change the generation to greedy sampling, as then only the token with the highest probability is used \cite{Peeperkorn2024}.

Todays top-tier like OpenAIs \ac{GPT} models or Metas \ac{LLaMA} models \acp{LM} do make use of the decoder part of the transformer \cite{Radford2018,Grattafiori2024}. Models especially with large amount of parameters are typically referred to as \acp{LLM}. Those decoder-only models do only have the target to make predictions for the token $t_i$. Those models use unsupervised pre-training, by using a text-corpora and maximizing the probabilities of each subsequent token in this corpora to be predicted. In former models like the original GPT version, after pre-training a task-specific supervised fine-tuning was necessary to get usable results \cite{Radford2018}.

The recent history of \acp{LM} showed, that increasing the corpora size on the pre-training and the parameters number enables the models to be able to process tasks from various domains without further fine-tuning \cite{Radford2018,Radford2019,Brown2020}. With the GPT-3 publication, \citet{Brown2020} showed that their model can leverage in-context learning to increase their performance on specific tasks. Therefore, in the input of the model, what is also called the prompt, examples will be added. For instance, when the \ac{LM} should process translation tasks, it get's in it's prompt examples like \textit{house $\rightarrow$ Haus} or \textit{light bulb $\rightarrow$ Glühbirne}. Including multiple examples is called few-shot prompting, while including one example is called one-shot-prompting and including no example is called zero-shot prompting.

This technique has shown great success especially when using larger models, as they were able to process in-context information more efficient. But also the zero-shot experiments showed superior performance to SOTA models in various tasks, showing the general capabilities of recent \acp{LM} \cite{Brown2020}. To enable this performance, \citet{Brown2020} used the Common Crawl corpora, filtered it and added also other smaller, but high quality corpora to their pre-training dataset. Therefore, the \ac{GPT}-3 pre-training dataset had access on over 500 billion tokens \cite{Brown2020}.

As the Common Crawl corpora follows the idea of providing a copy of the entire internet \cite{CCF2025} and other used corpora also provide prose text combined with the overall training goal of \acp{LM} leads to a superior performance in text generation but not in instruction following \cite{Ouyang2022}. In addition, \citet{Ouyang2022} states the real-world usage of \acp{LM} differ from the given corpora, as most users use instructions. Therefore, \ac{GPT}-3 was finetuned towards two datasets. One dataset uses human-given answers to prompts to fine-tune the model. In addition, human-labeled comparisons between answers of different \ac{GPT}-3 models are used to train a reward models, that is applied using reinforcement learning on the model. At the end of the experiements, the resulting InstructGPT model reached superior performance on human evaluated benchmarks based on the output on held-out prompts from customers. Even the smallest instruction tuned model with 1.3 billion parameters outperformed \ac{GPT}-3 with 175 billion parameters in this evaluation \cite{Ouyang2022}.

In order to choose ideal model for use-cases, on option could be to use benchmarks like MMLU-Pro \cite{Wang2024} or the human-evaluated Chatbot Arena \cite{Chiang2024}. The MMLU-Pro benchmark is testing for multi-task language understanding with the goal to test the various capabilities of LLMs. Therefore, the MMLU-Pro keeps tasks from maths, physics, law, engineering and various other topics \cite{Wang2024}. The Chatbot Arena\footnote{The Chatbot Arena can be accessed under \url{https://lmarena.ai}} is a live benchmark working with human preferences. Therefore, the use gets two answers from two distinct models to the user prompt. Then the human chooses which \ac{LM} performed better. Based on this feedback a win rate and a score can be calculated \cite{Chiang2024}.

The \acp{LLM} breakthrough performances on such benchmarks rely also on their high complexity. Models like GPT-3 are using 175B parameters make the use of multiple high-performance GPUs necessary \cite{Brown2020,Frantar2023}. There can be seen two methods how to utilise \acp{LLM} within a limited performance set up. First is to use smaller models with less parameters. This shows consequences in the abilities of the models \cite{Brown2020,Grattafiori2024}. Recent research shows that especially newer models can achieve prior state-of-the-art performance with less parameters \cite{Meta2024}.

Another way to use \acp{LLM} that fit into the limited configurations, but utilising large parameter models while handling a tradeoff with performance is quantisation. In general, quantisation methods lower the number of bits used per parameter. As naive quantisation leads to higher accuracy drops, methods like GPTQ or AWQ are developed. Both methods implement variants to lower the error, by either handling and lower the error in the quantisation process or by preserving salient weights. Both approaches show around 3x faster performance while producing high quality results compared to the standard 16-bit accuracy \cite{Frantar2023,Lin2024}.

In conclusion, \acp{LM} are \ac{ML} models consisting out of multiple multi-head attention and feed-forward network layers with the goal to predict the probability of a following token based on all previous tokens. Therefore, those models are designed as with a large amount of parameters and additional use pre-training based on large size corpora to achieve outperforming results. In the end, those models can be benchmarked using MMLU-Pro or the Chatbot Arena to test various capabilities of them.

\section{Sentence Embeddings}
\label{sec:sentence_embeddings}

Sentence embeddings in general have the idea to represent a text in a vector \cite{Singhal2001}. Building those vectors, the semantic of the sentence can be encoded in those embeddings, so that a meaningful similarity between the vectors can be calculated \cite{Reimers2019}. Typically this similarity is the cosine of the angle between two vectors, which is named cosine similarity. The property of the cosine function then allows, that the cosine between two vectors is 1.0 when they are total identical and 0.0 if not \cite{Singhal2001}. An visualisation of this behavior can be found in figure \ref{fig:cosine_similarity}. Such models are critical to enable large-scale semantic similarity comparisons which are useful for various use cases, like retrieving knowledge similar to a user query \cite{Reimers2019,Gao2024}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.6\textwidth]{figures/cosine_similarity.jpeg}
  \caption[Visualization of cosine similarity between two vectors showing how the angle between vectors determines their similarity score]{Visualization of cosine similarity between two vectors showing how the angle between vectors determines their similarity score. \cite{Leys2022}}
  \label{fig:cosine_similarity}
\end{figure}

One recent model is M3-Embedding, which is trained to support semantic retrieval functions that rely on similarity functions. The overall idea of M3-Embedding is to support multiple languages, multiple retrieval functionalities and multiple input granularities. To achieve this goal M3-Embedding leverage the encoder architecture of transformers like stated in section \ref{sec:language_models} \cite{Chen2024}.

Training-wise, \citet{Chen2024} follows the pre-training approach, while fine-tuning later on high-quality data. The pre-training was done on unlabeled corpora utilising semantic structures like title-body or title-abstract. To support multi-linugua a translation dataset was leveraged. Then labeled corpora in different languages and synthesised corpora consisting of questions generated by \ac{GPT}-3.5 based on multilingual paragraphs were used to fine-tune the embeddings. Overall the M3-Embedding model was trained to detect if a queries matches a text passage from its semantics or not \cite{Chen2024}.

Overall sentence embeddings can be used to map sentence into the vector space, while also encoding semantic into this space. Leveraging vector algebra like the cosine similarity, semantic similarity between two sentence embeddings can be calculate. To achieve SOTA performance embeddings like M3-Embedding make use of the transformer architecture combined with extensive training sets and the pre-training technique.

\section{Retrieval Augmented Generation}
\label{sec:retrieval_augmented_generation}

As \acp{LM} are trained on large-size snapshots of corpora, they are by default not able to retrieve out-of-scope knowledge from the internal representation. Therefore, \ac{RAG} emerged as a solution to incorporate knowledge from external data sources into the \ac{LM} at runtime. \ac{RAG} in it's simplest form is build out of indexing, retrieval and generation. In the indexing step, the plain text, also called document, will be mapped into the vector space utilising embedding models like the previously named M3-Embeddings \cite{Gao2024}. This embeddings are stored for later retreive in a database that can handle vectors and vector algebra efficient \cite{Gao2024,Pan2024}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/RAG.png}
  \caption[Overview of the Retrieval Augmented Generation (RAG) architecture showing the indexing, retrieval, and generation pipeline]{Overview of the Retrieval Augmented Generation (RAG) architecture showing the indexing, retrieval, and generation pipeline. \cite{Gao2024}}
  \label{fig:rag}
\end{figure}

In figure \ref{fig:rag} an overview about the steps and the functionality of each step can be found. The steps of retrieval and generation are done at runtime, whereas the indexing can run independend. The retrieval steps utilises again the embedding model to map the user query into the vector space. As shown in section \ref{sec:sentence_embeddings}, models like M3-Embeddings are trained on to calculate the similarity between documents and user queries. This enables the retrieval step to run a similarity search on the \ac{VDBMS} and retrieve the most relevant documents based on the user query. After the retrieval those documents can be composed into a prompt template, where additionaly to the user prompt, a system prompt can be defined. Then this prompt is send to the \ac{LM} with the goal to produce a external knowledge aware answer \cite{Gao2024}.

Besides the already explained embeddings the \ac{RAG} depends on a \ac{VDBMS}. Those databases consist like normal \ac{DBMS} out of a query processor and a storage manager. The query processor is optimising the query and processes especially the similarity searches. One example of \ac{VDBMS} is Qdrant. Qdrant uses filtering and vector set size depended execution paths. If a vector set, named collection in Qdrant, keeps many vectors, a brute-force search would be to extensive. Therefore, Qdrant would use pre-filtering mechanism that limit the search results and computations that have to be done. The storage manager manages the physical access and storage of the data \cite{Pan2024}.

As already stated Qdrant is an example for a \ac{VDBMS}. It uses the concept of collection, where vectors are stored that should be retrieved together, for instance to cluster vectors that all belong to one project. Additionally to the vectors, payloads can be used to store metadata alongside with the vectors. Qdrant offers a python client and a Langchain integration, which is useful to be leveraged in vector store projects \cite{Qdrant2025}. Langchain itself is a framework to develop application with \acp{LM} \cite{LangChain2025d}. Through its query optimisations, Qdrant is able to handle large-scale datasets efficient \cite{Qdrant2025,Pan2024}.

\ac{RAG} is one solution to integrate external knowledge bases, that can be updated efficient, into \acp{LM}. Therefore, \ac{RAG} makes use of the ability of embeddings to encode semantic similarity that can be retrieved using cosine similarity. In order to make use of \ac{RAG} the external knowledge bases have to be indexed using embeddings. To support \ac{RAG}, \ac{VDBMS} are utilised for an efficient indexing and retrieval process.

\section{AI Agents}
\label{sec:ai_agents}

\ac{AI} agents are a more narrow concept of a normal agent. \citet{Dorri2018} defines an agent as \enquote{(a)n entity which is placed in an environment and senses different parameters that are used to make a decision based on the goal of the entity. The entity performs the necessary action on the environment based on this decision.} \cite[S. 28574]{Dorri2018} The entity in this case is defined as the type of the agent. The enviroment is the place of the agent, which is defined by the accessibility and quality of data, predictability of outcomes, the dynamic of enviroment changes and continuity of the state. Parameters can be defined as the data that the agent gets and the action is the set of actions that the agent can take \cite{Dorri2018}.

Agents do have a decision engine. \ac{AI} agents typically narrow this decision engine nowadays down to \acp{LLM} \cite{Sapkota2025,Park2023}. Furthermore \ac{AI} agents are defined by having a high degree of idependence, while being task-specific and react and adapt to the current state \cite{Sapkota2025,OpenAI2025}. The high degree of independence differs to workflows, were the path how to achieve a goal is well-defined \cite{Anthropic2024}. The idea behind \acp{LLM} that power agents is to generate human-like behavior, as \acp{LLM} have internal representation of human behavior via the training data \cite{Park2023}.

To achieve this goal the agent architecture cosists of agent orchestration, a \ac{LLM} model used for decision making and reasoning and tools \cite{Wiesinger2025,OpenAI2025}. All components are executed by an agent runtime. The orchestration layer is the layer that defines which information an agent gets. This consists of managing memory, providing the prompt templates to the agent and define a message flow, so how the actions that the agent takes are executed \cite{Wiesinger2025}.

According to \citet{OpenAI2025} tools can be defined in three types: Data, Action, Orchestration. Data tools are concentrated on retrieving information from external systems. Therefore, data tools can query databases or search the web. Action tools enable the agent to take actions in external systems. This means, the agent could update or create record in systems like a \ac{CRM}. Orchestration agents, agents that serve themselve as tools. This concept is referred to as \ac{MAS} an will be explained in detail in section \ref{sec:multi_agent_systems}. In general, tools are an enabler to AI agent to directly interact with external systems. This interaction allows \ac{AI} agents to act highly idenpendent.

A single \ac{AI} agent is targeted to process a single well defined tasks together with defined tools. Within this task it stays indepent, but a single \ac{AI} agent is not offering a high degree of flexibility, when not using other agents as tools \cite{Sapkota2025}. In this use case \citet{Anthropic2024} proposes that \ac{AI} agents are able to understand complex inputs, can make use of tools in reliable manner and recover from errors. In addition, \ac{AI} agents can engage in reasoning and planning over given tasks \cite{Anthropic2024}.

The ability to reason is especially used in the ReAct agent framework proposed by \citet{Yao2023}. The idea behind the ReAct frame is the synergy between reasoning on perceptions and taking action from there on, as this is a typical learning behavior of humans. In the proposed idea, the \ac{LLM} is mocking this human behavior by being told to reason and act \cite{Yao2023}.

In general the ReAct framework prompts an \ac{LLM} to reason about a task using a defined state. The resulting thought will be written in the state, alongside with all following thought. Besides giving a thought, the \ac{LLM} is prompted to take an action which could either be running a tool, running itself again or ending the process. This action leads to a result which is called observation. After each thought in the state, an action and the following observation is stored. Together this build up a history, that the \ac{LLM} could leverage to memorise it's own thoughts and actions \cite{Yao2023}.

To implement \ac{AI} agents \citet{Anthropic2024} proposes to take a framework like LangGraph. LangGraph is an open-source frame to build agent with the whole agent ecosystem. Therefore, tools, memory and the state can be define either using LangGraph in python or JavaScript. LangGraph offers a high extensibility, to define the agent as individual as needed \cite{LangChain2025}. Alltogether LangGraph is integrated with the LangChain package \cite{LangChain2025a}.

Single agents bring challenges along. First of all there are limitations brought by the \ac{LLM}, which is about missing the understanding for causal relationships. This arises out of the goal to generate text instead of detection causal relationships. In addition, as \acp{LLM} are prompt sensitive, the overall outcome is prompt sensitve \cite{Sapkota2025}. Furthermore, \citet{Sapkota2025} states, that \ac{AI} agents have limited long-horizon planning and missing recovery mechanism leading them to get stuck in a loop.

Overall \ac{AI} agents are defined by a model taking independent actions. Therefore, an agent must be orchestrated and has access to various tools. The ReAct framework can implement the ideas and capabilities of \ac{AI} agents so that the \acp{LLM} behave human-like and therefore achieve good results.

\section{Multi-Agent-Systems}
\label{sec:multi_agent_systems}

As stated in the previous section agents are often limited to a single task, being unflexible to solve other tasks. A solution to this limitation can be found in \ac{MAS}. The idea behind them is to produce a cost efficient, flexible and reliable solution, by using multiple agents instead of one. Therefore, the complex task can be splitted into multile simple task. The theory is that the simpler task lead to lower cost solutions amortising the overhead produced to manage the \ac{MAS} \cite{Dorri2018}.

So to make a general \ac{MAS} work, agents are defined for various simpler task. In addition, multiple agents could be defined for the same task. Then the routing within the \ac{MAS} must be defined. This means, that there is either a static or dynamic topology of agent and the communication routes between them. In this topology there coould a leader agent, that defines the actions that have to be taken by other agents and they communicate solely to the leader. The second option is a leaderless \ac{MAS}, where each agent decide on its on which agent is to call next \cite{Dorri2018}.

Especially leaderless \ac{MAS} bring a high degree of flexibility with them. From this, a high complexity arises in coordinating the agents towards one shared goal, organising the agents to communicate to each other and allocating a task to the correct agent with the correct inputs. Additionally, as multiple agents conduct to one goal, fault propagation and fault detection is getting more complex \cite{Dorri2018}.

All mentioned points can also be mapped and extended when focussing on \ac{LLM} based \ac{MAS}. In general, due to the capabilities of \acp{LLM}, single \ac{AI} agents are already able to take care of complex tasks. But the only way to keep with more complex task is to increase instruction size and the number of tools, which could lead the \ac{AI} agents into failing or looping like already outlined in section \ref{sec:ai_agents} \cite{OpenAI2025}. Therefore, the goal decomposition into various specialised \ac{AI} agents remains also a key enable to solve more complex tasks \cite{Sapkota2025}.

In the case of \ac{LLM}-based \ac{MAS}, each agent is in general required the same building blocks like mentioned in section \ref{sec:ai_agents}. This concept is adapted to \ac{MAS} by extending the state to a shared state \cite{Sapkota2025}. In addition, each agent in a \ac{MAS} needs to have an handoff. This handoff is defined by the agent itself and decides the further flow within agent system. Especially in LangGraph the handoff specifies the destination of the handoff, so the next tool or agent, and the payload, meaning the update of a state or inputs to the next agent or tool. The state itself in LangGraph is a python dictonary with pre-defined fields. Therefore, the orchestration layer of the \ac{LLM}-based \ac{MAS} gets more complex, what could be handled by frameworks like LangGraph \cite{LangChain2025b}.

The agentic architecture patterns of a \ac{LLM}-based \ac{MAS} follows the classic \ac{MAS} patterns as depicted in figure \ref{fig:mas_architecture}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/Multi-agent architectures.png}
  \caption[Example multi-agent architecture patterns showing supervisor, hierarchical, network, and custom patterns for LLM-based multi-agent systems]{Example multi-agent architecture patterns showing supervisor, hierarchical, network, and custom patterns for LLM-based multi-agent systems (self-created after \cite{LangChain2025b})}
  \label{fig:mas_architecture}
\end{figure}

The leader-follow pattern is defined as supervisor pattern by \citet{LangChain2025b}, alongside with the hierarchical pattern. The supervisor pattern therefore, has on supervisor agents, that manages the communication to other expert agents, which themselve can only communicate with the supervisor agent. In the hierarchical pattern, those expert agent can itself be supervisors to other expert agents \cite{LangChain2025b}.

\ac{LLM}-based \ac{MAS} can also be used with decentralised leaderless architecture \cite{OpenAI2025,LangChain2025b}. This concept is extended by \citet{LangChain2025b} to network and custom patterns. The network pattern allows each agent to decide to which agent in the network it should handoff its request. In this pattern each agent controls the flow within the \ac{MAS} \cite{LangChain2025b,OpenAI2025}. The custom pattern could not be perfectly adapted to either leader-follow nor leaderless patterns. In the custom pattern a user can also define workflows for specific agents or let some agents not communicate with specified other agents \cite{LangChain2025b}. The big benefit besides the theoretical more accurate performance of \ac{LLM}-based \ac{MAS}, is the high modularity that is being enabled. In addition, through packages like LangGraph, the communication flow between the agents can be precisely defined alongside with the agents specialisation \cite{LangChain2025b}.

Nevertheless, \ac{LLM}-based \ac{MAS} amplifies and adds challenges that were already apparent with \ac{AI} agents. At first within \ac{LLM}-based \ac{MAS} the lack of causal understanding gets amplified, as agents have to run multiple times. Each \ac{AI} agent brings already uncertainty with them, especially being prompt sensitive and are vulnerable to infinite loops. Using multiple \ac{AI} agents, leads to even more uncertainty and robustness \cite{Sapkota2025}. In addition, the communication and coordination of \ac{LLM}-based \ac{MAS} reveals further bottlenecks. This is amplified by the fact, that \acp{LLM} have limited context length model-wise and infrastructure-wise \cite{Kwon2023}. This adds complexity in managing shared context and aligning on one goal \cite{Sapkota2025,Han2025}. As \acp{LLM} can produce unpredicted behavior, \ac{LLM}-based \ac{MAS} is non-composable. This means, that adding another \ac{AI} agent to a \ac{LLM}-based \ac{MAS} could lead to more complexity in the prompts, but it does not necessarily mean, that this new agent is used. Therefore, new agents could decrease the overall performance of the \ac{MAS}. In addtion, with further scaling and the prompt senstivity of \acp{LLM} it remains complex to detect the root causes of issues in the \ac{MAS}. An evolving challenge is the immature foundations and the reletavely new reasearch field aroun \acp{LLM} in general, but especially in \ac{AI} agents and \ac{LLM}-based \ac{MAS} \cite{Sapkota2025}.

As this research subject is rapidly evolving, also solutions are already found towards several problems. For instance to support \acp{LLM} in better reasoning, one way is to include external knowledge bases using \ac{RAG}. In addition, as a \ac{LLM}-based \ac{MAS} also use \ac{AI} agents, those agent can also access tools, which are deterministic and deliver reliable results. The root cause tracing issue can be solved by using monitoring and auditing tools. In order to give \acp{LLM} a way to sense causality by using complex simulation-tools. The communication bottlenecks can also be solved using different memory architectures \cite{Sapkota2025}.

Overall \ac{LLM}-based \ac{MAS} are one solution to solve complex problems efficient and accurate. Therefore, multiple \ac{AI} agents, that solve one piece of the overall problem, can communicate and take action. This could be done within a network of \ac{AI} agents, hierarchical solutions or fully custom solutions. Nevertheless, as the overhead increases and so does the \ac{LLM} calls, \ac{LLM}-based \ac{MAS} are vulnerable to challenges like uncertainty amplification or tracibility issues. As the research field is relatively new, also several solutions like tracibility tooling or uncertainty reduction by external knowledge and tool use evolved.

\section{Agent Design}
\label{sec:agent_design}

As the area of \ac{AI} agent research evolves, so does the research about best practises about when to use \ac{AI} agents and how to design them. In general, \citet{OpenAI2025} recommends to use \ac{AI} agents as soon as  deterministic rules fall short. This includes especially, if a problem can not be put into a ruleset straightforward. Especially if the decision making within the problem is additionally complex and the problem relies mainly on unstructured data, \ac{AI} agents are proposed to outperform other approaches \cite{OpenAI2025}.

As already stated in section \ref{sec:ai_agents}, \ac{AI} agents are in general bound to one single task and also limited in the amount of context they can handle. Such cases can be detected, if the agents are starting to fail following instructions or the decision making performance starts to worsen. By design, some problems can lead to complex context and a higher amount of tools, which itself can lead to tool overload. In this case, the context, tasks and following this also the tools per agent can be splitted down to \ac{MAS}. In addition, complex problems can also require complex logic which would be preferable be splitted down into several subtasks using \ac{MAS} \cite{OpenAI2025,LangChain2025b}. Nevertheless, \ac{LLM}-based \ac{MAS} has to be design efficient, as this architecture comes with high costs \cite{Hadfield2025}.

On the overall agent design \citet{Anthropic2024} recommends simplicity before complexity. Furthermore, they define agent systems as a tradeoff between latency and overall task performance. In general, \citet{Hadfield2025} proposes to design an agentic system like a human team. This is followed by keeping the tasks consise and define clear actions \cite{OpenAI2025}. Furthermore, the context should stay human-understandable, as \acp{LLM} are trained on human content \cite{Anthropic2024}. In addition, \citet{Hadfield2025} recommends to use compression of the context, to keep the context shorter and more understandable. In general all of this comes down to the hypothesis created by \citet{Anthropic2024}, if a human can solve a task and \ac{AI} agent or \ac{LLM} should also be able to solve it. But also, \citet{Anthropic2024} follows up, that the problems and prompts should be kept obvious to solve. In addition, \citet{OpenAI2025} recommends to capture edge cases in order to make the \ac{AI} agents more robust overall. Specifically on \ac{LLM}-based \ac{MAS}, \citet{OpenAI2025} recommends to keep the single components flexible and composable.

As \ac{LLM}-based \ac{MAS} do have \acp{LLM} as decision engine and as already outline those models reamin prompt sensitive, prompt engineering remains critical to challenges in such \ac{MAS} \cite{OpenAI2025}. First of all, \citet{Anthropic2024} recommends to think about the training content and intentions of \acp{LM}. Those models were trained mainly on prose text and are created to generate text. That is why, \citet{Anthropic2024} recommends to keep the prompt format, but also the output format as close to the training data as possible. Following this recommendation no formatting overheads lowering the performance of the \ac{MAS} should be included by design. In addition, \citet{Hadfield2025} proposes to teach the \ac{AI} agents how to orchestrate the \ac{MAS}. This also includes to guide the thinking process of the \ac{AI} agents \cite{Anthropic2024}. Overall the \ac{AI} are recommended to perform better, if the prompts are kept clear and structured \cite{OpenAI2025}.

As already outlined in section \ref{sec:language_models} one apparent technique to produce high quality prompts is to leverage in-context learning. When building in-context learning enabled prompts by using either few-shot or one-shot prompting, decisions have to be made about the examples \cite{Schulhoff2025}. \citet{Schulhoff2025} outlines the quantity, ordering, format and similarity as decisive points. Already before providing examples the prompt can be designed proper \cite{Schulhoff2025}. Therefore, \citet{Schulhoff2025} outlines different styles of prompting, including role, style or emotion prompting. Another proposed prompt technique is \ac{CoT}. In \ac{CoT} prompting, the \ac{LLM} gets provocated to think step by step through the tasks. In addition, few-shot \ac{CoT} includes \ac{CoT} examples in the prompt. In addtion, automatic prompt optimisation can be used to improve the performance of the \ac{AI} agents in the \ac{MAS} \cite{Schulhoff2025}.

\citet{Schulhoff2025} experimented multiple configurations with zero-shot and few-shot prompting against the MMLU benchmark, which is similar to the MMLU-Pro benchmark showed in section \ref{sec:language_models}. Within this experiment the few-shot \ac{CoT} prompting is the worst, while the few-shot \ac{CoT} prompt worked the best. Therefore, \citet{Schulhoff2025} agrees with the earlier result of \citet{Brown2020}, which outlined \acp{LM} as few-shot learners.

In addition to the prompt itself, the definition of useful tools is crucial to solve specific tasks that have to make use of external applications or knowledge \cite{OpenAI2025}. As the tools itself have to be described in the prompt, the tool description have to be as good engineered as the overall prompt accordings to \citet{Anthropic2024}. In addition, tools have to be tested extensive, as their is a structured handoff, that has to be generated out of an unstructured text using a \ac{LLM} \cite{Anthropic2024}. Therefore, \citet{Anthropic2024} advises to test and log how tools are used. By further iterating, it is recommended to design prompts simpler \cite{Anthropic2024}. Following this recommendation, tools could also be made fool-proof by design, so that it is harder for the \ac{LLM} to make a mistake.

After designing the agents, the iteration for better performance is to trace and evaluate the agents. \citet{Hadfield2025} proposes therefore to start immediately after designing \ac{AI} agents using small examples. In addition, it is proposed that human evaluation should be used to keep track of errors, that are not apparent in automation. Therefore the agent execution, but especially the tool execution should be traced and later on debugged \cite{Hadfield2025}. One example platform for this kind of \ac{LLM} engineering is Langfuse \cite{Inc.2025}.

Overall, as \acp{LLM} come with limitation and challenges, it is crucial to design \ac{AI} agents using \acp{LLM} as their decision making engine proper. This includes the general approach to design \ac{AI} agents and the \ac{LLM}-based \ac{MAS} as human-like tasks for a single or for multiple specialised. Combined with proper prompt and tool engineering, \ac{LLM}-based \ac{MAS} could excel on complex tasks \cite{Hadfield2025}.

\chapter{Related Work}
\label{ch:related_work_chapter}

In this section the goal is to show the current state-of-the-art training and benchmarking datasets alongside various approaches in the field of information extraction with a focus on solutions in the are of closed information extraction. Therefore, REBEL as one of the first large scale datasets for open and closed information extraction followed by synthIE, a datasets which is synthecially generated using models of the GPT-3.5 will be shown in section \ref{sec:related_datasets}. In the following section \ref{sec:related_approaches}, the various approaches ranging from transformer fine-tuning over prompt-tuning towards use of \ac{AI} agent for the problem of open and closed information extraction will be shown.

\section{Related Datasets}
\label{sec:related_datasets}

The datasets remain crucial to train, but especially to evaluate approaches in the area of closed-information extraction correct. This implies a high quality, but also high volume dataset \cite{Josifoski2023}. Therefore, the REBEL dataset was conducted by analysing Wikipedia Abstracts and extract all Hyperlinks out of that. In addtion a RoBERTa \ac{LM} is used to filter whether a text contains the extracted triples by leveraging the entailment prediction of RoBERTa. This results in a large scale dataset, where noise is accepted and which is automatically created. Therefore, the REBEL dataset can be defined as a silver-standard dataset. As the REBEL dataset also contains the \acp{URI} for the extracted entities and predicates, it can be used for relation extraction as well as for closed information extraction \cite{HuguetCabot2021}.

Following up on the problems of the REBEL dataset being noisy and skewed in terms of predicate frequency, the advances in the field of \acp{LM} \citet{Josifoski2023} introduced the synthIE dataset. The idea is to leverage the advances in text generation that a \ac{LM} from the GPT-3.5 series has and generating the text correlated to the expected triples \cite{Josifoski2023}. Following this idea, \citet{Josifoski2023} creates a unskewed set of triples based on a subset of wikidata and than prompting the triples with an corresponding instruction into text-davinci-003, which is based on InstructGPT, or code-davinci-002, which is a base GPT model \cite{Josifoski2023,OpenAI2025a}. Human annotated samples showed, that in contrast to REBEL most of the triples within the text generated by the synthIE dataset approach were detectable \cite{Josifoski2023}.

Overall, \citet{HuguetCabot2021} and \cite{Josifoski2023} provided large scale datasets. The synthIE dataset remains of higher quality and therefore promises better results when used for evaluation. Both datasets are providing large amounts of training, validation and testing data, providing a foundation for approach development in the area of closed information extraction.

\section{Related Approaches}
\label{sec:related_approaches}

Like already outline in section \ref{sec:closed_information_extraction} the area of open and closed information extraction have the research streams of pipeline- and joint-approaches. Both streams relied on a broad variety of solutions ranging from table-filling with tag probability learning over LSTM-based approaches to encoder-decoder models \cite{Zhang2022,Angeli2015,Trisedya2019}. With current advances of Seq2Seq text generation models towards the transformer architecture, recent approaches mainly implement various kinds of transformers in their solution architectures \cite{Josifoski2021,Josifoski2023,Moeller2024}.

Earlier implementations prior to the emergence of \acp{LLM} showed already superior performance using transformers to other state-of-the-art solutions. One example for this is the REBEL approach \cite{HuguetCabot2021}. Leveraging a large dataset of texts as queries and triples as outputs, the BERT-model fine-tuned by \citet{HuguetCabot2021} surpassed every compared method on similar benchmarking datasets, presenting a flexible relation extraction model.

\citet{Josifoski2021} introduced the idea of GenIE, which is adapting the idea of REBEL towards closed information extraction. This especially meant that the decoding in the BART \ac{LM} was constrained towards the underlying knowledge base, which is Wikidata \cite{Josifoski2021}. Therefore, \citet{Josifoski2021} used an output linearization by introducing special tokens to delimit subject, predicate and object. In addition, \cite{Josifoski2021} introduced a constrained beam search, that limits which tokens can be generated towards Wikidata. This idea on how to secure valid triple generation, outperformed the state-of-the-art pipeline consisting of named entity recognition, entity disambiguation, relation classification and triplet classification when released \cite{Josifoski2021}.

Using the idea of GenIE and the quality of the synthIE dataset, \citet{Josifoski2023} introduced the synthIE model. The synthIE model follows the architecture of GenIE, but replaces BERT by Flan-T5 \ac{LM} due to a higher availablity of usable pre-training configurations. The results showed, that the best synthIE model trained on the train split of synthIE dataset could surpass the REBEL-trained GenIE model, which was also using Flan-T5 in this comparison, by a gap of over 0.8 macro-F1 using the synthIE-text dataset. This outlined the high correlation between the training and benchmarking dataset quality and the overall quality on the model \cite{Josifoski2023}.

Proceeding on to ideas of leveraging foundation models that then can be either fine-tuned or prompt engineered, \citet{Xue2024} presented a pipeline approach with fine-tuned \acp{LLM} for Relation Extraction, Subject Identification and Triplet Fact Extraction, while \citet{Chen2024} presented a prompt tuning approach for joint optimisation. The approach of \citet{Xue2024} was evaluated on the document-relation extraction dataset Re-DocRED showing a 10\% increase in F1-score compared to state-of-the-art models. Furthermore, it was shown that non fine-tuned models like the base ChatGPT model were outperformed by a large gap \cite{Xue2024}.

The approach of \citet{Chen2024} showed the opposite, while proposing prompt tuning as technique to adapt \acp{LM} towards an open information extraction task. In difference to \citet{Xue2024} the relation were extracted among sentences instead of whole documents. The results showed, that using intelligent prompt tuning approaches can match state-of-the-art performance compared to open information extraction fine-tuning approaches. It has to be noticed, that \citet{Chen2024} as well as \cite{Xue2024} used different datasets than \citet{Josifoski2023} which limits the implications on the closed information extraction problem, but remains relevant for the overall approach in the field of information extraction.

The most similar approach to this work remains AgentRE from \citet{Shi2024}. In remarks of advances in using \ac{AI} agents, \citet{Shi2024} proposed a single-agent solution to open information extraction. This agent had access to a retrieval module and a memory module. The retrieval module was able to provide relevant samples and context from an existing knowledge graph. This included retrieving sample triples as well as relation descriptions. The memory module followed the idea of saving incorrect and correct triples extractions, while including the \ac{LLM} to process on self-reflection. The agent itself was in charge of making use of the modules, while also extracting the correct triples out of the given text \cite{Shi2024}.

This approach was tested against various different approaches on benchmarking data-sets that are non-related to datasets like REBEL or synthIE. Especially the used english dataset named SciERC, can be defined as rather limited and old \cite{Luan2018}. The experiments were conducted on GPT-3.5 Turbo and on a reasoning trajectory fine-tuned Llama-2-7B. The AgentRE approach outperformed the compared approaches on a majority of the datasets, showing the ability of \ac{AI} agents to tackle information extraction \cite{Shi2024}. As previously stated, the implications on closed information extraction remains limited also for this approach.

The related work shows, that apparent advances in \ac{LLM} reasearch can also advance results in open and closed information extraction. It has been shown that various approaches from fine-tuning over prompt-tuning to agent-frameworks can handle the subject of information extraction. Even more has been shown, that high quality dataset are crucial to train and especially benchmark models for closed-information extraction. Many of the outlined approaches are not including the advances of the most recent \acp{LLM} or do not work on the closed-information extraction and are therefore the results are not fully applicable on this work.

\chapter{Approach}
\label{ch:approach}

This work introduce a novel approach to closed information extraction using multi-agent systems. The overall idea is evaluate both the pipeline and joint approach to closed information extraction conducted by multiple specialised agents. In order to fullfil the task the agents should be able to access and retrieve data from the knowledge graph directly. Therefore the concept of tools should be utilised.

The general design follows to goal to achieve an multi-agent system that can be applied to real-world usage and therefore can handle various type of texts and extract triples out of them. This is why, the approach relies solely on prompt tuning and in-context learning rather than on fine-tuning models. The concept of limiting to in-context learning is based on \citet{Brown2020} achieving outperformance with in-context learning against other domain fine-tuned models. Additionally, recent advances of various \acp{LLM} to outperform prior models by a huge marging or match the performance of prior models while keeping lower parameter sizes \cite{MetaAI2025,Chiang2024} shows increased capabilities and can imply higher in-context learning abilities. The exact advances will be outlined in section \ref{sec:eval_language_models}.

This work followed an iterative approach in designing various multi-agent systems following the agent design best practises shown in section \ref{sec:agent_design}. As of my knowledge, there is no other work proposed using the multi-agent system approach to closed information extraction, which makes the iterative approach crucial. This approach is giving the ability to learn the limitations of the agents and then iterate with those ideas. From the output four core architecture arose. The baseline (section \ref{subsec:baseline}) structure following strictly the closed pipeline idea. The supervisor (section \ref{subsec:supervisor}) architecture splitting up tasks from the baseline. The ReAct architecture (section \ref{subsec:react}) as the opposite direction is simplifying all agents to one, while keeping the tools. The full network system (section \ref{subsec:network}) shows the abilities of having expert agents that are defining the flow through the agent system themselves.

In addition to the agents, multiple tools arose with the most important tool to fulfill the closed information extraction being the URI retrieval tool (section \ref{subsec:uri_retrieval}), which is designed to match search terms to URIs. To increase the knowledge graph incorporation, the tools of a network traversal search (section \ref{subsec:network_traversal}), a semantic validation (section \ref{subsec:semantic_validation}) and a turtle to label tool (section \ref{subsec:turtle_to_label}) were developed. Meaning that those tools have been developed does not imply that each architecture was connected to each tool.

The agents are designed as \ac{LLM} calls with a prompt template that is field with selected fields from the prompt. In theory, more and more \acp{LLM} in LangChain support structured output, meaning that the output of the \ac{LLM} is mapped automatically to a pre-defined scheme \cite{LangChain2025e}. As this structured output experienced as not supported by all models, this work relies on parsing instructions out of the text generation of the \acp{LLM} directly. This is done by requesting the \ac{LLM} to output specific XML-tags with information of the next agent, the final output, the instruction for the next agent or the tool input.

In addition, it has to be mentioned that all architectures were further advanced in regards of prompts and tools through the process, but especially those that were achieving the best results. As already stated, the process were imperative and so was the tool development, meaning that some tools were only developed for specific architectures. Further details which tools were evaluated for which architectures can be found in section \ref{sec:evaluation_configurations}.

\section{Agent Architectures}
\label{sec:agent_architectures}

In the following section the various agent architectures will be outlined. This is including the declaration which agents have been used and how the overall flow is desing. In addition the definition of the state and handoff will be shown per architecture.

\subsection{Baseline Architecture}
\label{subsec:baseline}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/Baseline Architecture.png}
  \caption[Baseline architecture showing the pipeline approach with specialized agents for each step of the closed information extraction process]{Baseline architecture showing the pipeline approach with specialized agents for each step of the closed information extraction process (self created)}
  \label{fig:baseline_architecture}
\end{figure}

The baseline architecture remarks the first approach used in this work to approach. This architecture follows the pipeline approach of closed information extraction by implementing two specialised agents for extracting and disambiguating the entities and forming triples. The idea follows the multi-agent priciple of splitting down complex tasks like closed information extraction is perceived \cite{Josifoski2021} into simple managable tasks. In addition, the baseline follows the overall principle of the supervisor pattern, by implementing one agent that defines the flow and communication between the agents. The URI retrieval tool is already included in this stage, in order to map the free-text triples to URIs. An overview of this architecture can be found in \ref{fig:baseline_architecture}.

The backbone of the baseline architecture remains the state. The state is build up of the fields text, messages and instruction. The text is part of each state and keeps the text that is being processed by the agent. The messages field is an array of messages send. Therefore, especially the supervisor agent gets access to the message history to prevent looping and enable targeted reasoning. The instruction can be filled with variable that should be given as an input to either a tool or other agents.

In a supervisor architecture like in the baseline the orchestration and routing relies solely on the supervisor agent. In this configuration the supervisor agent is the only agent, which has access to the full state. The supervisor is designed to take additionally care of agent results validation and to formate the final result. This means, that the supervisor is in charge to extract the entities and triples using the specialised agents and then evaluate whether those results are valid or if it has to reiterate with the agents to get better results or to get a entity disambiguation. Therefore, the supervisor agent can leverage the instruction field on the state to pass individual prompt instructions to the agents. With triples formed by the triple extractor, the supervisor agent then has to formulate search terms, that will be search using the URI retrieval tool. With the output the final task of the supervisor is to formulate a valid turtle output. In order to parse the next agents and the final output, the supervisor agent is using xml tags to delimit the parseable outputs.

The entity and relation extraction agent are related on prompt engineering. Therefore, both agents were initially used with a simple prompt asking for entity, respective relation extraction. Further details on the general prompt engineering approach can be found in \ref{sec:iterative_prompt_engineering}. The idea is that over time both agent can tackle the limited task of entity and triple extraction to a very good extend.

All in all the idea can be lead to a flow where first the entities get extracted and then the the triples get formulated. Then the supervisor should get the corresponding URIs and produce a final turtle output. If this straightforward approach fails, for instance because a URI can not be found as the entity or predicate in the triple is incorrect, the supervisor agent can then loop. This shows that in theory this approach can extend the simple workflow by refinements and limit error propogation.

\subsection{Splitted Supervisor Architecture}
\label{subsec:supervisor}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/Splitted Supervisor Architecture.png}
  \caption[Splitted supervisor architecture showing the decomposition of the supervisor agent into specialized sub-agents for better task management]{Splitted supervisor architecture showing the decomposition of the supervisor agent into specialized sub-agents for better task management (self created)}
  \label{fig:splitted_supervisor_architecture}
\end{figure}

As in the baseline archiecture, the supervisor agents has the task to plan the task, route the task to right agent or tool with the correct instruction and then evaluate the observations from the agent and the URI retrieval tool following up with a refinement of the plan or the output of a turtle string. This task is a rather complex one, especially if the idea remains to iterate over the closed information extraction task. The \ac{SSA} is a step in the iterative agent system design process, to adapt towards \acp{LLM} which are not able to process as many tasks at the same time alongside with an increasing prompt and context size. Therefore, the supervisor agent is split up into a planner, agent instructor, result checker and result formatter agents. In addition the specialised agents (Entity and Triple Extractor) were completed by an property extractor. As the property extractor was added during the iterative process, an exact evaluation of the introduction of this agent can be found in section \ref{subsec:error_message_incorporation}. An overview of the architecture can be found in figure \ref{fig:splitted_supervisor_architecture}.

The state is redefined in the \ac{SSA}, according to provide more overview to the supervision agents (planner, agent instructor and result checker). This means in addition to the text and the instruction, a call trace, a results and a comment field was implemented in the state. The call trace is used by the agent instructor to save which specialised agent or tool was called with which input. The results field is than the counter part where every result of the specialised agents and the URI retrieval are saved. At last, all comments made by the supervision agents are written into the comments field. Doing so, the actual closed information extraction results can be seperated from the overhead communication made by the supervison agents within the state. Furthermore, this can also separate the information within the prompt with idea to give the agents are pre-structured overview of the flow within the multi-agent system.

The planner agent is the central point within the \ac{SSA}. It generates an initial plan and decides whether to how to proceed with the plan or finish the flow by handing over to the result formatter. If the next step of the plan should be executed, the agent instructor refines this action into parseable agent id with the matching instruction. The idea behind is, that the planner can fully concentrate on planning, while the agent instructor can parse ideas into actions. Using a result formatter agent follows this idea and is added up by the complexity of providing a valid turtle output for the selected datasets. In addition, the result formatter is used to put all pieces of information like URI retrievals and extracted triple together.

The result checker agent follows the idea of a real supervisor. It has the task to look onto whether the specialised agents are producing correct results. In addition, the result checker agent should give the planner ideas how to refine the overall processing plan and what information are missing. Therefore, the result checker agent should induce iterating over the closed information extraction task.

The entity extractor and relation extractor agents are designed like in the baseline architecture, but are changed in the point in which field they save their outputs to. The property extractor agent follows the overall plan of the practises designed in section \ref{sec:agent_design}. This means, that the relation extractor is taken apart the task to identify the properties within text. The URI retrieval tool is similar to the one in the baseline archiecture, but as the agents, so does the URI retrieval tool save its output to the results field of the \ac{SSA} state.

Overall the \ac{SSA} is an extensive interpretation of splitting up complex tasks. Therefore, it follows an custom architecture pattern similar to the original supervisor pattern. In addition, the state is changed in order to provide more overview for the added overhead of more agents.

\subsection{Simplified Splitted Supervisor Architecture}
\label{subsec:simplified_splitted_supervisor}
\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/Simplified Splitted Supervisor Architecture.png}
  \caption[Simplified splitted supervisor architecture showing a streamlined version of the supervisor decomposition with optimized agent interactions]{Simplified splitted supervisor architecture showing a streamlined version of the supervisor decomposition with optimized agent interactions (self created)}
  \label{fig:simplified_splitted_supervisor_architecture}
\end{figure}

The \ac{SSSA} is following the general idea of the \ac{SSA}, but uses a simplified supervisor splitting. Based on the assumption that a single supervisor can handle all supervison task, but struggles with putting together the triples and URIs to valid turtle strings and using an unstructured state as context. Therefore, all specialised agents remain the same as in the \ac{SSA} and result checker and agent instructor are merged into the planner agent similar to the supervisor agent of the baseline archiecture. Additionally, the mapping of results of the agents is adapted to an updated and more structured state. An overview of the the architecture can be found in figure \ref{fig:simplified_splitted_supervisor_architecture}.

A core change in comparison to the \ac{SSA} is the overall structure of the state. In order to sleeken the state, the \ac{SSSA} state just keeps the core of the result of the specialised agents. This means, that the state has now field for entities, properties, triples and URI mapping instead of a single results field. Those fields will be filled by the specialised agents and the URI retrieval.

As this state change deletes the full output of specialised agents and of the URI retrieval, a field agent response is added that exposes the full output of the speicalised agent, but also tools to the planner to detect, if the agent are processing the tasks given correct. In order to prevent looping, the message field in the state remains the same, but is now the output history of the planner agent.

Overall the \ac{SSSA} is designed for less resource consumption and more efficient context use. The architecture is mainly designed towards context limits, that can apply, while keeping the idea of iterating over the process. In addition, it is another approach to split up the supervisor agent and therefore it remains an architecture following the custom multi-agent system pattern.


\subsection{ReAct Architecture}
\label{subsec:react}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/ReAct Architecture.png}
  \caption[ReAct architecture showing the single-agent approach with reasoning and action capabilities for closed information extraction]{ReAct architecture showing the single-agent approach with reasoning and action capabilities for closed information extraction (self created)}
  \label{fig:react_architecture}
\end{figure}

All previously shown solution rely on multi-agent system, as of the assumption of high complexity wihtin the task of closed information extraction. The ReAct architecture is targetting an opposite direction. The idea is to show, how capable a single-agent system with reasoning capabilities can be, as simplicity often showed empirical success within the work. In addition, the ReAct architecture can solely concentrate of incorporating with tools other than incorporating with agents which increases the possiblity for failures. Like already state in section \ref{sec:related_approaches} a joint-optimisation has the advantage of a single-optimisation point with no error propogation. The ReAct architecture follows this joint-optimisation. Another conceptual advantage is that the agent calls are reduced, which results in lower cost and lower inference latency.

The state is also made simpler than in the \ac{SSA} and \ac{SSSA}. As the agent calls get reduces, so does the context. Therefore, the baseline state shown in section \ref{subsec:baseline} is used as well. The tools are writing their outputs into the messages field.

As the agent is limited in its availablity to handle the task to the full extend, it is initially given URI retrieval tool. As the ReAct architecture showed a good optimisation capability further tools were developed for it. First, there were tools to incorporate and communicate with the knowledge graph, namely the network traversal, semantic validation and turtle to label tool. Second, to give the agent the ability to manage the context, a message deletion tool was implemented. A overview of the tools used in the ReAct architecture can be found in figure \ref{fig:react_architecture}. As outlined, there were multiple iterative steps within the development of this architecture. All of them will be review in section \ref{sec:evaluation_configurations}.

The ReAct architecture is not a multi-agent system, but it remains one step to contrast highly complex systems in order to develop an understanding of the \ac{LLM} used for the closed information extraction. As of its cost efficiency it remains a good point to start to develop more tools and to test which of them are providing a leap over the previous configuration. Therefore, the ReAct architecture is a logical iterative step to a target architecture.

\subsection{Network Architecture}
\label{subsec:network}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/Network Architecture.png}
  \caption[Network architecture showing the fully connected multi-agent system with dynamic routing and reasoning capabilities]{Network architecture showing the fully connected multi-agent system with dynamic routing and reasoning capabilities (self created)}
  \label{fig:network_architecture}
\end{figure}

The network architecture following the idea of the network pattern outline in section \ref{sec:multi_agent_systems} is the result of the experience made with all previous architectures but also with all different configurations of tools and states. Therefore, the idea is to leverage the reasoning and validation capabilities build up within the \ac{SSA} and \ac{SSSA} and combine it with a direct triple extraction approach like shown in the ReAct architecture. In addition, the network architecture spreads the decisions about the flow on all used agents. The resulting architecture figure can be found in figure \ref{fig:network_architecture}.

The state of the network architecture is a extension of the idea within the state of the \ac{SSSA}. The idea is again to save intermediate results in a context efficient way. Therefore, the fields triples and uri mapping are again part of the state. The URI mapping contains in this architecture the label of the entity or predicate alongside with the URI and the label and description stored in Wikidata.

In addition, a call trace is introduced again to prevent looping and enable logical reasoning. To provide a good overview, the last agent or tool call is stored alongside the response in the fields \texttt{last\_call} and \texttt{last\_response}. In addition, the \texttt{agent\_instruction} field is introduced to persist the instruction given to an agent by a previous agent, while not being dropped within a tool call. The input to any tool is persisted in a \texttt{tool\_call} field. A \texttt{message} field is also introduced, but unlike in other architectures, in the network architecture it is used to output the final result, which is based on interoperability considerations.

This architecture is also thought to minimize context length by not having any field in the state that builds up content increasingly except for the call trace. Therefore, the agents have to decide on the next steps utilising the previous call trace and the current results. This increases the reliability requirements for each agent and could potentially be a point where heavy prompt engineering must be used.

Agent-wise the network architecture uses three agents, which all have access to the full-state, while the tools are using solely the tool input given by the agents. This is done, because each agent needs to have the full overview to take better decisions on the overall agentic flow. All inquiries start at the extractor agent, which follows the idea of the main agent in the ReAct architecture, but splits the URI mapping, triple validation and turtle output part from it. The extractor agent has write access to the triples as the only agent in the architecture.

The URI mapping is done by the URI mapping and refinement agent. It is thought to be the central place where the URI mapping gets generated or changed on request. Therefore, it is the only agent with write access to the URI mapping. The agent is also bound to the triples extracted by the extractor agent. Tool-wise the URI mapping and refinement agent has access to the URI retrieval tool.

The validation and output agent has the task to prevent halucination of the agents and also validate triples based on semantic features which are used in the knowledge graph. Therefore, the agent is asked in its prompt to do a semantic validation followed by a turtle to label conversion to check the results. Both steps are based on tools that are connected to the validation and output agent. The validation and output agent is also the point to refine and polish the results, if they fall through a validation. Then the agent is able to call either the extractor or the URI mapping and refinement agent again, in regards where it assumes the error can be solved.

The network architecture is a results of the experience gathered throughout prior work. Therefore, it already misses out on unpromising tools or uses a highly tweaked state. In the end, the network architecture remains a multi-agent system in its core idea, while keeping the overhead and context length minimal.

\section{Agent Tools}
\label{sec:agent_tools}

The agents in the various architectures are the core of the solution to the closed information extraction. As \acp{LLM} are limited in their knowledge and also can show hallucination like shown in section \ref{sec:language_models}, the tools are necessary to limit both caveats and on the other side improve the performance. Therefore, two general types of tools are used in this work. First, the knowledge graph incorporation tools, which are URI retrieval (section \ref{subsec:uri_retrieval}), network traversal (section \ref{subsec:network_traversal}), semantic validation (section \ref{subsec:semantic_validation}) and turtle to label (section \ref{subsec:turtle_to_label}). Second, the tools to orchestrate the agent system. In this work, just the message deletion tool (section \ref{subsec:message_deletion}) is proposed.

\subsection{URI Retrieval}
\label{subsec:uri_retrieval}

The URI retrieval tools remains a central tool in solving a closed information extraction task. Various \ac{LLM}-based agents can achieve a extraction of free-form triples, but the challenge of closed information extraction remains in the correct mapping to the underlying knowledge graph. Therefore, this URI mapping ability is given to the agents by the URI retrieval tool, which is able to incorporate with the knowledge graph.

The general idea of the URI retrieval tool is to get individual search terms of the agent and then search for it using embeddings and their cosine similarity. The instructions are ideated to be variied throught the iterations. Therefore, the agents can re-search for entities or properties that were not found by using the simple free-form text.

In order to provide embeddings of the underlying knowledge graph it is needed to pipeline the generation of a search index. The pipeline is executed against the Wikidata knowledge graph, as this is the only knowledge graph used in the benchmarks evaluated in this work. In the final implementation three search indices exist. Those indexes keep embeddings for either the \texttt{rdfs:label} or \texttt{rdfs:description} of an entity in Wikidata. The third search index is saving triple examples for the use of a specific properties out of Wikidata. The idea is, that the sentence embeddings can embed semantic features of subject and object, which later can be retrieved by the agents.

The pipeline works in three steps. The first step is loading a dataset split like the test-split on synthIE with a limited number of documents to be loaded. The second step is to get the label and description for all entities and properties inside the data loaded. In addition, the example triples for the properties will be retrieved for the properties if existing in Wikidata. In a third step all parts will be embedded and saved into the corresponding search index. In order to provide label and description as well as a distinction between entity and property, those data will be stored as metadata in the search index.

In order to provide access to the various collections, the URI retrieval tool required search modes in the instructions. This means, that the agent can decide whether it wants to similarity search its search term agains all labels, description or examples of an entity or property. In addition, as the URI retrieval tool can access the type of a stored point in the search index, the instruction does get another filter mode, where the agent can decide if it searchs solely for entities or properties. In the last implementation a mixture of search and filter modes is used. In this case the agent can decide whether it search for entities or properties by its label or it searches for properties by an sentence. The trajectory of the work resulting in this limitation can be found in section \ref{sec:evaluation_configurations}.

The URI retrieval tool itself parses the instruction and the search mode, respective filter mode per search term. Afterwards, it execute a cosine similarity search using the embedding of the search term on the selected search index. The search result includes the most similar results with their rdfs:label, rdfs:description and their URI.

In cases with agent architectures that are prone to have a problem with context bloating, this can show problem when many search terms are used. In order to take care of this, the URI retrieval tool gets an additional \ac{LLM} call, that should evaluate if one search result matches by looking on the given output. Afterwards it returns a simplified URI mapping, with a reason why a mapping has been choosen, but without the full information about other results and information about descriptions of the search results. This is especially used in the baseline architecture, the \ac{SSA} and the \ac{SSSA}.

All in all the URI retrieval tool is ideated to give the agent the maximum flexibility in searching matching results. Therefore, it indexes the relevant parts of Wikidata within a search index, which later can be retrieved by the agents, which in general follows a retrieval augmented generation idea. As the URI retrieval tool is the tool where much accuracy can get lost, it is the most changed tool throughout the work, which can be seen in section \ref{sec:evaluation_configurations}.

\subsection{Network Traversal}
\label{subsec:network_traversal}

The network traversal tool is the next step in knowledge graph incorporation. The idea targets the problem of agents choosing super or sub-properties of a searched property. This problem could arise especially, when the sentence does not include the exact label of the searched property. The network traversal tool should give the agents the ability to get insights in the knowledge graph property hierarchy by executing SPARQL queries on the knowledge graph.

In Wikidata the property \textit{subproperty of} is used to show this relation. The SPARQL query then searches for all direct super- and subproperties of a targeted property. In addition the SPARQL query is enhanced by a label query, searching for the corresponding labels of the found properties. Then the network traversal tool creates an output consisting of the label and example triple, if one exists for the found property.

Some properties can have a vast amount of super- and subproperties. This can lead to a unsorted output, where \acp{LLM} can struggle selecting the relevant property from the output. That is why, in later implementations the network traversal tool checked the possible properties for property constraints. In Wikidata there are subject and object type constraints, that can be accessed behind qualifiers.

Qualifiers in wikidata is a triple consisting of a predicate and an attribute \cite{Wikidata2025}. For the subject and object type constraint, the property named property type constraint is used. This property has either the property subject type constraint or the property value type constraint for the object. The attribute is than the actual URI of the type that the original property is constrained to.

Using this knowledge the SPARQL query used in the network traversal tool could output whether a properties subject and object type constrained have been matched or not. This is also done by using one level of superclasses above the type of the particular subject or object in the corresponding triple. This is limited due to the exploration about infinite looping by not restricting, when accessing Wikidata directly like done in this implementation.

Utilising the output of the network traversal tool, the agents are enabled to detect to narrow or to wide property extractions. This gives a better insight in knowledge incorporation for the agents and can make the results more correct. Nevertheless, the network traversal tool can produce a high amount of results, which can be adding overhead to the agents, as they have to decide if any of the resulting properties is fitting better into the extracted triple, while resisting properties that might match the property constraints more, but could be either to narrow or to wide.

\subsection{Semantic Validation}
\label{subsec:semantic_validation}

As \acp{LLM} can show hallucination and additionally do not have the build-in the ability to double check their results, the semantic validation was ideated as solution. The overall idea is like in the network traversal tool, to check for type restrictions on each property of each resulting triple. The semantic validation tool uses a pre-filtered Wikidata class hierarchy, which is loop-free and therefore enables to search across the full hierarchy.

The semantic validation tool gets as input a ready turtle string, which gets checked and afterwards splitted into triples and per triple in subject, property and object. Then the in subsection \ref{subsec:network_traversal} explained qualifiers are utilised to check for subject and object type restrictions. In addition, the semantic validation tools also detects, whether there is a subject or object type restriction at all. In the end it outputs the results per triples back to the agent.

Therefore, the semantic validation tool is rather simple, but remains powerful in creating valid results. With the semantic validation tool the agents can detect whether a property could be meant for another type of relations, when the descriptions and examples in the URI retrieval tool could not bring this recognition. This enhances the knowledge incorporation that other solution do not make use of and is intended to give agents the starting point for iteration.

\subsection{Turtle to Label}
\label{subsec:turtle_to_label}

The agents have shown multiple points, where wrong URI were used because of copy failures or internal knowledge incorporation. As Wikidata is one of the biggest knowledge graphs, it can be assumed that it was part of the training data used for \acp{LLM}. As wikidata uses the same namespace to define entities and properties and especially relations to other properties, labels or descriptions, but uses a different namespace for the actual property in the used triples, and Wikidata knowledge can be present in the \ac{LLM}, it is crucial to check if the output was generated in the correct namespace. Especially as other tools leverage SPARQL queries on property hierarchies, the output in CIExMAS is limited to the Wikidata entity namespace, which can lead to mismatches.

The turtle to label tool therefore tries to leverage the final turtle output string to collect labels for each part of each triple. This is done by using a simple SPARQL Query asking for the value behind the rdfs:label of every part. This query fails, when the resulting properties are in the wrong namespace. In addition, the \ac{LLM} can hallucinate the URIs completely, which is shown by the turtle to label tool as it outputs the free-form triples again, but also checks whether a URI exists or not. The output also contains a corresponding message, when a URI exits but it has no english label.

The turtle to label tools is overall another tool to incorporate with the knowledge graph directly. The ability for the agents to check if any agents before createc hallucinated results, is crucial to decrease later errors in the final result, while also limiting hallucination. Together with the semantic validation, the turtle to label tool can increase the precision of the final results.

\subsection{Message Deletion}
\label{subsec:message_deletion}

In multiple chapters was the topic of context bloating a topic that should be miminised by the design of agent, state and tools. Another approach is to give the agents an ability to manage the context themselves. Therefore, the message deletion tool was implemented.

The message deletion tool can enable the agents to delete messages in the state by their id. This is especially important, as this tools was developed for the ReAct architecture. As this architecture has a single message field, where all output of the main agent and the tools is saved and tools like the network traversal tool or the URI retrieval tool tend to produce a high amount of output, the message field can bloat the context quickly. On the other side, the agents sometimes just reuse content and have the ability to summarise content. Therefore, the agents could also be able to delete single message out of the messages field and generate a sleeker summary of the core knowledge gained through the deleted messages.

Alongside with the ability to edit fields in the state like the triples field in the \ac{SSSA} or network architecture, the message deletion tool enables the agent to self-manage the state and context. This gives the opportunity of not getting any context length errors. Nevertheless, this adds complexity to the agents, as they have to create summaries but also decide which message are not useful anymore. The corresponding results can be found in section \ref{sec:evaluation_configurations}.

\section{Iterative Prompt Engineering}
\label{sec:iterative_prompt_engineering}

As outlined in the sections \ref{sec:ai_agents} and \ref{sec:multi_agent_systems} \acp{LLM} are prompt sensitive. Therefore, finding the correct prompt remains complex and challenging. As this work focusses primarily on developing various architecture of multi-agent system and proof that knowledge graph incorporation can lead to better results, the prompt engineering was done manual in the iterative process.

Overall the prompting followed the ideas from section \ref{sec:agent_design}. This means, that overall the prompts are written and evolved, so that a human can handle the task. In addition, the prompt uses examples to drive in-context learning. In the iterative process those examples either have been examples for tool instructions or examples from the dataset used for tasks like entity extraction. In the last case the original text was given with the expected entities from the dataset. The idea is to give the dataset an example what kind triples are expected in the use case.

Another technique that was used is guided \ac{CoT}. Therefore, the agents got the instruction to follow a predefined prompted \ac{CoT}. In addition to this technique most of the prompts were build out of a role introduction, the tools with descriptions if the agent could decide of the agentic flow, guidelines, examples and the state inputs. The guidelines were especially used to prevent edge cases and problems that were experienced. In contrast, the role instruction stayed similar to the start of prompting in general.

Like outlined in section \ref{sec:agent_design} the tool description are crucial to enable the agents to make use of them. In CIExMAS the tools will be incorporated through the prompt directly. This means, that like outlined, there is a section where the tools will be described. Each tool is described by its ID, its name and a description. The description is also the place, where instruction definitions were done. Especially with tools like the URI retrieval, this is important to enable the agents with the correct instruction, like using the correct search and filter modes.

Overall the prompt engineering in CIExMAS remains a manual and iterative process. The prompting is heavily adapted to best practises shown by other researchers. This includes the design of human-readable prompts, that are structured, well defined and include examples for the use of tools or for solving the tasks.

\section{Error Handling}
\label{sec:error_incorportion}

As \acp{LLM} are designed to generate unstructured outputs in form of texts, problem can arise when specific output tags or a specific form of output is expected. Therefore, a solution can be, that the reasoning and looping abilities of agent system can be used to incorporate error message into the agent flow. Leveraging this idea, agents can correct wrong behavior, especially when the error message are clear and understandable.

Therefore, in the iterative process of creating CIExMAS, more and more agents and tools are made error prone. This is done by using simple try except blocks, while the except block generates a specific message, for the problem. Those try except blocks are mainly done when tag parsing is done from the output of an agent. Like described in the agent architecture sections before, this is especially the case when an agent gives instructions and decides on the agentic flow. There are mainly one goto and one instruction or input tag that has to be read out. At every point, the agents can fail to include one of those, which is why there are try and except blocks around the parsing section detecting, which tags might be missing.

In addition, the agents can produce inputs to tools, which can not be interpreted. That is why also tools get the try and except handlers for parsing inputs. Like for the agent output parsing, the instruction parsing also gives dedicated error message to the error.

Another problem of the agents are incorrect outputs. Like already shown in section \ref{subsec:semantic_validation} and \ref{subsec:turtle_to_label} the agent systems used in CIExMAS have multiple tools to reduce hallucination and incorrect outputs. Nevertheless, the final turtle string has also to be syntactical valid, meaning for instance that when prefixes are used, they have to be defined. To tackle this, in the final implementation, the outputs will be checked against a turtle parser, which produces errors, when the output is syntactical incorrect. This error can also be incorporated back into the agent system and then be processed.

With this measures, various errors from parsing issues to syntactical issues can be detected and processed. In addition, the error message incorporation also adds error handling, which enables the agent system to not stop when an error occurs, expect for external errors like context overflow or GPU memory problems. Together, the error handling in the whole system can enable better results and can enable to get a valid result for all datapoints.

\chapter{Evaluation}
\label{ch:evaluation}

This chapter is about the overall evaluation of the effectiveness of multi-agent system in doing closed information extraction. In general, the multi-agent system was build using python. The overall setup of it including the used datasets and Wikidata incorporation, the used language models and used frameworks will be explained in section \ref{sec:evaluation_setup}. Furthermore, the calculation of the evaluation metrics which are used for the comparison later will be outlined in section \ref{sec:evaluation_metrics}. The results within this evaluation will be done in section \ref{sec:evaluation_configurations} leading by an overview comparison of the best CIExMAS configuration to the approaches synthIE \cite{Josifoski2023} and GenIE \cite{Josifoski2021} on the a split of the synthIE dataset \cite{Josifoski2023}. This will be followed by the single interation steps and their results. In section \ref{sec:discussion} all results will be concluded and interpreted.

\section{Evaluation Setup}
\label{sec:evaluation_setup}

The evaluation setup consists out of three essential parts. First, is the subsection \ref{sec:dataset} about the dataset used for the evaluation and espeically which split of it is used. Additionally, the subsection contains details about where external information are stored for the information. Afterwards the language models and providers will be outlined in subsection \ref{subsec:eval_language_models}. The evaluation setup will be concluded by section \ref{sec:evaluation_setup} about the concrete agentic framework used. In addition, huge parts of the work is traced using the open-source application LangFuse \footnote{available under \url{https://langfuse.com}}.

\subsection{Dataset and Comparison Models}
\label{sec:dataset}

The evaluation is based on the dataset synthIE, with one experiment conduct using REBEL. Both datasets, which are described in section \ref{sec:related_datasets}, contain triples, that are extracted out of a given text. Each extracted triples contains unique identifiers from Wikidata for each part of the triple, which make them ideal for closed information extraction. Each identifier could be resolved within the entity namespace \texttt{https://www.wikidata.org/entity/}.

Both datasets follow a similar structure. Both datasets are stored in json lines, which is a line separated format of objects consisting of entities, relations and triples. Each entity and relation, which can also be named as property, is further split down into a surfaceform and uri, which is a unique identifier. The surfaceform is exactly how the entities and relations are written in the given text. The uri field is the local part of the Wikidata Qname. A Qname itself has a prefix, which is the namespace in the case of Wikidata, and a local part which is the unique identifier \cite{ASF2010}. This means that the uri field is for instance Q120 with the surfaceform \enquote{June}. The full entity \enquote{June} can only be detected in the namespace of \texttt{https://www.wikidata.org/entity/}. The triples contain of a subject, object and predicate, which itself are build up like entities and relations.

As already outlined in section \ref{sec:related_datasets} there are two datasets of synthIE, which are synthIE-code and synthIE-text. Both versions of the datasets differ in the GPT-3.5 model used for the text generation. As the text model showed better performances, the evaluation is strictly done on synthIE-text.

Nevertheless, all evaluation configurations until section \ref{subsec:knowledge_graph_integration} were developed on synthIE-code, as of the larger amount of training data could have provided are more extensive development set in order to detect as much edge cases as possible. For development reasons, the train-split of synthIE-code was used for those configuration and sorted, so that the document with id one is the first in the jsonlines file.

As of upcoming limitations due to dataset quality and the experience of developing on at most ten examples, the latest developments were done on the validation-split of synthIE-text, which is also sorted and includes the same underlying triples but different text. The validation split is used, as synthIE-text does not offer a train split. In the end, this offers a higher quality of text and might produce more solvable edge cases, than triples that are hard to find in the text.

The evaluation was done for all comparison models and evaluation configrations of CIExMAS on the first 50 documents within the sorted test split of the synthIE-text datasplit. The number was choosen based on limitation in computing capacities, especially for agent call intense architectures like \ac{SSA} or \ac{SSSA}. Again synthIE-text was choosen, as it was perceived by \citet{Josifoski2023} to produce improved results in comparison with synthIE-code without changing the training dataset, which implies a higher dataset quality. In addition, the experiments have shown a more detectable result of triples.

To illustrate the distinction between \texttt{synthIE-code} and \texttt{synthIE-text}, the first document of both datasets is shown in the following example. In the \texttt{synthIE-code} version, the sentence reads: "\emph{'Groovin' Blue' is an album by Curtis Amy, released on Pacific Jazz Records.}" In contrast, the \texttt{synthIE-text} version presents a variation: "\emph{Groovin' Blue was released on Pacific Jazz Records and performed by Curtis Amy.}" While both versions encode the same structured triplets, which can be found in table \ref{tab:triple-example}, the textual surface varies. The synthIE-text version already gives a hint on the exact property, which in the case of synthIE-code is harder to find.

\begin{table}[h]
  \centering
  \begin{tabular}{l l l}
    \toprule
    \textbf{Subject} & \textbf{Property} & \textbf{Object}        \\
    \midrule
    Groovin\_Blue    & record label      & Pacific\_Jazz\_Records \\
    Groovin\_Blue    & performer         & Curtis\_Amy            \\
    \bottomrule
  \end{tabular}
  \caption{Surfaceform Triplets - DocID: 0 - synthIE Code \& Text}
  \label{tab:triple-example}
\end{table}

As it was planned to benchmark the best CIExMAS models on the REBEL dataset, the first 50 samples in the sorted test-split were uploaded in the vector databases. Like already outline, CIExMAS focussed mainly on synthIE as foundation for developing the agents, which could conclude in worse results on REBEL. As of testing, no approach scored over 0.1 F1-score, which is why REBEL was not further used for evaluation. The results of the testing can be found in the section \ref{sec:rebel_testing} of the appendix.

Both datasets were evaluated on various different models before. Espeically for the synthIE dataset, the solutions of \citet{Josifoski2023} synthIE- and GenIE were used as they were used pre-trained under \url{https://github.com/epfl-dlab/SynthIE}. For the synthIE solution all three versions synthIE$_{T5-base}$, synthIE$_{T5-base-SC}$ and synthIE$_{T5-large}$ were evaluated. For the GenIE solution the version GenIE$_{T5-base}$ and GenIE$_{T5-base-SC}$ were tested. The abbreviation \textit{SC} stands for subject-collapsed, which means, that those variants outputs subject grouped triples. All models are using the Flan-T5 \ac{LM}. Like the CIExMAS solution, those solutions were also evaluated against the same samples of synthIE-text.

In the end the REBEL dataset showed very low scores on testing on the best models like depicted in the appendix \ref{sec:rebel_testing}. To provide an example of the data quality, in the following sentence \enquote{Richard H. Weisberg is a professor of constitutional law at the Cardozo School of Law at Yeshiva University in New York City, a leading scholar on law and literature.}, the two triples \textit{(Cardozo School of Law; headquarters location; New York City)} and \textit{(Yeshiva University; located in the administrative territorial entity; New York City)} are expected. This is just a very small subset of triples, that could be derived from the text. In addition, many texts are spreading across two paragraphs, making the \ac{cIE} task harder. As the scores were below 0.1 F1 for the triple extraction and the triple quality in this test set can be found below what is human extractable, it was decided to not further proceed with an REBEL optimisation.

Overall the first 50-sample sorted synthIE-text dataset serves as benchmark for CIExMAS and comparison models. In addition, the dataset can also show which evaluation configuration changes had which impact on the overall performance.

\subsection{Knowledge Graph Access}

Like outlined in various sections about knowledge graph incorporation tool in section \ref{sec:agent_tools} it is necessary to provide the agent system direct access to Wikidata as underlying knowledge graph. To provide faster latency this is done by a system consisting of Qdrant as vector database, Redis as key-value storage and Apache Jena Fuseki as local SPARQL endpoint. All of this is hosted on a virtual private server, which provide lower latency than using the SPARQL endpoint of Wikidata directly. Nevertheless, a direct access to the Wikidata SPARQL endpoint is used in the network traversal and turtle to label tool to get the restrictions directly.

The URI retrieval tool, like already outlined in the corresponding subsection \ref{subsec:uri_retrieval}, needs a search index to produce relevant mappings. In this evaluation each search index is one collection in the hosted Qdrant vector storage. It has to be mentioned, that using some kind of database that supports similarity search was necessary to support the outlined approach.

In order to fill the Qdrant collections, the relevant data was pre-collected for all development and benchmarking datasets and their corresponding samples. This means that also when developing and benchmarking on synthIE dataset, the benchmarking parts of REBEL, meaning entities and properties are indexed in all collections of Wikidata. This is based on the goal to make CIExMAS real-world ready, where it would have to decide out of the whole underlying knowledge graph, while keeping the collections manageable. On the otherside, this enabled a simple dataset switch in either development or benchmarking.

As already stated, the semantic validation needed a loop-free hierarchy graph of the entities and properties of Wikidata. To provide them across various machines, a instance of Apache Jena Fuseki was hosted with a class- and a property-hierarchy. As those graphs were also smaller, this gave another performance boost over calling the SPARQL-endpoint of Wikidata directly.

The key-value store Redis is used for faster data processing pipelines and debugging. This means, that the redis primarily stores, which data from Wikidata have already been stored into the Qdrant database. Alongside it also stores the label, the description and the type of element saved from Wikidata, so that also the displaying the labels is faster. Displaying labels faster also saves time, when for instance benchmark runs have to be evaluated in detail and each URI must be transformed into a human-readable label.

Overall the usage of a vector store is necessary to solve the task of closed information extraction with the CIExMAS approach. Furthermore, things like a triple store and a key-value store can help to make information available across multiple machines and decrease latency. Combined this enables the overhead of preparing and executing of the agent system to be low.

\subsection{Language Models}
\label{subsec:eval_language_models}

The choice of a language model is a very complex task in regards of a multi-agent system. For such a task, the \ac{LLM} has to be able to follow prompts, plan, reason about tasks, but also have to extract triples and know how knowledge graphs triples are typically build. In addition, from the kick-off of the CIExMAS project until the end multiple models have been published. Those models were also not tested before on the related approaches to CIExMAS, which lets the evaluation start at the foundation.

An additional limitation is the system used to benchmark as well as the providers used to develop the system. The benchmarks were all executed on 2x Nvidia A100 with 48GB VRAM, which had to run the \ac{LLM} using vLLM \footnote{available under \url{https://docs.vllm.ai/en/latest/}} and the embedding model using Ollama \footnote{available under \url{https://ollama.com}}. Therefore, the \ac{LLM} parameter limit was experienced at circa 70 billion parameters for a 4-bit quantised \ac{LLM}. In addition, the extensive development and evaluation was limited to open source models, as of the traceability of CIExMAS and to offer more flexibility in model use. Additionally, the evaluation could be done on local servers instead of using credits at AI vendors for the token instense benchmarking.

In the course of the work, Llama 3.3 70B showed the best performance in the outlined capabilities, especially in executing a multi-agent system and following instructions. That is why all benchmarks of CIExMAS except for the model variation were done on a 4-bit AWQ model of Llama 3.3 70B named \texttt{kosbu/Llama-3.3-70B-Instruct-AWQ}. The high performance also matches with the benchmarks executed by \citet{Meta2024}, which showed a similar performance to GPT-4o or Claude 3.5-Sonnet, which were state-of-the-art models back at the time, but needed more parameters and are no open sourced. The Llama 3 Series furthermore is build like the GPT models, but could leverage a large scale of high quality data, which reduced the parameter size down to 405 billion parameters in Llama 3 and 70 billion parameters in Llama 3.3, while keeping the performance up \cite{Grattafiori2024,Meta2024}.

More recently Google released a new open source model called Gemma3 which got ranked one of the best models on the human-evaluated LMSys Chatbot Arena \cite{Chiang2024}, while maintaining a low number of 27 billion parameters \cite{Team2025}. Nevertheless it showed slightly lower scores than Llama 3.3 70B in for instance the MMLU-Pro benchmark. Furthermore, the Gemma3 model showed shortcomings in instruction following and executing a logic agent flow.

In addition, newer model architectures like Mixture-of-Experts or reasoning models became present with the rise of Deepseek-R1 or the Meta Llama 4 models \cite{DeepSeekAI2025,MetaAI2025}. Those models have also shown high benchmarking results, while keeping the parameters lower then top-end state-of-the-art models. Those models partly have shown higher performances, but as the reasoning capability keeps looping over the LLM and produces a higher need for tokens as well as higher needs on resources, those models were not used for development due to hardware and time limitations.

Nevertheless both Gemma3 and Meta Llama 4 are used to test different models with the best evaluation configuration of CIExMAS. Therefore, the whole configuration stayed the same. This can lead to expositions of the prompt senstivity of the other models, which can show underperformance in comparison to a perfectly adapted prompt. In order to use Gemma3 on the given setup, a 4-bit GPTQ-quantised version named \texttt{ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g} was used. As the best version at the time is Llama 4 Maverick and this model requires over 96GB of VRAM, that the two available Nvidia A100 GPUs offer, the evaluation on Llama 4 Maverick was done on SambaNova Cloud, which is a provider for LLM inference.

All in all, Llama 3.3 70B remained the ideal model for fast development using SambaNova Cloud and the unquantised Llama 3.3 70B model, while the main evaluation was done on the quantised model. This model already provided a great leap over the previous used \ac{LM} of \citet{Josifoski2023}. Therefore, the model advance are included in CIExMAS. To test even more recent advances, other models were also included in the evaluation.

\subsection{Agentic Framework}
\label{subsec:agentic_framework}
In order to evaluate any agentic system, an agentic framework is needed. As the \ac{LM} and the embedding model run on vLLM and Ollama, while the \acp{LLM} in development are called from cloud providers, the agentic framework is also required to support those requirements. In addition it needed to support custom states like outlined in chapter \ref{ch:approach}.
A package that supported those requirements and had the flexibility to be extended was LangGraph like already stated in section \ref{sec:multi_agent_systems}. As LangGraph implements mainly flow features, but in the form used does not interact with the \acp{LLM} directly, the \ac{LLM} and embedding model access were again flexible. The decision was taken on LangChain, as LangGraph and LangChain were integrated into each other. Therefore, the monitoring using Langfuse can be done seemlessly on the agent overview level. This gives the outlined capability of agent tracibility outlined in section \ref{sec:agent_design}. Another advantage of LangChain is the wide availability of adapters to various LLM providers. In addition, all frameworks are also open-sourced projects and have big communities what was supporting the creation of CIExMAS.
In the end, many agentic and \ac{LLM}-frameworks in general could be used. Nevertheless, the combination out of LangChain, LangGraph and Langfuse was taken due to their match in requirements and wide-spread usage in the community. With those tools, the best practises of agent design are enabled for the implementation of CIExMAS.

\section{Evaluation Metrics}
\label{sec:evaluation_metrics}
The evaluation metrics are crucial to make CIExMAS comparable to other models, but also to identify optimisation potentials in CIExMAS. The evaluation is therefore based on evaluation metrics proposed by \citet{Josifoski2021}, which are meant to define true and false positive triples. Derived from defining positive and negative matches, typical score like F1-score, precision or recall can be defined. In addition to \citet{Josifoski2021} we propose a definition of close matches.

To define close matches, it is important to outline the definition of a match proposed by \citet{Josifoski2021}. Therefore, the set of predicted and actual triples are compared per document. A predicted triple is a match, when there is a triple in the set of actual triples per document, where each part of the triple matches by its \ac{URI}. Derived from this, there can be a number of matching triples, so called true positive triples be derived. All remaining triples are false positive triples. All unmatched triples of the actual triple set are then false negative triples.

In addition to the main category triples proposed by \citet{Josifoski2021}, four additional categories for direct matches were derived: Subject, Property, Object and Entity. This has the background of showing where a configuration lacks off capability. In addition, it shows which configuration can handle each part the best and then offers a insight to derive prompts to other configurations. Entities in this case is a set of all subject and objects in a document, where the place in the triple does not matter. The metric is calculated in the same way for those addition categories like for the triples.

To offer insights in how close the predictions are towards the expected results, soft matches are addition proposed for the property. Those soft matches also includes triples that use a super-property of the expected property as true positive. This matches are defined as parental soft matches. When a predicted property is either a super- or sub-property of the expected property, the match is defined as related soft match. Both soft match categories can be applied to either the predicate and the triple category.

Those soft matches are implemented by using a greedy search, whether a triple matches a triple from the gold standard and vice a versa to detect to correct number of true and false positive as well as false negative triples. This opens the error of creating f1-scores, precision and recalls over one, as multiple triples of the predicted set could match to one triple in the gold standard. That is why the recall is calculated as number of gold standard triples or properties that were detected devided by the total number of gold standard triples, while the precision was done the same but on prediction side. This follows also the common definition of precision and recall precisely.

The pre-liminary evaluation metrics of true positive, false positive and false negative triples, subjects, properties, objects and entities as well as the related soft matches are calculated for each document. In addition with the resulting turtle string they are saved into a excel sheet, which later on can be processed to F1-scores, precisions and recalls. As the scores are evaluated document-wise, an overall macro or micro average can be used for all three scores. In the following evaluation macro-scores are used, when the averaging method is not further defined, as the macro average gives each document equal weight regardless of the amount of triples in each document.

To illustrate how the evaluation metrics are computed, we consider a concise toy scenario with three triples about Angela Merkel.  Two sets are contrasted below: the triples predicted by CIExMAS and the manually curated gold standard.  Because the example is deliberately minimal, every intermediate step—from strict matching to soft matching—can be verified by hand.

\begin{table}[ht]
  \centering
  \label{tab:merkel_triples}
  \begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
    \toprule
    \textbf{Predicted triple} & \textbf{Actual triple}                                      \\ \midrule
    Angela~Merkel ; \textit{profession} ; Politician
                              & Angela~Merkel ; \textit{profession} ; Politician            \\[0.2em]
    Angela~Merkel ; \textit{is~member~of} ; CDU
                              & Angela~Merkel ; \textit{is~member~of~political~party} ; CDU \\[0.2em]
    Angela~Merkel ; \textit{hobby} ; Tennis
                              & Angela~Merkel ; \textit{lives~in} ; Berlin                  \\
    \bottomrule
  \end{tabular}
  \caption{Predicted versus actual triples for Angela~Merkel.}
\end{table}

In this ontology the predicate \textit{is~member~of~political~party} is a declared sub-property of the more general predicate \textit{is~member~of}.  Consequently, when CIExMAS predicts \textit{is~member~of} while the reference solution specifies the specialised variant, the pair is counted as both a \emph{parental soft match} (because the prediction is a direct super-property) and a \emph{related soft match} (because "related" embraces any super- or sub-property relationship).  Such soft matching awards partial credit whenever predicted and gold predicates are ontologically linked, even if their URIs differ.

\begin{table}[ht]
  \centering
  \label{tab:merkel_metrics}
  \begin{tabular}{lrrrrrr}
    \toprule
    Category               & TP & FP & FN & Precision & Recall & $F_1$ \\ \midrule
    Triples                & 1  & 2  & 2  & 0.33      & 0.33   & 0.33  \\
    Triples -- Parental    & 2  & 1  & 1  & 0.67      & 0.67   & 0.67  \\
    Triples -- Related     & 2  & 1  & 1  & 0.67      & 0.67   & 0.67  \\
    Subjects               & 1  & 0  & 0  & 1.00      & 1.00   & 1.00  \\
    Properties             & 1  & 2  & 2  & 0.33      & 0.33   & 0.33  \\
    Properties -- Parental & 2  & 1  & 1  & 0.67      & 0.67   & 0.67  \\
    Properties -- Related  & 2  & 1  & 1  & 0.67      & 0.67   & 0.67  \\
    Objects                & 2  & 1  & 1  & 0.67      & 0.67   & 0.67  \\
    Entities               & 3  & 1  & 1  & 0.75      & 0.75   & 0.75  \\
    \bottomrule
  \end{tabular}
  \caption{Per--category evaluation metrics for the example in Table~\ref{tab:merkel_triples}.  "Parental" and "Related" rows count soft matches where the predicted predicate is, respectively, a super-property or any super/sub-property of the expected predicate.}
\end{table}

The strict comparison in Table~\ref{tab:merkel_metrics} yields one fully correct triple, perfect subject recognition, and largely accurate object selection, while property alignment remains the principal source of error.  Allowing parental and related soft matches mitigates this deficiency by recognising the semantic proximity between \textit{is~member~of} and \textit{is~member~of~political~party}.  For example, in the object category two true positives, one false positive, and one false negative produce a precision and recall of $\tfrac{2}{3}$, resulting in $F_1\approx0.67$.  The same arithmetic is applied uniformly across all other categories.

Because these metrics are computed on a document-by-document basis, macro averages give each document equal weight, thereby yielding an interpretable, document-equitable overall score.  Evaluating at multiple granularities—triples, subjects, predicates, objects, and undifferentiated entities—while incorporating soft matches ultimately offers a robust foundation for diagnosing and improving CIExMAS.



\section{Evaluation Overview}
\label{sec:evaluation_overview}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrrrr}
    \toprule
    \textbf{Model}         & \multicolumn{5}{c}{\textit{\textbf{Triples}}}                                                                     \\
                           & Precision                                     & Recall         & F1             & Parental F1    & Related F1     \\
    \midrule
    synthIE$_{T5-large}$   & \textbf{0.835}                                & \textbf{0.832} & \textbf{0.831} & \textbf{0.841} & \textbf{0.858} \\
    synthIE$_{T5-base-SC}$ & 0.789                                         & 0.798          & 0.789          & 0.819          & 0.833          \\
    synthIE$_{T5-base}$    & 0.784                                         & 0.769          & 0.775          & 0.812          & 0.826          \\
    GenIE$_{T5-base}$      & 0.527                                         & 0.344          & 0.391          & 0.406          & 0.419          \\
    GenIE$_{T5-base-SC}$   & 0.527                                         & 0.320          & 0.372          & 0.391          & 0.404          \\
    \midrule
    \textbf{CIExMAS}       & 0.728                                         & 0.635          & 0.665          & 0.728          & 0.728          \\
    \bottomrule
  \end{tabular}
  \caption{Performance comparison of CIExMAS against state-of-the-art models on the synthIE dataset.}
  \label{tab:evaluation_overview}
\end{table}

The best CIExMAS configuration tested on the outlined 50-sample synthIE-text dataset, was found using the network architecture outlined in section \ref{subsec:network}. The exact configuration can be found in section \ref{subsec:full_network_agent_architecture}. The configuration scored 62\% F1 better than the best GenIE solution of \citet{Josifoski2021} and reached near performance to the synthIE models with the largest performance gap being 25\% of F1 increase. All models were evaluated on the same dataset samples.

In total the evaluation overview in table \ref{tab:evaluation_overview} shows, that there is a gap between non synthIE fine-tuned models and synthIE fine-tuned models like all synthIE models are. Nevertheless the subject collapsed models do not show significant better performance on the used dataset. The synthIE T5-base models are 16\% better than the CIExMAS architecture, while the T5-large model is again 7\% better than the T5-base models.

The comparsion highlights the different streghts and weaknesses of the approaches. First of all, the precision gap between CIExMAS and synthIE models is 8\% at minimum. This means that many triples that are generated by CIExMAS also are apparent in the gold standard. Nevertheless, CIExMAS misses out on Recall by synthIE$_{T5-large}$ performing about 31\% pointing out how CIExMAS detects not all triples expected in the gold standard. In addition, the gap between precision and recall is persistent in all models but the synthIE$_{T5-base-SC}$, but especially high in non synthIE fine-tuned models.

What also can be shown, is that the CIExMAS approach scored approximately 10\% more soft matches than typical matches. In comparison the best synthIE$_{T5-large}$ model scored a parental F1 of 0.841 and related F1 0.858, which means an increase of 1\%, respective 3\%. This implies a closing gap between the CIExMAS and the synthIE$_{T5-large}$ model, meaning that the synthIE model being just 15\% better, respective 18\% better in related F1. The gap to the synthIE$_{T5-base}$ models remain similar, but are also closing, while the gaps to the GenIE models can be seen increased with the soft match evaluation.

In addition, to the triples category the other four categories consisting of subject, property, object and entity can be found in the appendix. Nevertheless, the highlights will be explained in this paragraph. The CIExMAS approach shows state-of-the-art performance when detect subjects and object, which implies also a high score in predicting entities in triples. The precision in those categories is the best, while the F1-score are close. This differentiates CIExMAS clearly from the performance of GenIE, whereas the GenIE precision scores are similar, but the recalls are lower on all categories leading to worse F1-scores overall.

The additional evaluation also shows a lack of performance in predicting properties. This means that the F1-score of synthIE$_{T5-large}$ in the category properties is 24\% higher than the best CIExMAS approach. Overall the properties category shows the lowest scores across all aproaches when compared with the other non triple categories. The triple categroies combines the correct subject, property and object extraction and shows the lowest scores overall.

Overall CIExMAS shows a near state-of-the-art performance in processing the closed information extraction task. It performance 62\% better than GenIE, where synthIE models perform 25\% better than CIExMAS. The main performance difference can be seen within the recall of expected triples, which is also a problem of the non synthIE finetuned GenIE model.

\section{Evaluation Configurations}
\label{sec:evaluation_configurations}

The evaluation configuration section is intended to outline the various steps in the iterative process of developing CIExMAS. Therefore, this particular section will present an overview over the results. The the separate sections about the configurations will present the changes in detail, while also a reason about why particular steps were taken is presented.

\begin{table}[h]
  \centering
  \begin{tabular}{p{5cm}|rrrrrr}
    \toprule
    \textbf{Configuration}             & \multicolumn{6}{c}{\textit{\textbf{Triples}}}                                             \\
                                       & Prec.                                         & Rec.  & F1    & Par. F1 & Rel. F1 & Err.  \\
    \midrule
    Initial Baseline                   & 0.294                                         & 0.380 & 0.322 & 0.358   & 0.358   & 0.200 \\
    Task Modularization                                                                                                            \\(SSA) & 0.220 & 0.306 & 0.237 & 0.277 & 0.277 & 0.180 \\
    Error Incorp. (SSA)                                                                                                            \\ + PropEx & 0.205 & 0.264 & 0.222 & 0.262 & 0.272 & 0.020 \\
    Error Incorp. (SSA)                & 0.293                                         & 0.406 & 0.325 & 0.365   & 0.365   & 0.120 \\
    Error Incorp.                                                                                                                  \\(Baseline) & 0.431 & 0.507 & 0.456 & 0.525 & 0.525 & 0.000 \\
    Agent System Simplification (SSSA) & 0.376                                         & 0.410 & 0.385 & 0.423   & 0.423   & 0.020 \\
    ReAct Architecture                 & 0.485                                         & 0.438 & 0.456 & 0.511   & 0.511   & 0.060 \\
    URI Retrieval (SSSA)               & 0.455                                         & 0.451 & 0.449 & 0.495   & 0.503   & 0.040 \\
    URI Retrieval                                                                                                                  \\(ReAct) & 0.473 & 0.419 & 0.440 & 0.484 & 0.491 & 0.020 \\
    Knowledge Graph                                                                                                                \\Integration & 0.390 & 0.362 & 0.373 & 0.438 & 0.448 & 0.240 \\
    \textbf{Network Architecture}                                                                                                  \\\textbf{(Gen2)} & \textbf{0.728} & \textbf{0.635} & \textbf{0.665} & \textbf{0.728} & \textbf{0.728} & \textbf{0.000} \\
    Advanced Adapt.                                                                                                                \\(ReAct) & 0.667 & 0.484 & 0.545 & 0.584 & 0.584 & 0.020 \\
    Advanced Adapt.                                                                                                                \\(Baseline) & 0.538 & 0.578 & 0.552 & 0.619 & 0.627 & 0.000 \\
    \bottomrule
  \end{tabular}
  \caption{Performance comparison of CIExMAS development iterations on the synthIE dataset.}
  \label{tab:evaluation_iterations}
\end{table}

The comparison in table \ref{tab:evaluation_iterations} shows the metrics already shown in previous chapters, but an additional error rate. This indicates how many runs over a sample produced an error and therefore, was included as zero scores in the macro averages. First and foremost, it can be seen, that the iterative process, was not producing a clear trajectory of producing better results. Especially the initial baseline implementation was the best tested method until the network approach, when concentrating an the F1-score. This means, that a rather simple architecture with a rather simple implementation.
In the end the most sophisticated approaches including a high knowledge graph integration and result validation mechanics could also outperform the initial baseline by a margin of at least 71\% increase in F1. The best solution could be found, when combining this sophisticated approach with a network architecture like outlined in section \ref{subsec:network}. This solution outperformed the best adapted baseline by another 20\%. Only with those improvements, a CIExMAS approach could surpass the F1-score of GenIE$_{T5-base-SC}$, which was 0.372. In the follwoing chapters, references to the appendix will be taken, espeically when differences for the different categories are highlighted. The decision was taken due to better readability.

\subsection{Initial Baseline Setup}
\label{subsec:initial_baseline_setup}

As a starting point, the baseline architecture was designed like described in section \ref{subsec:baseline}. The initial baseline is a simple version of this architecture. This means that, the prompts were rather simple, especially for the extraction agents. In addition, the output of the URI detection tool was returned directly to the supervisor agent.

In general, this configuration\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/blob/b75556c727e208f048e00caa327778d80cfc9934/baseline.ipynb}} showed a static pattern of executing first entity and relation extraction, than using the URI tool for mapping and afterwards producing an output. Therefore, in the traces no iteration over the triples can be found. As this configuration relates to a very early version, the target was to output solely QNames instead of full URIs. As this baseline was then tested again within the current agent system framework of CIExMAS, the QNames were parsed to turtle strings. The evaluation logs have shown, that sometimes instead of QNames, URIs were outputed. As this was not indented, it is considered as error.

In this early state, the supervisor agent already showed flaws, what led to the prompt architecture build out of role description and guidelines used. Those flaws were about the supervisor acting without the extraction agents and especially without the URI Mapping Tool. As Wikidata is likely to be apparent, the used \ac{LLM} is expected to know the format of Wikidata URIs as well as the mapping from URIs to entity by the training dataset. The supervisor agent showed the behavior to extract the triples and map them with the internal knowledge. This led to errors, as the URIs were hallucinated to some extend.

In addition, the supervisor agent was prone to miss out necessary outputs. For example in some case no goto tag was provided to decide which agent to call next, which led to a NoneType error, as the tag was not found. Therefore, the supervisor needed strict rules to work correctly in this early baseline. Based on this behavior, the prompt design with role description and guidelines like outlined in section \ref{sec:iterative_prompt_engineering} was used for further development. The guidelines than instructed the supervisor, to delegate the tasks instead of solving themselve and follow the guidelines.

In addition, the extractors also got the same prompt design with edge cases included. For the entity extractor this was about composite entities like \textit{2022 Winter Olympics}, which was expected by the dataset to be split up into \textit{[2022, 2022 Winter Olympics, Winter Olympics]}. In addition, both extractors needed to be prompted about the expected result. This means, that synthIE expected not directly visible results, especially in synthIE-code were the initial baseline was designed on. To provide an example, the composite word \textit{Corfe Castle railway station} was expected to lead to a triple \textit{(Corfe Castle railway station; named after; Corfe Castle)}.

Nevertheless, the initial baseline with the outlined tweaks could score near GenIE scores in remarks of the F1-score, even surpassing the recall of both GenIE models. When assumed that the result were achieved on 80\% of the data, and those results scale to the rest of the data, the baseline had the potential to score an F1 of 0.402. Achieving this score, the baseline would have surpassed both GenIE models.

The baseline showed shortcomings in the area of subjects and objects, with an F1 of 0.646, respective 0.665 with higher recall than precision. The main shortcoming like in every other configuration can be found in the detection of properties, which limited the overall F1-score. Espeically, as the initial baseline missed out on hard matches, leaving the parental F1 on properties 22\% higher than the hard matched F1.

Compared to the configuration, the initial baseline already showed the potential of agentic systems. With scores around comparison models, with similar prequisites not being finetuned on synthIE, compared with the flaws detected in the baseline opened the trajectory for further developments. The baseline architecture also was further developed, as it already showed this great potential.

\subsection{Modularization of Supervisor Agent Tasks}
\label{subsec:modularization_agent_tasks}

The supervisor agent showed major flaws in the initial baseline setup, which could not even fully resolved by prompt engineering. In traces of the initial baseline, it can be found that the initial baseline followed mainly a workflow pattern. That is the reason why the supervisor agent was up to modularization in the \ac{SSA} \footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/tree/ad061f1fd93d8e22ca9046769580e46e8ff2365d}}.

In addition, to splitting up the supervisor agent into planner, agent instructor, result checker and result formatter, the URI mapping got a \ac{LLM}-based summary of the results. This changes made the whole processing more explicit and accessible. Each step could be instructed exactly for what it was meant for. In addition, the planning got more attention, as it was done explicitly in the \ac{SSA}, with the planner agent instructed to make adaption as needed. In contrast to the initial baseline, the \ac{SSA} switched to turtle string outputs, to match the real-world adaption ability of CIExMAS. This requirement is also used on all coming configurations.

In order to give the agentic system the ability to decide on the search terms and especially on how to search for URI, two search modes were introduced. The first mode was the label mode, which executed the similarity search against the rdfs:label of entities and properties. The second mode was the description mode, which was intend for the agentic system to describe the entity or property and get the correct answer.

The overall evaluation on triples F1 shows an enormous decrease of performance using the initial version of the \ac{SSA}. The \ac{SSA} in this first implementation just reaches 74\% of the initial baseline performance, scoring an F1 of 0.237. The errors were mainly context length errors. On the other side, the error rate is slightly lower with 18\% of failed executions, which would provide a better starting point for a higher score.

The idea of splitting up the supervisor agent led directly to more iterations over the closed information extraction task. For instance, the result checker agent once outputted: \enquote{To further refine the extraction, consider calling the URI Detection Agent to find associated entities and relations in the Knowledge Graph for the extracted entities "Bluegogo", "bicycle-sharing system", and "bankruptcy". This step can help validate the extracted information and potentially identify additional relationships.} This behavior was extinct when considering the supervisor agent of the initial baseline. Besides the result checker agent did its task it was intended for, some iterations show, that it was iterating over the same entities over and over again without providing any additional value.

In addition, the plan to give the agentic system access to multiple search modes was not used appropriate. To provide an examples, the agent instructor used the search terms: \enquote{Bluegogo[LABEL], bicycle-sharing system[LABEL], bankruptcy[LABEL], a product or material produced[DESCR], history[DESCR]}. It is apparent, that the description mode was primarily used for properties while the label mode was primarily used for entities.

For the remaining evaluation categories, this \ac{SSA} configuration showed lacks in every of them. The biggest gap was experienced in detected properties, while the smallest gap is at detected entities in general. In addition, the \ac{SSA} snapshot has also a high gap between soft matches and hard matches, especially for properties, with the related F1 being 30\% higher.

The first implementation of the \ac{SSA} shows additional flaws and highlights the idea of error propagation, while iterating more logically over the closed information extraction task. Adding the complexity also creates new limitations in the are of context lengths, while not performing better than the baseline solution. In the end, the \ac{SSA} revealed the needs for improvements to match and outperform even the baseline solution.

\subsection{Error Message Incorporation and Agent Engineering}
\label{subsec:error_message_incorporation}

Both the initial baseline configuration as well as the initial implementation of the \ac{SSA} show substantial potential based on their error rates. In addition, several tweaks are needed to increase the performance of the \ac{SSA} based on the previous configuration. This led to implementation of better feedback mechanisms as well as a new agent with the property extractor (short: PropEx) for the \ac{SSA}\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/tree/38c72a951ad513bb980b40f432b1958b796d7e4b}}. In addition, the idea of using error incorporation as well as using a URI mapping summary were implemented in the baseline architecture.

As already outlined, looping and errors were issues in the first \ac{SSA} implementation. This loops occured mainly because of missing instructions, where an agent was called without the ability to give any response or give an indecisive response. Besides the error of context overflow, missing goto tags were also a problem that count towards the error rate.

As a solution, error messages were provided and incorporated in the agent flow from this configuration onwards. First of all missing goto tags, led to loops on the same agent, which was especially apparent on the planner and agent instructor agent. In general, the idea was to loop about the agent that has to decide on the further agent flow and to instruct it to provide any goto tag. In addition, the instructions were checked from there on, so that empty instructions, were detected on agent or tool level, where the response was an instruction back to the issuing agent to provide any input to the agent or tool. The error of the context overflow was look on from a prompt design side, but not from the side of let the agents change the context on their own.

Another adaption to the \ac{SSA} was the property extractor agent. As the \ac{SSA} showed shortcomings on the property extraction side, like the baseline architecture also did before, the idea was to implement another agent gathering properties from the text. This agent followed the same prompt structure as the entity or triple extractor.

Besides implementing this adaption of error message incorporation to the \ac{SSA}, the error incorporation was also implememted for the baseline architecture. In addition, the idea of summaries of the URI mapping showed a logical behavior in the \ac{SSA}, why it was also used in this and coming configuration for the baseline architecture. As outlined in the initial baseline section, the initial implementation was asked to output QNames. Like in the \ac{SSA}, the baseline afterwards was asked to output turtle strings as well.

Those configurations could lower the error rates and surpass the performance of the first implementation of the task modularization of the \ac{SSA}. Therefore, the updated \ac{SSA} reached a triple F1 of 0.325, while the updated baseline reached a F1 of 0.456 even surpassing the initial baseline result. The addition of the property extractor does lower the performance in comparison to the previous implementation of the \ac{SSA} by reaching 0.222 F1.

The baseline architecture combined with error incorporation shows no errors, which enabled it to surpass the potential F1 score of the initial baseline. Same goes for the \ac{SSA} with the property extractor against the initial \ac{SSA} implementation, as the error is decreased to 2\%. Nevertheless the F1-score is 32\% lower than the updated \ac{SSA} without the added agent. It has to mentioned, that for all configurations the prompts were adapted, to provide the additional functionality properly.

Besides the loss in triple extraction performance, all configurations could increase their F1-scores in extracting subject, objects and entities. Especially the \ac{SSA} with the property extraction could surpass the initial baseline in subject and entity extraction, while matching the object extraction F1. The main problem of the \ac{SSA} is the extraction of properties, which is amplified by using the property extraction. The updated baseline could outperform the initial baseline and also the GenIE models in all categories, but it misses out on forming the correct triples.

Therefore, the errors were now on the extraction side instead of on the agentic system overhead. A simple example is the text \enquote{Daniel Johannsen is a tenor.}, which should be extracted to \textit{(Daniel Johannsen; voice type; Tenor)}. The updated baseline extracted the property \textit{occupation} instead, missing out on the context that tenor is not a job.

All in all the error message incorporation showed the expected function. It limited the error rate and the traces also showed less looping. Nevertheless, the results remain limited because of the limited sense for the proper use of properties.

\subsection{Agent System Simplification}
\label{subsec:task_simplification_state_refinement}

As the main issues of the \ac{SSA} stays the error of context length errors. Combined with the experience of a looping between the result checker, planner and agent instructor agent, the \ac{SSSA} was implemented\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/tree/91e14e7561e2ed6ba85e944f8063aca813d173e6}}. The main idea was state simplification, which meant to split up the state in more granular but simple parts.

Like already outlined in section \ref{subsec:simplified_splitted_supervisor}, the tasks of planning, instruction and result checking were reassembled in one planner agent, while the result formatter stayed as it was. In addition, manual prompt engineering was engaged to make the \ac{SSSA} work. Furthermore, the new more granular state had to be parsed out of the responses of the \ac{LLM}.

Providing are more simpler state, while also adding a minor part of complexity showed improvements over the \ac{SSA}. First of all, the \ac{SSSA} showed less token usage, due to the fact of using less agents. Nevertheless the central planner also showed parts of the behavior previously encoded in the result checker. For instance, the planner agent mentioned \enquote{
  The triple extraction agent has successfully formed additional triples from the extracted entities and predicates, but we should verify if the entities and predicates are correctly extracted and if the triples are accurate.} and instructed the entity extractor \enquote{Re-examine the text to extract entities, focusing on locations such as villages, districts, and counties, and verify the accuracy of the previously extracted entities.}. This example showed, that also the \ac{SSSA} showed the capability of iterating over the triples.

In general the \ac{SSSA} achieved a triple F1 of 0.385, which is the second best result compared with the prior configurations. All while lower the context window errors to 2\%, which gives the ability to achieve potential higher scores. In theory, the updated \ac{SSA} with 12\% error rate, could have potentially scored a F1 of 0.369, while the \ac{SSSA} could potential have scored 0.393, when the non-error execution scale propotionaly to the error samples. This shows, that the \ac{SSSA} performance is slightly better than the \ac{SSA} performance.

Overall the \ac{SSSA} showed a overperformance in all evaluation categories against the \ac{SSA} and the initial baseline. Nevertheless, the traces reveal a problem of the \ac{SSSA}. This is the iteration, which produces many triples, as the planner agents tries to get every triple out of the sentence. This can lead to less precision, as the triples that were outputed sometimes were alternatives the original triples. To provide an example the \ac{SSSA} configuration extracted that the song \textit{No More} is instance of rock music, internet archive or daemosan station out of the sentence \enquote{"No More" by Jamelia is a Baroque pop single. It is performed by Jamelia.}.

In the end, the \ac{SSSA} is a adaption of the \ac{SSA} in order to keep the idea of iterating over the triples. The shorter context showed a lower error rate and therefore also a higher triple F1 score. In addition, the \ac{SSSA} is another improvement on the extraction of subject, properties, objects and entities. Nevertheless, the complexity of the idea of iterating over triples also produces hallucinated triples that will lower all performance metrics.

\subsection{ReAct Architecture}
\label{subsec:one_agent_architecture_tool_usage}

In contrast to the \ac{SSA} and \ac{SSSA}, the ReAct architecture implementation has gone the full contrast. Using the original URI retrieval tool from the initial baseline within a ReAct agent, the architecture simplified the whole agentic system. The idea was to check the joint-optimisation approach and also a most simplified approach within the use of a \ac{LLM}-agent. The main agent was then in charge for the variety of task like the whole extraction, planning, mapping URIs and output a final result. It should also show the ability of the \ac{LLM} in regards of how many tasks can be done at once\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/tree/91e14e7561e2ed6ba85e944f8063aca813d173e6}}.

With this simple approach, the score of the updated baseline with error incorporation could be matched with the achieved triple F1 of 0.456. In addition, the ReAct agent could lower the token use in contrast to the updated baseline with error incorporation by nearly 25\%, as for the benchmark 453 thousand tokens instead of 606 thousand tokens were used. While being more efficient, the ReAct agent was more simple to tune, as there was a single point to do it. This also added complexity as the capability of the used Llama 3.3 70B showed high limitation in instruction following, being hard to tune towards the goal.

In all categories the ReAct agent showed a larger gap between precision and recall, with precision being higher than recall. This is unlike the earlier models and shows that the ReAct agent was focussed on a few but therefore correct triples. Unlike the \ac{SSSA}, the ReAct agent has generated fewer triples overall.

Nevertheless, the ReAct agent a showed new high-scores among the previous models in the F1 of extracting subjects. Other than that the ReAct agent showed scores in the remaining categories that were matching the one of the \ac{SSSA} implementation. In addition the error rate is slightly increase to 6\% instead of 2\% like in the \ac{SSSA} what also goes back to context window issues. This implies, that the ReAct architecture has a theoretical potential of scoring 0.485, if the scores scale proportianal.

An result limiting factor is the missing sense for the usage of the URIs like in all previous models. As an repeated example the sentence \enquote{Daniel Johannsen is a tenor.} expected the property \enquote{voice type}. This time the ReAct agent extract instance of, which is incorrect given the idea of instance of. The agent should instead have detected that Daniel Johannsen is instance of a human. In addition, the URI retrieval showed limitations, as many subjects and objects are in the correct triple together, but the predicate is wrong.

The simple combination of the URI retrieval tool and a ReAct agent shows high potential. The joint optimisation idea leads to near initial baseline performance, which remains the best approach. Nevertheless, the simple idea can be extended by using further tools and ideas in order to create better results.

\subsection{URI Retrieval Filtering}
\label{subsec:uri_retrieval_filtering}

As already outlined in section \ref{subsec:modularization_agent_tasks} for the first implementation of the \ac{SSA}, a problem of the URI search terms were, that the search modes were not used properly. Mostly the label search mode was used for entities whereas the description mode was used for properties. In order to take the agent the opportunity of using the search modes for distinct searches, another filter mode was introduced. The goal of it was that the agent is able to filter for entities or properties, while deciding if the search is conducted on the label or the description\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/commit/35ff8fc370103a9453aaf7babb8e62f576fd8650}}.

In detail, this filtering mode was another keyword behind the search term. For instance [LABEL-Q] executes a similarity search on the rdfs:label filtered on entities. This filtering mode was given to the ReAct architecture as well as to the \ac{SSSA}, as both seemed the most promising according to the results.

The adaption had positive results for the \ac{SSSA}, while the ReAct solution was achieving similar results than before. The latest implementation \ac{SSSA} had a slightly lower error rate of 4\%, while achieving 16\% better results than the original \ac{SSSA} implementation with a F1-score of 0.449. On the other side the ReAct agent had achieved a 0\% error rate, but nevertheless the F1-score decreased from 0.456 to 0.440. Therefore, the \ac{SSSA}, ReAct agent and various baseline implementation are scoring close to each other.

When taking a look into the seperate parts of the evaluation, it get visible, that the ReAct agent with the new filtering mode can score up top or nearly top of the prior models. Espeically subjects and entities overall get very good extracted by the ReAct agent with F1-score of 0.885 and 0.906. On the property and object category it is defeated by the baseline architecture with error incorporation. In addition, the updated \ac{SSSA} is also able to score nearly as good as the ReAct agent, explaining the improved F1-scores on the triple category. The property F1-scores are increase for the \ac{SSSA} by 5\%, while also being increase for the ReAct agent by 6\%, which shows that the URI-filtering had no high effect.

As the extraction of subject, objects is already nearly perfect, the biggest limiting factor remains the extraction of properties and the merging of all parts into correct triples. In traces it is shown, that the URI filtering was used but sometimes in the unexpected way. For example the sentence \enquote{Bluegogo was a bicycle-sharing system} led the updated ReAct to search for \textit{bicycle-sharing system[LABEL-P]} and therefore not detecting in as entity. Nevertheless, most extraction showed a higher sense of URI retrievals. In addition to the problems with the URI retrieval, the soft matches show high potential in achieve higher triple F1-scores, with the parental F1 being over 10\% higher than the normal F1, which goes also for properties and for both ReAct architecture and \ac{SSSA}.

All in all the URI retrieval filtering reveals a high potential in extracting correct triples. The ReAct agent achieves near perfect extraction for subject and entities with scores above 0.885 F1. Also the \ac{SSSA} achieves scores lower, but also similar to the ReAct agent. Nevertheless, the problem is, that the high scores in those categories are not reflected in the triple F1-scores. In addition, the URI-filtering does not have shown an effect on the property or triple F1 score.

\subsection{Knowledge Graph Integration}
\label{subsec:knowledge_graph_integration}

In previous configurations, a dominant problem was, that the parental and related F1 scores were significantly higher than the hard matched F1. Espeically the parental F1-score explains the most of the gap. This implies that the approaches are more over to general in their extraction. An idea to cover this problem and close the gap is to integrate the underlying knowledge graph directly into the agentic system\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS/tree/9ae8a7b8b5d5aa54c0875684a0f42a41cf740e04}}.

The property extraction, no matter whether it was done by a separate agent or not, for instance opened up a gap of maximum 41.2\% worse than on the entity category. Therefore, the expectation is, that if the properties are correct, but just soft matches, the correct ones can be found within the property hierarchy of Wikidata for the case of synthIE. In addition, this hierarchy may also give an intend of the semantics of the original property.

In this configuration the network traversal tool like described in section \ref{subsec:network_traversal} is used to create this connection. As this is an earlier implementation of the knowledge graph integration, Wikidata is accessed directly. Therefore, only the direct sub and superproperties were used, which is based on Wikidata not being loopfree and additional on the immense amount of properties that could appear in the output. As context window overflows were already a problem, bloating the context with even more properties does not seemed targeted.

As the ReAct archiecture remained simpler to develop, it was the architecture of choice to test the knowledge graph integration with the network traversal tool. The network traversal tool was then implemented as recommended step in the prompts towards the result. As example the agent outputs \enquote{Next, I will use the Network Traversal Search Tool to find super- and sub-predicates for "located in" and "capital of" to ensure the best match for the context.}

In the end, this does not lead to the expected effect of higher triple F1-scores. Instead the knowledge graph integration lowers the F1 by 18\%, achieving 0.373 F1. This lowering goes also for all remaining categories. Nevertheless, two effects are apparent in the detailed evaluation. First, the scores on all categories do show a high gap to the top previous models, but the F1-score is not as affected as it could be expected. Second, the error rate is at 24\% and shows the problem of context overflowing, which is mainly caused by the agent trying to use the URI search tool with various search terms and modes. The error rate shows a much higher potential F1 of 0.49, which would have been best-in-class for the CIExMAS approaches.

As an idea the message deletion tool like described in section \ref{subsec:message_deletion} was tested in small test batches, without any successful implementation. The main problem was, that the agent could then delete messages, that were useful for the further processing, like URI retrievals. Without prior summaries, the relevant context got deleted and therefore, the results also got worse. That is why the decision was taken, to focus mainly on providing precise and small context.

In the end also this configuration shows similar errors like the previous configuration. Again the URI mapping remains a vulnerable point. In this configuration, the traces show the behavior of search for multiple alternatives. Nevertheless this shows problems as the result therefore will also not be found.

All in all the knowledge graph integration remains an experiment, that shows that such tools not always bring an improvement, especially if the data basis has not the highest quality. The knowledge graph integration shows that also the knowledge graph could be leveraged by agents, but nevertheless the experiment has shown that this tool makes the development incrementaly harder, but adding to the context. This limits the editability of the prompt and context even more. Therefore, the network traversal tool will not be used in one of the remaining configurations.

\subsection{Network Agent Architecture}
\label{subsec:full_network_agent_architecture}

Throughout this approach, various experiences could be gathered. First of all, it has been shown, that more complex system like the \ac{SSA} do not necessarily produce better results. With major improvements, the performance of the \ac{SSA} and later the \ac{SSSA} could match the baseline performance. In contrast the most simple solution of using one agent in addition with the URI retrieval tool showed matching results to the baseline, while taking complexity out of the process. And in the middle, there is the baseline which keeps one of the best scores with a simple pipeline process implemented in a supervisor architecture.

The network agent architecture, also presented in section \ref{subsec:network}, combines the findings into three agents\footnote{The snapshot of this configuration can be found under: \url{https://github.com/maxlautenbach/CIExMAS}}. First of all, the finding of the high performance of the ReAct archiecture revealed, that one agent is able to extract the full triple at once. On the otherside, the \ac{SSA} and \ac{SSSA} showed iterations and result reviews, that seemed logical, but at the end not improving the results. The network traversal tool showed the potential of incorporating the knowledge graph, but nevertheless was not helpful either.

In addition, the previous approaches showed problems with getting the correct properties and hallucinating URIs. Furthermore, the semantics of the properties were not included by using the knowledge graph integration. In addition, central planning like in the supervisor architectures was often showing bad capabilities. Also, the URI search tool was often used incorrect even after the filter modes, as the agents search for descriptions using labels as inputs. Nevertheless, the URI summaries used in some of the previous approaches except for the ReAct architecture based, showed more condensed results. In general, the \ac{SSSA} proved, that more simple states and contexts will lead to less errors.

As all previous configuration followed either a one agent architecture or a supervison pattern, which is also adapted to a custom pattern, this configuration was also a test to use specialised agents that decide about the agentic flow. The iteration triggered but the result reviewer was the inspiration to provide a validation and testing agent. This agent was set up with the semantic validation and turtle to label tool, in order to give a sense of semantics into the agentic system and reduce hallucination. As outlined the semantic validation tool was used with a filtered Wikidata dump, that was loopfree and locally hosted other than the network traversal tool.

In addition, many of the prompt design features were not already exhausted. Especially the from \citet{Brown2020} advertised in-context learning was therefore used for the triple extraction agent. In the triple extractor prompt, three samples of the synthIE-text validation-split were human-filtered. In addition, the triple extraction was asked to give a type of the entity for simpler disambiguation in the search, as the embeddings will also embed a semantical sense of the word.

For the URI search, the search and filter modes got simplified. The URI retrieval tool just accepted entity and property filtering, while using rdfs:label for the similarity comparison. For the property filtering there was an additional search mode to search by a example. The idea is that the agent can input the triple and the example search leads to properties, that embed the correct semantic of what is meant by the text. The URI mapping and refinement agent was asked, to use both search modes in order to find any suitable property.

From a qualitative point of view, the improvements showed their expected impact. The validation and output agent showed the ability to reinforce request back to the URI mapping and refinement agent, for instance when a type restriction was violated. To show one reasoning example of the validation and output tool: \enquote{The semantic triple checking tool has identified a type restriction mismatch for the object of the triple, so the uri\_mapping\_and\_refinement agent is called to refine the triple and resolve the mismatch.}

From the quantitative point of view, the collection of improvements lead to the best CIExMAS result overall. Reaching a F1-score of 0.665 showed the potential of bringing all experiences together. In addition, the precision remains higher than the recall showing, that the output of the network agents are few but mostly correct triples. Furthermore, the error rate is lowered to 0\%, which means that the context adaption to a simple context, that includes all needed information shows a result. In addition, neither the further updated baseline nor the future update ReAct agent could come near to the network agents. Nevertheless F1-score of the soft matches of the network agent architecture remain about 10\% higher than the hard matches. This comes primarily from properties, that were parent properties of the searched properties.

In detail the network architecture shows a near perfect ability to extract subjects and entities overall with F1-scores of 0.9 and above. The object extraction is leading to a F1 of 0.867. Further more the precision in all categories is 0.93 and above, which indiciates best-in-class or near best-in-class subject, object and entity extraction.

The big upgrade on the previous models was on the F1-score in the properties category. The achieved 0.710 F1-score in this category is 33\% better than the previously best extracting model, the ReAct agent implementation with URI retrieval filtering. This result in combination with the best CIExMAS score shows, how limiting the property extraction is and which potential could get unleashed from using this potential.

The network architecture also reveals problems that were present throughout the whole CIExMAS project. Also in this configuration, a problem remains the URI mapping. To give an example the search term \enquote{took place in} revealed the result \enquote{took place in - Search mode applied [P|X] - Applicable to [P1] -> URI: http://www.wikidata.org/entity/P2408, URI-Label: set in period}.

In addition, the new semantic validation tool has limitations. As example, the triple \textit{(Vapiano; cuisine; Italian cuisine)} is not accepted by the semantic validation tool, as it states, that the object type constraint of Italian cuising being an instance of cuisine is not given. This is an issue with the underlying dataset, as the relation between Italian cuisine and cuisine is not given in the dataset, but in Wikidata.

In the end, the network architecture is the most performant architecture. Espeically through the combination of a few but capable agents, the network architecture can merge the advantages of all previous architecture. The idea of combining the one step of extracting all triples from the one agent, while on the other side keeping a point of validation that is able to take out erronous triples or iterate back into other agents, shows the highest overall performance. In the end the network agent also is not errorfree and reveals also points for improvement.

\subsection{Integration of Tool Improvements to ReAct and Baseline Architecture}
\label{subsec:performance_increases_gen2}

As the integration of both the validations tools and the refinement of the URI searching modes released high potential in subject and object extraction, but especially in property extraction, this concept could be adapt to more simpler approaches. Espeically the ReAct agent is interesting for this testing, as it showed high scores while providing lower token use and easier optimisation. Therefore, especially the URI filtering should be adapted to the two architectures, with the ReAct agent being extended by the additional validation tool.

In detail this means, that both ReAct and baseline architecture implementations got the new example search mode, while the label and description mode were deleted. As the baseline architecture should stick with the original set of agents and tools, the validation tools were only implemented to the ReAct architecture. In this case the prompt got adapted to make use of semantic validation and turtle to label tool.

In the end, the achieved results are in between the updated baseline and initial ReAct implementation and the network agent architecture. With an F1-score of 0.545 for the ReAct architecture and 0.552 for the updated baseline, both models show a nearly 20\% increase over their previous models. Additionally, both approaches keep their characteristic with the baseline detecting more triples of the gold standard, where the ReAct approach outputs more triples, that are in the gold standard.

For the other categories, especially the ReAct approach showed the overall limitation of the properties once again. As now more properties got detected, with an F1-score of 0.616 for properties, other scores like the subject or object F1-score was lowered towards the midfield of CIExMAS approaches. Nevertheless, the previous top scores, were outperformed by the ReAct agent. The baseline on the other side showed best of CIExMAS performance in detecting objects and entities overall, while also maintaining higher property scores than the ReAct approach.

In the end it shows the potential that can also be revealed within all approaches of CIExMAS, especially out of those that are already simple to maintain and to optimise. Both baseline and ReAct architecture could be optimised by the same tools and ideas used for the network architecture to surpass their previous implementation. Nevertheless in all configuration, so in this configurations the problem stays the URI retrieval, that limits the properties F1-score and from there implied also the triple F1-score.

\subsection{LLM Variation}
\label{subsec:llm_model_variation}

\begin{table}[h]
  \centering
  \begin{tabular}{p{5cm}|rrrrrr}
    \toprule
    \textbf{Model (Provider)}      & \multicolumn{6}{c}{\textit{\textbf{Triples}}}                                                                                      \\
                                   & Prec.                                         & Rec.           & F1             & Par. F1        & Rel. F1        & Err.           \\
    \midrule
    Llama 3.3 70B 4-bit AWQ (vLLM) & \textbf{0.728}                                & \textbf{0.635} & \textbf{0.665} & \textbf{0.728} & \textbf{0.728} & \textbf{0.000} \\
    Llama 3.3 70B (SambaNova)      & 0.650                                         & 0.599          & 0.608          & 0.647          & 0.647          & 0.000          \\
    Llama 4 Maverick (Groq)        & 0.346                                         & 0.306          & 0.321          & 0.391          & 0.391          & 0.200          \\
    Kimi-K2 Instruct (Groq)        & 0.060                                         & 0.043          & 0.049          & 0.049          & 0.049          & 0.060          \\
    \bottomrule
  \end{tabular}
  \caption{Performance comparison of a \ac{LLM} variation against the original Llama 3.3 70B \ac{LLM}, evaluated on the synthIE dataset.}
  \label{tab:model_variation_comparison}
\end{table}

The in CIExMAS used Llama 3.3 70B model matches the performance of OpenAIs GPT-4 models from end of 2023 \cite{Chiang2024}. As already outlined in section \ref{sec:language_models} Meta released a newer herd of Llama 4 models, where the best model is as today Llama 4 Maverick. In addition, Kimi-K2 was released and scores near state-of-the-art scores. Both models could outperform Llama 3.3 70B by a significant margin on the LMSys Chatbot Arena benchmark. That is why it is relevant to test those models against Llama 3.3 70B.

The configuration taken is the network agent architecture presented in section \ref{subsec:full_network_agent_architecture}. All tools and prompts, stayed the same for the evaluation of the comparison models. The comparison models were executed on the provider Groq and SambaNova, instead of running them locally in a quantised model on vLLM. This is caused by the significant bigger size of both models, as Llama 4 Maverick is a 109 billion parameter model with 17 billion being active, whereas Kimi-K2 has 1 trillion parameters, whereas only 32B are active. Nevertheless, both models remain to large for the used infrastructure. In addition, SambaNova was used to run an unquantised version of Llama 3.3 70B, which was also mainly used for the agent engineering.

The evaluation shown in table \ref{tab:model_variation_comparison} reveals, that all models have lower scores across all metrics. Especially Kimi-K2 just reaches a 0.049 F1-score, which is 7.4\% of the score achieved with Llama 3.3 70B. Llama 4 Maverick performs better, but in the end the 0.321 F1-score is matching the initial baseline achieved with Llama 3.3 70B. Both models therefore have higher error rates, with Llama 4 Maverick having 20\% of errors, while Kimi-K2 has just 6\%. The unquantised version shows a 8.5\% worse result than the quantised model. This shows that the quantisation has an effect, which in this case is now beneficial for the closed information extraction.

As it seems counterintuitive that immense bigger models, show near complete failure of errors, whereas a smaller older models shows near state-of-the-art result, it is necessary to anaylse the traces. First of all, many errors of Llama 4 are caused by recursion limit errors. Those are mostly caused through syntax problems between the agent and the semantic validation tool, as the validation and output agent using Llama 4 outputs turtle like \enquote{@prefix wd: <http://www.wikidata.org/entity/>.\\nwd:Q907827 wd:P1546 wd:Q877781}. In this string \textit{\\nwd} is not expected and leads to a syntax error, that the agent is unable to fix. This leads to recursion limit errors, as the agent keeps looping over the error.

For the remaining loss, it can be assumed according to the traces, that the model is less able to extract the expected triples and therefore reaches just about 48\% of the Llama 3.3 70B result. On the other side the in benchmarks much more capable Kimi-K2 shows a even lower score, while not producing as much errors as Llama 4. The main problem of the model is hallucination and not relying on the tools. In the three successful results, with a score of over zero, the URI search tool is used. In the majority of traces, the call of the URI search tool can not be found. The 6\% of errors are explained by a looping through the turtle to label tool. In one case the triples are from dbpedia and therefore produce syntax errors, but in the other cases the input and output of the tool is correct, but the model does not follow the guideline and loops back to the tool instead of calling the semantic validation tool.

An idea to conduct an experiment using Gemma3 as another smaller open source, but very capable model failed. The traces showed problems with Gemma3 following the output guidelines. Instead of the xml tags, Gemma3 outputed json structured output, which can not be processed by the CIExMAS setup.

All in all the various \acp{LLM} showed no improvement at all, while also being more expensive and slower than Llama 3.3 70B 4-bit quantised. Some models like Kimi-K2 or Gemma3 were problematic to produce any result with F1 greater than zero or even a result. In regards of this comparison, which was also done empirical throguht the configuration iterations of CIExMAS, the model of choice stayed Llama 3.3 70B.

\section{Discussion}
\label{sec:discussion}

In order to research the effectiveness of multi-agent system at solving the task of closed information extraction and in addition analyse the highest performance agentic architecture patterns, an iterative approach was employed to develop CIExMAS. This appraoches tested supervisor, network and one agent patterns, while the supervisor pattern was also modified with a splitting supervisor and another simplified splitted supervisor. All approaches were tested against the comparison models GenIE and synthIE \cite{Josifoski2021,Josifoski2023}, evaluated on the 50 first samples of the synthIE-text dataset.

The overall results have shown the high performance of the CIExMAS approach by achieving a F1-score of 0.665. Within the comparison of multiple approaches, the network architecture scored the best, where a custom architecture, with a splitted supervisor approach scored the worst overall. Comparison models on the same synthIE-text dataset scored up to 0.831 with a dataset fine-tuned model, whereas the CIExMAS approach is using in-context learning.

In more fine-grained comparisons done on the subject, object and entity extraction the CIExMAS achieved best-in-comparison results with F1-score of 0.93 and above. In addition, multiple CIExMAS configurations achieved best-in-comparison result in one of the categories. One exception to the overall near perfect results is the property extraction, which shows a 19\% gap between the best CIExMAS configuration and the best synthIE model.

Nevertheless, the results has to be reviewed with the approaches of \citet{Josifoski2023,Josifoski2021} in mind. First of all, \citet{Josifoski2023} trained their \ac{LM} on the synthIE-code train split, with over 1.8M sample documents, instead of using manual prompt engineering on mainly five samples of the synthIE-text validation split. GenIE as another non-finetuned model shows even more drawbacks than CIExMAS, while reaching 52\% of the synthIE performance, while CIExMAS reaches 81\%.

The setup of CIExMAS has the intend to create an approach that is dataset-agnostic. To give CIExMAS a sense of what kind of triples are expected, the prompt engineering was combined with in-context learning. That is why fine-tuning was not used or any kind of extensive in-context learning.

The results showed that the initial baseline could already score a reasonable result compared to various later used approaches like the \ac{SSA} or the knowledge graph integration. What could be shown within the various configurations is, that the various kinds of approaches had problems, as the output expected the properties to be in the entity namespace of wikidata. The initial baseline was indented to output QNames instead of full URIs, which made the output process simpler.

Additional, it has to be mentioned, that the GenIE and synthIE model has not looked onto the problem of URI retrieval. Instead both models had limited possible tokens, that they could output. As follow up of the output restriction, also no hallucination has to been handled by \citet{Josifoski2023}. That could cause better results, as the result checking and output limiting must be heavily enforced via different agents in CIExMAS configurations.

The overall configuration comparison also shows that the idea of using the simplest architecture possible is also apparent for closed information extraction. Like outlined in section \ref{sec:agent_design} multi-agent system should be started if the agent start to fail to follow instructions. Combined with \citet{Anthropic2024} this implies to prefer simplicity before complexity.

The baseline and ReAct architecture could be optimised much further and easier than complex and individual solution like the \ac{SSA} or \ac{SSSA}. In the end, the work of CIExMAS approached the multi-agent system first, as models showed low instruction following. Nevertheless, the \ac{SSSA}, but more especially the \ac{SSSA} solution has not been the appropriate solution to that. Instead testing out the capabilities of the used \ac{LLM} was leading to the best configuration. Especially the high capabilities showed by the ReAct agent, but also the idea of iterating over a solution like a human or the \ac{SSA} and \ac{SSSA} would to came together in the network approach.

Especially the low instruction following capabilities enabled through the prompts were limiting the most simplest architectures. As additional guidelines in the prompts did not led to a solution to edge case errors, another solution needed to be established. This showed that especially the complexity in the connection of triples to URIs in Wikidata led CIExMAS to employ a multi-agent system. In addition, the network solution has shown clearly scoped agents, where the overhead of the agentic system was spread over the whole system. This has been very effictive, as the agent flow could be considered in the context of the needs of the agents. This also complies with the various agent design ideas like a human-understandable and consise agent design presented in section \ref{sec:agent_design}.

Another decision about simplicity against complexity is about the URI search mechanism. Throughout the process of creating the various CIExMAS approaches, it has been shown that more complex filter and search modes does not led to higher results. In the end, the \ac{LLM} has to understand perfectly when to use what search and filter mode, which did not become evident. Especially the search modes label and description were not used as intended. In the end the simplicity of filtering on entities and properties was the best, when combined with a property example search. Again, closed information extraction requires a minimum of complexity, as especially the mapping of labels to URIs is a problem in CIExMAS.

The usage of LLMs as models did add additional complexity. Those models showed hallucination in the URI Mapping, even when the URI retrieval tool was used. A paper of \citet{Xu2025} proposed that \acp{LLM} inevitably hallucinate. Nevertheless, the employed methods to prevent hallucination and check on the results of the agents has been shown useful in the network architecture and in the updated approaches of the ReAct architecture and the baseline architecture. Especially the turtle to lable tool could show hallucinated results, which could be \ac{LLM}-detected.

On the other side a architecture which was not advanced by additional tool use and hallucination prevention is the baseline architecture, with one supervisor, two extractos and the URI retrieval tool with \ac{LLM}-summary. This architecture could be optimised solely by using prompt optimisations, error incorporation and the best URI search modes and then it achieved good results either. Therefore, it can be assumed that most of the performance gain of the network architecture and the updated ReAct architecture come from the switched URI modes. Nevertheless, as the validation tools lead the agents to keep non-sense triples out of the output, it is likely to have a positive effect on the F1-score, especially on the precision.

What can also be assumed from the results achieved with knowledge graph integration tool, is that the quality needs to be high for those tools to work. The network traversal tool based on Wikidata showed performance losses, whereas the semantic validation tool which is based on a filtered subset of Wikidata showed overall performance gains. Especially the data needs to be loop free and efficient to crawl. Otherwise, the retrieval would take unconsiderabely long or run into timeouts.

In the end of the interpretation of the results, it remains visible that the biggest problem are the properties. Error rates could be eliminated by using error incorporation and to decrease the context size by design. Subject, object and entity extraction could be optimised by using in-context learning and prompt optimisation. Those parts of the triple could also be consistently found using the URI retrieval tool. On the property side, most of the properties were not written like they were in Wikidata. The sentence \enquote{Daniel Johannsen is a Tenor} will lead the agents to extract \textit{is a} as the free-form property. Then it will search for \textit{is a}, which is likely to return something like \textit{wd:P361}, which has the label \textit{part of}. To prevent this result, the agent has got the ability to search with the full triple, which is in this case the full sentence. Nevertheless, the traces and experiments showed, that only a part of the missing properties could be found via this search method.

Overall the meaningfulness of the results remains limited as only 50 samples are used for testing, with even less samples used for a manual training. The comparability to the comparison models is nevertheless given, as they were tested on the same samples. Exactly those models also show an underperformance on those samples, as \citet{Josifoski2023} show a macro F1-score for triple extraction of 0.93 for their best synthIE model on the full dataset. Therefore, the chosen samples could have led to worse results on CIExMAS either. The decision to use just 50 samples is grounded in the fact, that for instance the \ac{SSA} and \ac{SSSA} already took a runtime of approximately 6 hours on those 50 samples on the vLLM Llama 3.3 70B setup with 2x Nvidia A100 cards. In addition, the focus of this work was to evaluate, whether it may be possible to process closed information extraction with multi agent system and to detect the most effective architecture. To test this in regards to a given time limit of 12 hours runtime, it was the decision not to include more samples on testing.

The URI mapping remains a point for discussion. The Wikidata knowledge graph is most likely included in one of the datasets used to train Llama 3.3 70B or other models. Therefore, the models might already memorise URIs and their mapping, which could give a benefit in triple formation and also in the URI retrieval. On the otherside traces that have shown no interaction with the URI retrieval tool at all mostly have hallucinated URIs, that are foremost limiting the results. In addition, the Wikidata incorporation leads to a problem, where properties were outputed in the namespace \textit{wdt:}, which in fact is the correct namespace for properties. Nevertheless, for a simpler evaluation, especially for the detection of soft matches in the property hierarhcy, the namespace \textit{wd:} was necessary.

Additionally, the synthIE dataset could additionally be inside the training dataset of various \acp{LLM}. Also, examples of the dataset are used for in-context learning. As the performance of CIExMAS is nowhere near perfect, it can be assumed, that a possible inclusion of synthIE data in the training data or in the prompt has near zero effect on the extraction performance.

The agent engineering was conduct for most of the configurations on synthIE-code instead of the text version of synthIE. As the quality of synthIE-code remains lower than on synthIE-text, the prompts could tend towards edge only existant in synthIE-code. As an example the code version included \enquote{Herman Heijermans was born in the Netherlands.} and the text version included \enquote{Herman Heijermans was a citizen of the Kingdom of the Netherlands.}. Both version searched for the triple \textit{(Herman Heijermans; country of citizenship; Kingdom\_of\_the\_Netherlands)}. Nevertheless in experiements, the same models have shown improved results when comparing the code and the text versions. Espeically, as edge cases were not given by example instead there were generalised.

The dataset used for the knowledge graph integration tools of network traversal and semantic validation variied. The network traversal showed with the full Wikidata dataset limitation in regards of the depth of the SPARQL query evaluating if type restrictions are matched or not. The semantic validation instead could use the full depth using a filtered wikidata class and property hierarchy, which are both loopfree. As the dataset was not part of the development of CIExMAS it will not be further described. Nevertheless, this shows, that the network traversal could have performed better on another dataset. In the end, other topics like the integration of the validation tools to the ReAct architecture and updating the search mode were prioritised. Due to time constraints the network traversal tool, which would also have needed additional optimision, was not implemented.

All prompts were manually created and adapted, except for some help through ChatGPT 4o or Cursor. This kind of manual prompt engineering is not necessarily leading to the best overall prompts. In addition, the prompts are and had to be adapted with every configuration to adapt to new tools or new tool implementations. This could lead one architecture to be accidentially score higher F1-scores than others. Nevertheless, a clear trend of architectural ideas could be seen throughout the evaluation, which leads to the assumption, that the prompt had a minor effect, than implementation and design details like the search type and state, which were kept constant per architecture. In addition, automatic prompt engineering is ressource or cost intensive, without a guarantee of the desired outcome.

The same time and resource constraints that led to the sample reduction also limited the use of models. Nevertheless, as outlined in section \ref{subsec:eval_language_models} \acp{LLM} with up to 70 billion parameters show near state-of-the-art results on benchmarks. In the case of CIExMAS, the model of Llama 3.3 70B showed the best overall performance against other and especially more capable models when relying on benchmarks. As \acp{LLM} remain prompt senstive and especially to format of output that is expect remains unstructured, it can lead to worse results. In addition, modern models support longer context, with the new Llama 4 models supporting up to 10 million tokens. As a constraint of multiple providers and the system used for testing on the synthIE dataset, the context in CIExMAS is limited to 8192 tokens. In addition, the limitation made problems throughout the whole process. On the positive side, the context needed therefore to be designed precise while also allowing iterations.

In addition to the restriction on \acp{LLM}, also the Embedding model has to be open-source. In total two models were tested with nomic-embed-text and bge-m3. In the bge-m3 showed better results in small experiments and also supervisor results in embedding benchmarks \cite{Muennighoff2023}. In the end, there are better models available, which either use more memory, were later published or were not available on Ollama. In addition, the main attention was put into the \acp{LLM}, but especially in the agent engineering, as the embeddings have been shown working like outlined at multiple points in the thesis.

In addition, CIExMAS was designed to work with multiple datasets and also provide the ability to be extended by the generation of entities in a knowledge graph later on instead of just using what is already provided in the knowledge graph. That is why, unlike in synthIE, the results were not limited towards predefined tokens that form the triples. In addition, there were multiple entities of various datasets and datasplits imported in the vector database used for the URI retrieve. This could affect the URI retrieval performance negeatively, but on the other side is a more realistic scenario, espeically as not all entities and properties of synthIE and REBEL were imported. In addition, uploading multiple dataset to the vector stores gave the ability to switch through the datasets easily without handling multiple vector store collections or filtering on datasets. Furthermore, it could be assumed that some entities and properties are the same and that the URI retrieval should find only relevant URIs according to the search term and search mode.

Furthermore, a high focus was put on the generalisation of CIExMAS to other dataset. Nevertheless, CIExMAS was extensively evaluated on only one dataset. It showed, that many configurations were already necessary to push the overall performance of the CIExMAS configurations. In addition, other datasets like REBEL, that would be comparable to many other models, was found non sufficient in its data quality. Therefore, CIExMAS was designed generalisable, but it remains untested as the switch from synthIE-code to synthIE-text was no switch in the expected triples, just of the texts.

All in all, the process of CIExMAS needs to be discussed as whole. In general, the iterative process showed how the experience with specific agents could enhance architectures. For instance the experience with the ReAct agent lead to consilidation of extraction agents in the network architecture. Nevertheless, the CIExMAS process did not progressed the trajectory from simple to more complex. Starting with the baseline architecture, which hold the steps of the pipeline approach for closed information extraction, and then going over to the more complex \ac{SSA} skipped the step of starting with the most simplistic architecture. Nevertheless, all steps were done based on the experiements with the architectures. In the end, every learning of especially also the more complex architecture led to the CIExMAS overall result.

In addition, multiple ideas were further optimised before being scraped. For instance the property extraction agent, that showed a worse result when being included in the \ac{SSA}, was also implemented in th \ac{SSSA}. As a background all of the tools had the idea to target a single issue. As for instance properties remain a present issue throught all appraoches the agent was further optimisation. On the otherside, the comparisons of the impact of each agent could have furthermore improved the understanding of why an agent works and why not. In addition, CIExMAS was trained as a whole, instead of training the single steps to be peak perfect. This made it easier to train all agents and tools towards an common goal.

Overall, CIExMAS remains a successful approach to do closed information extraction using multi-agent systems. Compared to especially synthIE the result of 0.665 F1-score was achieved without heavy fine-tuning or extensive in-context learning. Other approaches like GenIE could be outperformed. In addition, the process of CIExMAS may not have been perfectly streamlined it showed the flaws and drawbacks of each configuration and showed, that simplicity should be used before complexity, while in the closed information extraction domain some complexity is likely to be necessary, especially when \acp{LLM} with limited capabilites were used.

\chapter{Conclusion and Outlook}
\label{ch:conclusion_outlook}

In this master thesis CIExMAS was developed as an answer to the two research questions of to what extent \ac{LLM}-based \acp{MAS} can perform closed information extraction on unstructured text and which agentic architectures (e.g., single-agent, supervisor-agent, or agent networks) perform best for this task in terms of accuracy and robustness. The evaluation on a 50-sample dataset out of synthIE-text could show, that the best CIExMAS approach could score 0.665 F1-score on the triple extraction. Therefore, CIExMAS reaches 80\% of the compared synthIE${_T5-large}$ model, which is fine-tuned on the train split of the dataset. Another model of \citet{Josifoski2021} reaches just 0.392 F1 for the same metric on the same samples, but in comparison is trained on another dataset, with less quality.

In more detailed evaluations it can be shown that MAS especially with the choosen way of embedding-based similarity searches for URI-retrieval, excels on extracting subjects, objects but also entities in general. Nevertheless, throughout various configurations, the prevalent problem remain the property extraction. It could be seen, that this is also the limiting factor on synthIE or GenIE models. Therefore, the answer is that the \ac{LLM}-based \acp{MAS} tested in this thesis can already perform closed information extraction to a high extend, but not to the highest extend or near perfect.

The agentic architectures varied highly from the count of agents and tools over the state to their overall capabilities. A clear trajectory can be drawn across the general complexity of the architectures. The most simple but also most precise archiecture, prompt or tool can achieve the best results. Complex architecture require complex prompts and complex optimisation, while tend to bloat the context and therefore create more errors. In the evaluations of the thesis it has shown, that especially more complex models, do also in non-erronous runs produce no better results than simpler architecture. That is why the ReAct and baseline architecture, last is a supervisor archiecture, are one of the best architectures, which are only surpassed by the network architecture. It has been shown that the usage of \acp{LLM} and an URI retrieval can make use of extra agents for the URI mapping task as well as for a validation. Therefore, it is not the simplest architecture with the network architecture that performs the best for the \ac{cIE} task in terms of accuracy and robustness.

The approach of CIExMAS introduces multiple \ac{MAS} architectures that can process closed information extraction tasks. The work therefore, contributes to an overall goal of generating knowledge graphs out of unstructured text. The work therefore contributes to latest research within the overall field of using \acp{LLM} for various \ac{IE} tasks with a general proof of concept of using \ac{MAS} for closed information extraction, which can be used for further development.

CIExMAS proposes in general five architectural patterns for the use in \ac{cIE}. From those, the supervisor, ReAct and network patterns have been found most useful after the testing. In addition, CIExMAS introduces advantages and disadvantages of various kinds of agents and tools used for the closed information extraction. Therefore, knowledge graph incorporation and a URI retrieval on rdfs:label, but also on property examples have been found useful.

As the area of \acp{LLM}, sentence embeddings and agentic AI is a fast evolving research field, the work first of all will and can not include all recent improvements. In addition, the development of \ac{MAS} opens a broad area for optimisations. For instance the usage of agents is highly depended on the users ideas. This large solution space could not searched exhaustively throughout CIExMAS, with the limited timeframe of a master thesis. Instead the focus was on architectures and knowledge graph incorporation.

This focus led to various other limitations of CIExMAS. First, the prompt engineering was done manually. Second, CIExMAS does not include any finetuned models. Both limitations were additionally caused by limited resources. Against the fine-tuned models spoke the overall proposal of \citet{Brown2020} that proposes in-context learning as nearly as good alternative to fine-tuning of models.

In general, the evaluation was also done on 50-samples which limits the meaningfulness of the exact F1-score. Nevertheless, the results indicate a general behavior. In addition, the generalisation idea that was designed closely to all architectures, has never been tested extensively. Therefore, no statement can be done about the generalisation capabilities of CIExMAS nor on the compared synthIE models.

In addition, as the area of \acp{LLM} is fastly evolving, driven through big tech companies, \acp{LLM} are published with a high velocity \cite{Brown2020,Grattafiori2024,MetaAI2025,Chiang2024}. Therefore, there are definite better models than \textsc{Llama 3.3 70B} published. The same goes for the use of \textsc{bge-m3} as embedding model to retrieve \acp{URI}. Other models were tested, but not exhaustively, especially larger and now SOTA models. Nevertheless, those models have not been found to perform better.

In the end the whole processing of the creating CIExMAS was manually. Ranging from the architectures of the agentic system to the single prompts of each agent CIExMAS was developed by hand. Automated approaches have shown greate success, but also need multiple \ac{LLM}-calls. As this was not the focus of the thesis, the iterative trial and error process was more expendit.

The work of CIExMAS and the connected limitations with this works reveals enormous ideas for future work. The high focus on the generalisation, where also in-context learning was prefered over fine-tuning, needs to tested on other datasets. Until now, the REBEL or REDFM are closely comparable to the synthIE dataset \cite{HuguetCabot2021,Cabot2023}. Nevertheless, both datasets miss out on quality or comparisons. Therefore, it could also be useful to wait for other high quality closed information extraction datasets. In addition, document-level datasets could be evaluated. In addition, the free-form triple extraction could be tested on multiple other datasets to be comparable to various \ac{IE} approaches. In addition, datasets without Wikidata as underlying knowledge graph could be used to exclude the error source of test data inclusion in training data.

Parallel to switching the dataset, the models used for the agents and URI retrieval could be exchanged. Especially as \acp{LLM} are prompt sensitive it could be assumed, that if another model would have been used and optimised model-specific, well performing models could also have scored high scores on the \ac{cIE} tasks. In addition, future research will open up for even more capable models, which could be used in various CIExMAS configurations.

Another idea could to use another setup. In general, Llama 3.3 70B could support up to 128,000 tokens \cite{Meta2024}, but the setup with fast-inference providers on the on side limiting the context length to 8192 and 2x A100 on the other side limited the maximal context length. Therefore, the tradeoff of slower inference but therefore larger context lengths could be used in the future.

In addition to switching models, different models than \acp{LLM} could be used for specific tasks, as other \ac{NLP} models could also perform well on tasks like relation extraction or entity recognition. In general, the Llama 3.3 70B model could also be further fine-tuned for each specific task. With this step, especially the expected properties could be extracted into the resulting triples. Nevertheless, the generalisation factor has to be re-evaluated when using fine-tuned models.

The generalisation also led CIExMAS to allow for completely free-form triples, which in the end made it harder for the agent to retrieve the matching URIs for especially properties. Other approaches like synthIE are using a smart limitation mechanism for possible outputs. Such ideas could also be used in CIExMAS.

Another problem are the outputs of CIExMAS that could be further approved. First and foremost, the switch to the standardised structured output format could be improving the overall performance. Espeically errors in parsing the custom format will be evaded. In addition, the output of turtle strings remains hard in some configurations. More interestingly the output of QNames also worked in the initial baseline and outperformed various other more complex approaches. Using another output format could also make it easier to create correct machine-readable triples.

The major problem remains the property extraction. The idea of providing extra agents has not been found useful in CIExMAS. Nevertheless other approaches like describing the property instead of extracting a free-form label for the property extraction could be used. Especially as this task could be considered as rather hard, as properties could be hidden within relations between subjects and objects in simple words that mean a specific property, it could be useful to thing out of the box. For instance the subject, object connection could be created using one agent and the properties describing this relation being created with another agent. Providing better properties could then also lead to simpler URI search.

In general, other approaches could be tested on closed information extraction. All CIExMAS appraoches mainly approach through agents that are processing the triples step by step, but sequential. This appraoch could be considered as pipeline approach, which have shown inferior to joint approaches. Therefore, possible URIs, entities, relations and other useful things could be gathered in one step, where in the other one agent puts all information into a final output, except for question. The usage of \acp{LLM} opens up for even more of such ideas, that combine a workflow with an agentic idea.

In addition, the documents, which are mostly consisting out of maximum three sentences, could be processed in another way. First of all, they are processed at once in CIExMAS. This could be replaced by a sentence by sentence processing. In addition, the text keeps exact the free-form properties that are a problem to all CIExMAS solutions. Therefore, prior to the run of CIExMAS, the sentences could be rewritten by an \ac{LLM} in order to highlight especially properties.

In addition, the URI retrieval could also be a point to enhance the property extraction capabilities of CIExMAS. The sample search mode alongside with the property label search mode has already revealed the role that the URI retrieval tool plays. As an example, the properties can get more detailed described by CIExMAS and than be search on the description again. Especially, as this mode has never been exhaustively used by the agents before, it would be worth to try it again in future research. In addition, the URI retrieval is done via embeddings as of now. Systems like GraphRAG proposed by \citet{Edge2025} also use the knowledge graph directly and let the \ac{LLM} evaluate on the usefulness of subgraphs.

In general, the knowledge graph incorporation could be intensified in future research. CIExMAS has already proven the usefulness of semantic validation and turtle to label tools. An final conclusion to the network traversal tool can not be drawn. Nevertheless, an access to the knowledge graph via an SPARQL endpoint could be given directly to the agents in future research. Therefore, the agents could to things like network traversal searches or semantic validation themselves, when prompted correctly.

Another core optimisation point remains the prompt itself. The prompt do already follow some best practises, as it contains a general structure and constains few-shot examples for in-context learning. In the end, automated methods like proposed by \citet{Agrawal2025} have shown high effectiveness in prompt tuning. Especially as \acp{LLM} are able to understand language and problems, they show great performance in checking the problems of a prompt and an output \cite{Agrawal2025}. This would provide less subjective iterations, that are build on human-logic and would tend towards a more reproducable process.

In addition to using automated prompt engineering, it could be interesting in future research, to check on using more sophisticated prompt techniques. For instance, the prompt of the triple extractor could use more few-shot examples and an even more explicit chain of thought. In addition, the prompts could be reworked from ground up to try with more readable prompts.

In the end CIExMAS remains a starting point for future research. As of the modular design of a \ac{MAS}, CIExMAS could either be narrowed towards extracting just properties or disambiguate entities, but it could also be extended to create whole knowledge graphs. As of now the \ac{cIE} task already shows high limitations and challenges. When those challenges can be tackled and the F1 score is near perfect, the CIExMAS approaches could go for the next step and create entities or properties that can not be found in the knowledge graph, as otherwise they would find it in the knowledge graph. Nevertheless, this would transfer to another research field where datasets are currently missing, but where the usefulness in real-world use-cases can be shown.

Overall CIExMAS reveals a part of the overall potential of the usage of \ac{MAS}. It can reach 80\% of SOTA comparison models, while not using fine-tuning and outputting turtle strings. In the end the CIExMAS work showed that especially simpler, but also precise and capable approaches showed high performances. This resulted in a network architecture with agents for triple extraction, URI mapping and validation and output with corresponding tools to perform the best. Nevertheless, CIExMAS only covers a focussed part of the \ac{MAS} and \ac{KG} possibilities, which can lead to outperforming of state-of-the-art results. In addition, CIExMAS is a starting point for future research including different appraoches to extract properties and to optimise the overall agentic system.

\bibliography{references/references}

\appendix
\chapter{Additional Material}
\label{ch:additional_material}

\section{REBEL Testing}
\label{sec:rebel_testing}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrrrrr}
    \toprule
    \textbf{Model} & \multicolumn{6}{c}{\textit{\textbf{Triples}}}                                                     \\
                   & Precision                                     & Recall & F1    & Parental F1 & Related F1 & Err.  \\
    \midrule
    Baseline       & 0.080                                         & 0.189  & 0.100 & 0.081       & 0.081      & 0.400 \\
    ReAct          & 0.107                                         & 0.115  & 0.089 & 0.085       & 0.085      & 0.100 \\
    Network        & 0.063                                         & 0.121  & 0.076 & 0.059       & 0.059      & 0.120 \\
    \bottomrule
  \end{tabular}
  \caption{Comprehensive performance comparison on the REBEL dataset for different CIExMAS configurations.}
  \label{tab:rebel_comprehensive_results}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Configuration} & \multicolumn{3}{c}{\textit{\textbf{Subjects}}}                  \\
                           & Precision                                      & Recall & F1    \\
    \midrule
    Baseline               & 0.417                                          & 0.507  & 0.414 \\
    ReAct                  & 0.577                                          & 0.410  & 0.447 \\
    Network                & 0.310                                          & 0.305  & 0.280 \\
    \bottomrule
  \end{tabular}
  \caption{Subject recognition performance on the REBEL dataset for different CIExMAS configurations.}
  \label{tab:rebel_subjects}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrrrr}
    \toprule
    \textbf{Configuration} & \multicolumn{5}{c}{\textit{\textbf{Properties}}}                                             \\
                           & Precision                                        & Recall & F1    & Parental F1 & Related F1 \\
    \midrule
    Baseline               & 0.176                                            & 0.362  & 0.214 & 0.276       & 0.300      \\
    ReAct                  & 0.253                                            & 0.247  & 0.217 & 0.259       & 0.318      \\
    Network                & 0.148                                            & 0.194  & 0.149 & 0.184       & 0.214      \\
    \bottomrule
  \end{tabular}
  \caption{Property recognition performance on the REBEL dataset for different CIExMAS configurations.}
  \label{tab:rebel_properties}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Configuration} & \multicolumn{3}{c}{\textit{\textbf{Objects}}}                  \\
                           & Precision                                     & Recall & F1    \\
    \midrule
    Baseline               & 0.163                                         & 0.384  & 0.208 \\
    ReAct                  & 0.198                                         & 0.200  & 0.161 \\
    Network                & 0.122                                         & 0.186  & 0.134 \\
    \bottomrule
  \end{tabular}
  \caption{Object recognition performance on the REBEL dataset for different CIExMAS configurations.}
  \label{tab:rebel_objects}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Configuration} & \multicolumn{3}{c}{\textit{\textbf{Entities}}}                  \\
                           & Precision                                      & Recall & F1    \\
    \midrule
    Baseline               & 0.311                                          & 0.582  & 0.382 \\
    ReAct                  & 0.383                                          & 0.370  & 0.342 \\
    Network                & 0.211                                          & 0.309  & 0.241 \\
    \bottomrule
  \end{tabular}
  \caption{Entity recognition performance on the REBEL dataset for different CIExMAS configurations.}
  \label{tab:rebel_entities}
\end{table}

\newpage

\section{Evaluation Results by Category}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Model}         & \multicolumn{3}{c}{\textit{\textbf{Subjects}}}                                   \\
                           & Precision                                      & Recall         & F1             \\
    \midrule
    SynthIE$_{T5-large}$   & 0.927                                          & 0.943          & 0.929          \\
    SynthIE$_{T5-base-SC}$ & \textbf{0.930}                                 & \textbf{0.945} & \textbf{0.934} \\
    SynthIE$_{T5-base}$    & 0.923                                          & 0.938          & 0.926          \\
    GenIE$_{T5-base}$      & 0.710                                          & 0.742          & 0.689          \\
    GenIE$_{T5-base-SC}$   & 0.691                                          & 0.698          & 0.665          \\
    \midrule
    \textbf{CIExMAS}       & \textbf{0.930}                                 & 0.915          & 0.907          \\
    \bottomrule
  \end{tabular}
  \caption{Subject recognition performance comparison of CIExMAS against state-of-the-art models on the synthIE dataset.}
  \label{tab:evaluation_subjects}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrrrr}
    \toprule
    \textbf{Model}         & \multicolumn{5}{c}{\textit{\textbf{Properties}}}                                                                     \\
                           & Precision                                        & Recall         & F1             & Parental F1    & Related F1     \\
    \midrule
    SynthIE$_{T5-large}$   & \textbf{0.882}                                   & \textbf{0.890} & \textbf{0.882} & \textbf{0.894} & \textbf{0.912} \\
    SynthIE$_{T5-base-SC}$ & 0.850                                            & 0.868          & 0.854          & 0.885          & 0.907          \\
    SynthIE$_{T5-base}$    & 0.853                                            & 0.848          & 0.849          & 0.888          & 0.905          \\
    GenIE$_{T5-base}$      & 0.646                                            & 0.395          & 0.459          & 0.501          & 0.527          \\
    GenIE$_{T5-base-SC}$   & 0.625                                            & 0.357          & 0.424          & 0.455          & 0.478          \\
    \midrule
    \textbf{CIExMAS}       & 0.784                                            & 0.672          & 0.710          & 0.782          & 0.790          \\
    \bottomrule
  \end{tabular}
  \caption{Property recognition performance comparison of CIExMAS against state-of-the-art models on the synthIE dataset.}
  \label{tab:evaluation_properties}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Model}         & \multicolumn{3}{c}{\textit{\textbf{Objects}}}                                   \\
                           & Precision                                     & Recall         & F1             \\
    \midrule
    SynthIE$_{T5-large}$   & 0.926                                         & \textbf{0.930} & \textbf{0.921} \\
    SynthIE$_{T5-base-SC}$ & 0.891                                         & 0.915          & 0.895          \\
    SynthIE$_{T5-base}$    & 0.912                                         & 0.915          & 0.909          \\
    GenIE$_{T5-base}$      & 0.858                                         & 0.484          & 0.583          \\
    GenIE$_{T5-base-SC}$   & 0.845                                         & 0.449          & 0.551          \\
    \midrule
    \textbf{CIExMAS}       & \textbf{0.960}                                & 0.823          & 0.867          \\
    \bottomrule
  \end{tabular}
  \caption{Object recognition performance comparison of CIExMAS against state-of-the-art models on the synthIE dataset.}
  \label{tab:evaluation_objects}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|rrr}
    \toprule
    \textbf{Model}         & \multicolumn{3}{c}{\textit{\textbf{Entities}}}                                   \\
                           & Precision                                      & Recall         & F1             \\
    \midrule
    SynthIE$_{T5-large}$   & 0.936                                          & \textbf{0.937} & \textbf{0.933} \\
    SynthIE$_{T5-base-SC}$ & 0.915                                          & 0.929          & 0.918          \\
    SynthIE$_{T5-base}$    & 0.931                                          & 0.929          & 0.928          \\
    GenIE$_{T5-base}$      & 0.932                                          & 0.606          & 0.712          \\
    GenIE$_{T5-base-SC}$   & 0.937                                          & 0.587          & 0.696          \\
    \midrule
    \textbf{CIExMAS}       & \textbf{0.966}                                 & 0.876          & 0.907          \\
    \bottomrule
  \end{tabular}
  \caption{Entity recognition performance comparison of CIExMAS against state-of-the-art models on the synthIE dataset.}
  \label{tab:evaluation_entities}
\end{table}



\clearpage
\section{Detailed Performance Analysis by Category}

\begin{table}[h]
  \centering
  \begin{tabular}{p{6cm}|rrrr}
    \toprule
    \textbf{Configuration}               & \multicolumn{4}{c}{\textit{\textbf{Subjects}}}                                           \\
                                         & Prec.                                          & Rec.           & F1    & Err.           \\
    \midrule
    Initial Baseline                     & 0.601                                          & 0.768          & 0.646 & 0.200          \\
    Task Modularization (SSA)            & 0.487                                          & 0.767          & 0.564 & 0.180          \\
    Error Incorp. (SSA) + PropEx         & 0.697                                          & \textbf{0.952} & 0.771 & 0.020          \\
    Error Incorp. (SSA)                  & 0.564                                          & 0.815          & 0.633 & 0.120          \\
    Error Incorp. (Baseline)             & 0.764                                          & 0.932          & 0.803 & 0.000          \\
    Agent System Simplification (SSSA)   & 0.764                                          & 0.880          & 0.791 & 0.020          \\
    ReAct Architecture                   & 0.827                                          & 0.863          & 0.825 & 0.060          \\
    URI Retrieval (SSSA)                 & 0.837                                          & 0.882          & 0.841 & 0.040          \\
    URI Retrieval (ReAct)                & 0.898                                          & 0.900          & 0.885 & 0.020          \\
    Knowledge Graph Integration          & 0.671                                          & 0.700          & 0.675 & 0.240          \\
    \textbf{Network Architecture (Gen2)} & \textbf{0.930}                                 & 0.915          & 0.907 & \textbf{0.000} \\
    Advanced Adapt. (ReAct)              & 0.870                                          & 0.833          & 0.837 & 0.020          \\
    Advanced Adapt. (Baseline)           & 0.800                                          & 0.948          & 0.840 & 0.000          \\
    \bottomrule
  \end{tabular}
  \caption{Subject recognition performance across CIExMAS development iterations.}
  \label{tab:evaluation_subjects_iterations}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{p{4cm}|rrrrrr}
    \toprule
    \textbf{Configuration}               & \multicolumn{6}{c}{\textit{\textbf{Properties}}}                                                                                      \\
                                         & Prec.                                            & Rec.           & F1             & Par. F1        & Rel. F1        & Err.           \\
    \midrule
    Initial Baseline                     & 0.351                                            & 0.393          & 0.363          & 0.442          & 0.450          & 0.200          \\
    Task Modularization (SSA)            & 0.281                                            & 0.331          & 0.290          & 0.364          & 0.378          & 0.180          \\
    Error Incorp. (SSA) + PropEx         & 0.301                                            & 0.294          & 0.286          & 0.345          & 0.358          & 0.020          \\
    Error Incorp. (SSA)                  & 0.378                                            & 0.445          & 0.390          & 0.469          & 0.487          & 0.120          \\
    Error Incorp. (Baseline)             & 0.522                                            & 0.564          & 0.531          & 0.617          & 0.625          & 0.000          \\
    Agent System Simplification (SSSA)   & 0.498                                            & 0.462          & 0.471          & 0.545          & 0.556          & 0.020          \\
    ReAct Architecture                   & 0.551                                            & 0.484          & 0.503          & 0.597          & 0.604          & 0.060          \\
    URI Retrieval (SSSA)                 & 0.529                                            & 0.482          & 0.495          & 0.577          & 0.585          & 0.040          \\
    URI Retrieval (ReAct)                & 0.597                                            & 0.497          & 0.533          & 0.611          & 0.623          & 0.020          \\
    Knowledge Graph Integration          & 0.495                                            & 0.420          & 0.449          & 0.539          & 0.546          & 0.240          \\
    \textbf{Network Architecture (Gen2)} & \textbf{0.784}                                   & \textbf{0.672} & \textbf{0.710} & \textbf{0.782} & \textbf{0.790} & \textbf{0.000} \\
    Advanced Adapt. (ReAct)              & 0.746                                            & 0.548          & 0.616          & 0.676          & 0.683          & 0.020          \\
    Advanced Adapt. (Baseline)           & 0.645                                            & 0.640          & 0.631          & 0.724          & 0.735          & 0.000          \\
    \bottomrule
  \end{tabular}
  \caption{Property recognition performance across CIExMAS development iterations.}
  \label{tab:evaluation_properties_iterations}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{p{6cm}|rrrr}
    \toprule
    \textbf{Configuration}               & \multicolumn{4}{c}{\textit{\textbf{Objects}}}                                                    \\
                                         & Prec.                                         & Rec.           & F1             & Err.           \\
    \midrule
    Initial Baseline                     & 0.625                                         & 0.745          & 0.665          & 0.200          \\
    Task Modularization (SSA)            & 0.524                                         & 0.702          & 0.568          & 0.180          \\
    Error Incorp. (SSA) + PropEx         & 0.793                                         & 0.851          & 0.802          & 0.020          \\
    Error Incorp. (SSA)                  & 0.675                                         & 0.777          & 0.705          & 0.120          \\
    Error Incorp. (Baseline)             & 0.860                                         & 0.922          & 0.880          & 0.000          \\
    Agent System Simplification (SSSA)   & 0.804                                         & 0.797          & 0.789          & 0.020          \\
    ReAct Architecture                   & 0.877                                         & 0.815          & 0.834          & 0.060          \\
    URI Retrieval (SSSA)                 & 0.899                                         & 0.861          & 0.871          & 0.040          \\
    URI Retrieval (ReAct)                & 0.910                                         & 0.800          & 0.843          & 0.020          \\
    Knowledge Graph Integration          & 0.705                                         & 0.641          & 0.665          & 0.240          \\
    \textbf{Network Architecture (Gen2)} & \textbf{0.960}                                & 0.823          & 0.867          & \textbf{0.000} \\
    Advanced Adapt. (ReAct)              & 0.862                                         & 0.637          & 0.714          & 0.020          \\
    Advanced Adapt. (Baseline)           & 0.906                                         & \textbf{0.949} & \textbf{0.918} & 0.000          \\
    \bottomrule
  \end{tabular}
  \caption{Object recognition performance across CIExMAS development iterations.}
  \label{tab:evaluation_objects_iterations}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{p{6cm}|rrrr}
    \toprule
    \textbf{Configuration}               & \multicolumn{4}{c}{\textit{\textbf{Entities}}}                                                    \\
                                         & Prec.                                          & Rec.           & F1             & Err.           \\
    \midrule
    Initial Baseline                     & 0.695                                          & 0.767          & 0.724          & 0.200          \\
    Task Modularization (SSA)            & 0.619                                          & 0.741          & 0.657          & 0.180          \\
    Error Incorp. (SSA) + PropEx         & 0.875                                          & 0.905          & 0.880          & 0.020          \\
    Error Incorp. (SSA)                  & 0.778                                          & 0.814          & 0.784          & 0.120          \\
    Error Incorp. (Baseline)             & 0.944                                          & 0.960          & 0.947          & 0.000          \\
    Agent System Simplification (SSSA)   & 0.882                                          & 0.892          & 0.879          & 0.020          \\
    ReAct Architecture                   & 0.918                                          & 0.878          & 0.891          & 0.060          \\
    URI Retrieval (SSSA)                 & 0.927                                          & 0.898          & 0.908          & 0.040          \\
    URI Retrieval (ReAct)                & 0.943                                          & 0.878          & 0.906          & 0.020          \\
    Knowledge Graph Integration          & 0.731                                          & 0.706          & 0.716          & 0.240          \\
    \textbf{Network Architecture (Gen2)} & \textbf{0.966}                                 & 0.876          & 0.907          & \textbf{0.000} \\
    Advanced Adapt. (ReAct)              & 0.895                                          & 0.718          & 0.785          & 0.020          \\
    Advanced Adapt. (Baseline)           & 0.963                                          & \textbf{0.970} & \textbf{0.964} & 0.000          \\
    \bottomrule
  \end{tabular}
  \caption{Entity recognition performance across CIExMAS development iterations.}
  \label{tab:evaluation_entities_iterations}
\end{table}

\backmatter
\chapter{Ehrenwörtliche Erklärung}
\label{ch:declaration}

Ich versichere, dass ich die beiliegende Bachelor-, Master-, Seminar-, oder
Projektarbeit ohne Hilfe Dritter und ohne Benutzung anderer als der angegebenen
Quellen und in der untenstehenden Tabelle angegebenen Hilfsmittel angefertigt
und die den benutzten Quellen wörtlich oder inhaltlich entnommenen Stellen als
solche kenntlich gemacht habe. Diese Arbeit hat in gleicher oder ähnlicher Form
noch keiner Prüfungsbehörde vorgelegen. Ich bin mir bewusst, dass eine falsche
Erklärung rechtliche Folgen haben wird.

\begin{center}
  \textbf{Declaration of Used AI Tools} \\[.3em]
  \begin{tabularx}{\textwidth}{lXlc}
    \toprule
    Tool & Purpose & Where? & Useful? \\
    \midrule
    % Add your AI tools here
    \bottomrule
  \end{tabularx}
\end{center}

\vspace{2cm}
\noindent Unterschrift\\
\noindent Mannheim, den XX.~XXXX 2024 \hfill

\end{document}
